{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Get Data \n",
    "\n",
    "National Speech Corpus\n",
    "- Part 3: 1000 hours of conversational speech data (Used by Home team)\n",
    "- Part 2: 1000 hours of prompted recordings of random sentences containing local words and entities (Used by some developer)\n",
    "- Part 4: Conversational code-switched data (from Singaporean English to various native languages)\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "- https://medium.com/htx-dsai/finetuning-whisper-for-the-singaporean-home-team-context-a3ae1a6ae809\n",
    "- https://www.jensenlwt.com/blog/singlish-whisper-finetuning-asr-for-singapore-unique-english\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Prepare Data\n",
    "\n",
    "- Match each transcript sentence to its corresponding audio file\n",
    "- Check on the environment where the audio is recorded (decide the environment)\n",
    "    - Hometeam\n",
    "        - The NSC Part 3 recordings are split into two environments, each with two different microphones used for recording. In the first environment, where speakers were in the same room, we selected the recordings using the close-talk mic as this isolated the main speakerâ€™s voice (without picking up background noise or the secondary speaker). For the second environment with speakers in different rooms, we chose to use the standing microphone recordings, as opposed to recordings via telephone.\n",
    "    - Same room environment: Close-talk mic that isolates main speaker's voice \n",
    "    - Different room environment: Standing microphone as opposed to telephone\n",
    "- Clean the transcripts by removing annotations\n",
    "- Normalise the transcript text\n",
    "    - Remove punctuations\n",
    "    - Lowercase text\n",
    "- Create 30s audio segments with corresponding transcripts\n",
    "    - Using time segments from ```TextGrid files```, splice out corresponding segments from WAV files\n",
    "    - Combine shorter consecutive segments (?)\n",
    "    - 30s: Whisper's feature extractor ensures all audio is 30s (intrinsic design)\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "- https://medium.com/htx-dsai/finetuning-whisper-for-the-singaporean-home-team-context-a3ae1a6ae809\n",
    "- https://www.jensenlwt.com/blog/singlish-whisper-finetuning-asr-for-singapore-unique-english\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "More on dataset part 3 (see ```ABOUT.txt```):\n",
    "\n",
    "Part 3 consists of about 1000 hours of conversational data recorded from about 1000 local English speakers, split into pairs. The data includes conversations covering daily life and of speakers playing games provided. \n",
    "\n",
    "Part 3's recordings were split into 2 environments. In the Same Room environment where speakers were in same room, the recordings were done using 2 microphones: a close-talk mic and a boundary mic. In the Separate Room environment, speakers were separated into individual rooms. The recordings were done using 2 microphones in each room: a standing mic and a telephone. \n",
    "\n",
    "Part 3 is further organised into a six subdirectories, 3 for each recording environment (Same Room or Separate Room). Among each group of 3 subdirectories, 1 contains transcriptions, while the remaining 2 contain audio data from each of the two microphones used for the environment. There is also a manifest document at the root of the Part 3 folder that lists the files released.\n",
    "\n",
    "\n",
    "Summary of Part 3 data organization:\n",
    "- Same Room environment, files organized by speaker number:\n",
    "    - /Scripts Same: Orthographic transcripts saved in TextGrid format\n",
    "    - /Audio Same BoundaryMic: Audio files in WAV format recorded using the boundary mic, sampled at 16kHz\n",
    "    - /Audio Same CloseMic: Audio files in WAV format recorded using the close-talk mic, sampled at 16kHz\n",
    "\n",
    "\n",
    "- Separate Room environment, files organized by speaker number and session number:\n",
    "    - /Scripts Separate: Orthographic transcripts saved in TextGrid format \n",
    "    - /Audio Separate IVR: Audio files in WAV format recorded using the telephone, sampled at 16kHz\n",
    "    - /Audio Separate StandingMic: Audio files in WAV format recorded using the standing mic, sampled at 16kHz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Iteration 1: Simple Example/Debugging**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Match 3000-1.wav and 3000-1.TEXTGRID**\n",
    "\n",
    "- Use Dataset Part 3 (used by Home Team)\n",
    "- Specific datasets (used by Home Team)\n",
    "    - Audio Same CloseMic\n",
    "    - Audio Separate StandingMic \n",
    "- In this simple example, first settle the Audio Same CloseMic dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Create 30s segments from 3000-1.wav and 3000-1.TEXTGRID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jiaaro/pydub#installation\n",
    "# https://github.com/timmahrt/praatIO/tree/main\n",
    "\n",
    "import os\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Initialise input and output paths\n",
    "audio_path = os.path.join(os.getcwd(), 'dataset', 'part3', 'simple_example', '3000-1.wav')\n",
    "textgrid_path = os.path.join(os.getcwd(), 'dataset', 'part3', 'simple_example', '3000-1.TextGrid')\n",
    "output_dir = os.path.join(os.getcwd(), 'dataset', 'part3', 'simple_example', '3000-1-splits')\n",
    "\n",
    "# https://github.com/jiaaro/pydub\n",
    "# https://github.com/timmahrt/praatIO\n",
    "# https://timmahrt.github.io/praatIO/praatio.html\n",
    "audio = AudioSegment.from_wav(audio_path)\n",
    "tg = textgrid.openTextgrid(textgrid_path, False) # do not include intervals and points with empty labels\n",
    "\n",
    "# pydub does things in milliseconds\n",
    "segment_duration_ms = 30 * 1000  \n",
    "\n",
    "# Get total duration of the audio in milliseconds\n",
    "audio_duration = len(audio)\n",
    "\n",
    "# Initialize start time and segment index\n",
    "start_time = 0\n",
    "segment_index = 1\n",
    "\n",
    "#while start_time < audio_duration:\n",
    "    # Initialise end time of the segment\n",
    "end_time = min(start_time + segment_duration_ms, audio_duration)\n",
    "\n",
    "# Extract audio segment given the current start and end timing\n",
    "audio_segment = audio[start_time:end_time]\n",
    "\n",
    "# Save the audio segment\n",
    "audio_segment_path = os.path.join(output_dir, f'segment_{segment_index}.wav')\n",
    "audio_segment.export(audio_segment_path, format=\"wav\")\n",
    "\n",
    "# Extract the corresponding TextGrid segment\n",
    "# https://timmahrt.github.io/praatIO/praatio/data_classes/textgrid.html\n",
    "tg_segment = tg.crop(start_time / 1000, end_time / 1000, mode=\"truncated\", rebaseToZero=False)\n",
    "\n",
    "# Check tg_segment \n",
    "# https://timmahrt.github.io/praatIO/praatio/data_classes/textgrid.html\n",
    "tg_segment_path = os.path.join(output_dir, 'tg_segment.TextGrid')\n",
    "tg_segment.save(tg_segment_path, \"long_textgrid\", True)\n",
    "\n",
    "# Collect transcriptions from the TextGrid segment\n",
    "transcriptions = []\n",
    "for tier_name in tg_segment.tierNames: # For each tier (in order) in the TextGrid segment\n",
    "    tier = tg_segment.getTier(tier_name) # Get the tier\n",
    "    for entry in tier.entries: # For each of its entries, extract the labels \n",
    "        if entry.label.strip():  # Only include non-empty transcriptions -> but should be handled above already\n",
    "            transcriptions.append(entry.label)\n",
    "\n",
    "# Save the transcriptions to a text file\n",
    "transcription_path = os.path.join(output_dir, f'segment_{segment_index}_transcription.txt')\n",
    "with open(transcription_path, 'w') as f:\n",
    "    f.write(\"\\n\".join(transcriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_audio = os.path.join(output_dir, 'segment_1.wav')\n",
    "\n",
    "from IPython.display import Audio\n",
    "display(Audio(output_dir_audio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transcription**\n",
    "```\n",
    "<S>\n",
    "(um) you can go first\n",
    "<S>\n",
    "you guys are going to stand here [ah]\n",
    "<S>\n",
    "they are like !wow! this is a weird topic (um)\n",
    "<S>\n",
    "Singapore and Malaysia are like\n",
    "<S>\n",
    "you know brothers but not really brothers brothers on a on a tricky relationship\n",
    "<S>\n",
    "you know what let's skip this topic\n",
    "<S>\n",
    "next do I go do I go next\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TextGrid**\n",
    "```\n",
    "File type = \"ooTextFile\"\n",
    "Object class = \"TextGrid\"\n",
    "\n",
    "xmin = 0 \n",
    "xmax = 30 \n",
    "tiers? <exists> \n",
    "size = 1 \n",
    "item []: \n",
    "    item [1]:\n",
    "        class = \"IntervalTier\" \n",
    "        name = \"3000-1\" \n",
    "        xmin = 0 \n",
    "        xmax = 30 \n",
    "        intervals: size = 14 \n",
    "        intervals [1]:\n",
    "            xmin = 0 \n",
    "            xmax = 1.556 \n",
    "            text = \"<S>\" \n",
    "        intervals [2]:\n",
    "            xmin = 1.556 \n",
    "            xmax = 2.661 \n",
    "            text = \"(um) you can go first\" \n",
    "        intervals [3]:\n",
    "            xmin = 2.661 \n",
    "            xmax = 3.848 \n",
    "            text = \"<S>\" \n",
    "        intervals [4]:\n",
    "            xmin = 3.848 \n",
    "            xmax = 4.998 \n",
    "            text = \"you guys are going to stand here [ah]\" \n",
    "        intervals [5]:\n",
    "            xmin = 4.998 \n",
    "            xmax = 10.473 \n",
    "            text = \"<S>\" \n",
    "        intervals [6]:\n",
    "            xmin = 10.473 \n",
    "            xmax = 13.531 \n",
    "            text = \"they are like !wow! this is a weird topic (um)\" \n",
    "        intervals [7]:\n",
    "            xmin = 13.531 \n",
    "            xmax = 16.156 \n",
    "            text = \"<S>\" \n",
    "        intervals [8]:\n",
    "            xmin = 16.156 \n",
    "            xmax = 17.868 \n",
    "            text = \"Singapore and Malaysia are like\" \n",
    "        intervals [9]:\n",
    "            xmin = 17.868 \n",
    "            xmax = 19.781 \n",
    "            text = \"<S>\" \n",
    "        intervals [10]:\n",
    "            xmin = 19.781 \n",
    "            xmax = 24.718 \n",
    "            text = \"you know brothers but not really brothers brothers on a on a tricky relationship\" \n",
    "        intervals [11]:\n",
    "            xmin = 24.718 \n",
    "            xmax = 26.281 \n",
    "            text = \"<S>\" \n",
    "        intervals [12]:\n",
    "            xmin = 26.281 \n",
    "            xmax = 27.318 \n",
    "            text = \"you know what let's skip this topic\" \n",
    "        intervals [13]:\n",
    "            xmin = 27.318 \n",
    "            xmax = 28.156 \n",
    "            text = \"<S>\" \n",
    "        intervals [14]:\n",
    "            xmin = 28.156 \n",
    "            xmax = 30 \n",
    "            text = \"next do I go do I go next\" \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Clean and format the transcripts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_transcript = os.path.join(output_dir, 'segment_1_transcription.txt')\n",
    "\n",
    "with open(output_dir_transcript, 'r') as f:\n",
    "    transcript = ' '.join(line.strip() for line in f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Cleaning</u>\n",
    "\n",
    "1. Lower-case the text\n",
    "\n",
    "2. Remove and replace annotations\n",
    "\n",
    "- Acronyms: Remove '_'\n",
    "- Multi-word nouns: Replace '-' with ' '\n",
    "- Discourse particles: Remove '[' and ']'\n",
    "- Fillers: Remove '(' and ')'\n",
    "- Interjections: Remove '!'\n",
    "- Paralinguistic Phenomena: Remove '(ppb)', '(ppc)', '(ppl)', '(ppo)'\n",
    "- Other languages: Remove '#'\n",
    "- Unclear words: Remove ```'<unk>'```\n",
    "- Incomplete words: Remove '~'\n",
    "- Short pauses: Remove ```'<s>'```\n",
    "- Invalid: Remove ```'<z>'```\n",
    "- Long-running non-english utterances: Remove ```'<nen>'```\n",
    "- Fillers: Remove ```'<fil/>'```\n",
    "- Speaker Noise: Remove ```'<spk/>'```\n",
    "- Unknown: Remove '**'\n",
    "- Non-primary speaker sound: Remove ```'<non/>'```\n",
    "- End of sentence: Remove ```'<s/>'```\n",
    "- Comma: Remove ```'<c/>'```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "transcript = transcript.lower()\n",
    "\n",
    "remove = [r'_', r'\\[|\\]', r'\\(|\\)', r'!', r'\\(ppb\\)|\\(ppc\\)|\\(ppl\\)|\\(ppo\\)', \n",
    "          r'#', r'<unk>', r'~', r'<s>', r'<z>', r'<nen>', r'<fil/>', r'<spk/>',\n",
    "          r'\\*', r'<non/>', r'<s/>', r'<c/>']\n",
    "\n",
    "replace = ['-']\n",
    "\n",
    "\n",
    "for e in remove:\n",
    "    transcript = re.sub(e, '', transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in replace:\n",
    "    transcript = re.sub(e, ' ', transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra spaces created by <s> and stuff\n",
    "transcript = re.sub(r'\\s+', ' ', transcript).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need to change the order** \n",
    "\n",
    "(ppl) (ppb) etc. should be put infront because if the parantheses are removed, they won't be matched later\n",
    "\n",
    "Also need to remove all ```<example_word>```, example: ```<malay>malay word</malay>```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = ['(ppl)','(test)','sfs','(rdg)', 'tg_s']\n",
    "testing_2 = ' '.join(test.strip() for test in testing)\n",
    "remove = [r'\\(ppb\\)|\\(ppc\\)|\\(ppl\\)|\\(ppo\\)', r'_', r'\\[|\\]', r'\\(|\\)', r'!', \n",
    "            r'#', r'<unk>', r'~', r'<s>', r'<z>', r'<nen>', r'<fil/>', r'<spk/>',\n",
    "            r'\\*', r'<non/>', r'<s/>', r'<c/>']\n",
    "for e in remove:\n",
    "    testing_2 = re.sub(e, '', testing_2)\n",
    "testing_2 = re.sub(r'\\s+', ' ', testing_2).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jiaaro/pydub#installation\n",
    "# https://github.com/timmahrt/praatIO/tree/main\n",
    "\n",
    "import os\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Initialise input and output paths\n",
    "audio_path = os.path.join(os.getcwd(), 'dataset', 'part3', 'simple_example', '3000-1.wav')\n",
    "textgrid_path = os.path.join(os.getcwd(), 'dataset', 'part3', 'simple_example', '3000-1.TextGrid')\n",
    "output_dir = os.path.join(os.getcwd(), 'dataset', 'part3', 'simple_example', '3000-1-splits')\n",
    "\n",
    "# https://github.com/jiaaro/pydub\n",
    "# https://github.com/timmahrt/praatIO\n",
    "# https://timmahrt.github.io/praatIO/praatio.html\n",
    "audio = AudioSegment.from_wav(audio_path)\n",
    "tg = textgrid.openTextgrid(textgrid_path, False) # do not include intervals and points with empty labels\n",
    "\n",
    "# pydub does things in milliseconds\n",
    "segment_duration_ms = 30 * 1000  \n",
    "\n",
    "# Get total duration of the audio in milliseconds\n",
    "audio_duration = len(audio)\n",
    "\n",
    "# Initialize start time and segment index\n",
    "start_time = 0\n",
    "segment_index = 1\n",
    "\n",
    "#while start_time < audio_duration:\n",
    "    # Initialise end time of the segment\n",
    "end_time = min(start_time + segment_duration_ms, audio_duration)\n",
    "\n",
    "# Extract audio segment given the current start and end timing\n",
    "audio_segment = audio[start_time:end_time]\n",
    "\n",
    "# Save the audio segment\n",
    "audio_segment_path = os.path.join(output_dir, f'segment_{segment_index}.wav')\n",
    "audio_segment.export(audio_segment_path, format=\"wav\")\n",
    "\n",
    "# Extract the corresponding TextGrid segment\n",
    "# https://timmahrt.github.io/praatIO/praatio/data_classes/textgrid.html\n",
    "tg_segment = tg.crop(start_time / 1000, end_time / 1000, mode=\"truncated\", rebaseToZero=False)\n",
    "\n",
    "# Check tg_segment \n",
    "# https://timmahrt.github.io/praatIO/praatio/data_classes/textgrid.html\n",
    "tg_segment_path = os.path.join(output_dir, 'tg_segment.TextGrid')\n",
    "tg_segment.save(tg_segment_path, \"long_textgrid\", True)\n",
    "\n",
    "# Collect transcriptions from the TextGrid segment\n",
    "transcriptions = []\n",
    "for tier_name in tg_segment.tierNames: # For each tier (in order) in the TextGrid segment\n",
    "    tier = tg_segment.getTier(tier_name) # Get the tier\n",
    "    for entry in tier.entries: # For each of its entries, extract the labels \n",
    "        if entry.label.strip():  # Only include non-empty transcriptions -> but should be handled above already\n",
    "            transcriptions.append(entry.label)\n",
    "\n",
    "print(transcriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(line.strip() for line in transcriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcription(transcript):\n",
    "    transcript = ' '.join(line.strip() for line in transcript)\n",
    "\n",
    "    transcript = transcript.lower()\n",
    "\n",
    "    remove = [r'_', r'\\[|\\]', r'\\(|\\)', r'!', r'\\(ppb\\)|\\(ppc\\)|\\(ppl\\)|\\(ppo\\)', \n",
    "            r'#', r'<unk>', r'~', r'<s>', r'<z>', r'<nen>', r'<fil/>', r'<spk/>',\n",
    "            r'\\*', r'<non/>', r'<s/>', r'<c/>']\n",
    "\n",
    "    replace = ['-']\n",
    "\n",
    "\n",
    "    for e in remove:\n",
    "        transcript = re.sub(e, '', transcript)\n",
    "\n",
    "    for e in replace:\n",
    "        transcript = re.sub(e, ' ', transcript)\n",
    "\n",
    "    transcript = re.sub(r'\\s+', ' ', transcript).strip()\n",
    "\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_transcription(transcriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Things to check**\n",
    "- check out 3000-1_33: <malay>malay word</malay>\n",
    "- check out 3000-1_36: no transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Iteration 2: Check if the transcriptions are still ok**\n",
    "\n",
    "```\n",
    "- imda_nsc_p3.tar.gz\n",
    "    - imda_nsc_p3.tar\n",
    "        - train\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files\n",
    "            - waves\n",
    "                - 3000-1_1.wav\n",
    "                - 3000-1_2.wav\n",
    "                - 3000-1_3.wav\n",
    "- prompts-train.txt.gz\n",
    "    - prompts-train.txt: Contains transcriptions for all the train .wav files\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import os\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcription(transcript):\n",
    "    transcript = ' '.join(line.strip() for line in transcript)\n",
    "    transcript = transcript.lower()\n",
    "    remove = [r'\\(ppb\\)|\\(ppc\\)|\\(ppl\\)|\\(ppo\\)', r'_', r'\\[|\\]', r'\\(|\\)', r'!', \n",
    "            r'#', r'<unk>', r'~', r'<s>', r'<z>', r'<nen>', r'<fil/>', r'<spk/>',\n",
    "            r'\\*', r'<non/>', r'<s/>', r'<c/>', r'<[^>]+>'] # Addition: remove all instances of <whatever's inside>\n",
    "    replace = ['-']\n",
    "    for e in remove:\n",
    "        transcript = re.sub(e, '', transcript)\n",
    "    for e in replace:\n",
    "        transcript = re.sub(e, ' ', transcript)\n",
    "    transcript = re.sub(r'\\s+', ' ', transcript).strip()\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input paths\n",
    "audio_filename = '3000-2'\n",
    "\n",
    "audio_path = os.path.join(os.getcwd(), 'dataset', 'dev', 'org_wavs', f'{audio_filename}.wav')\n",
    "textgrid_path = os.path.join(os.getcwd(), 'dataset', 'dev', 'org_transcripts', f'{audio_filename}.TextGrid')\n",
    "\n",
    "# Output paths\n",
    "# output_dir_train_wav = os.path.join(os.getcwd(), 'dataset', 'imda_nsc_prototype', 'train', 'waves', f'{audio_filename}')\n",
    "output_dir_train_wav = os.path.join(os.getcwd(), 'dataset', 'dev', 'train', 'waves')\n",
    "os.makedirs(output_dir_train_wav, exist_ok=True)\n",
    "output_dir_train_text = os.path.join(os.getcwd(), 'dataset', 'dev', 'train', 'prompts.txt')\n",
    "output_dir_train_tg = os.path.join(os.getcwd(), 'dataset', 'dev', 'train', 'textgrids')\n",
    "\n",
    "# https://github.com/jiaaro/pydub\n",
    "# https://github.com/timmahrt/praatIO\n",
    "# https://timmahrt.github.io/praatIO/praatio.html\n",
    "# Extract the audio and text grid\n",
    "audio = AudioSegment.from_wav(audio_path)\n",
    "tg = textgrid.openTextgrid(textgrid_path, False) # do not include intervals and points with empty labels\n",
    "\n",
    "# pydub does things in milliseconds\n",
    "segment_duration_ms = 30 * 1000  \n",
    "\n",
    "# Get total duration of the audio in milliseconds\n",
    "audio_duration = len(audio)\n",
    "\n",
    "# Initialize start time and segment index\n",
    "start_time = 0\n",
    "segment_index = 1\n",
    "\n",
    "while start_time < audio_duration:\n",
    "    # Initialise end time of the segment\n",
    "    end_time = min(start_time + segment_duration_ms, audio_duration)\n",
    "\n",
    "    # Extract audio segment given the current start and end timing\n",
    "    audio_segment = audio[start_time:end_time]\n",
    "\n",
    "    # Extract the corresponding TextGrid segment\n",
    "    # https://timmahrt.github.io/praatIO/praatio/data_classes/textgrid.html\n",
    "    tg_segment = tg.crop(start_time / 1000, end_time / 1000, mode=\"truncated\", rebaseToZero=False)\n",
    "\n",
    "    tg_segment_path = os.path.join(output_dir_train_tg, f'{audio_filename}_{segment_index}.TextGrid')\n",
    "    tg_segment.save(tg_segment_path, \"long_textgrid\", True)\n",
    "\n",
    "    # Collect transcriptions from the TextGrid segment\n",
    "    transcriptions = []\n",
    "    for tier_name in tg_segment.tierNames: # For each tier (in order) in the TextGrid segment\n",
    "        tier = tg_segment.getTier(tier_name) # Get the tier\n",
    "        for entry in tier.entries: # For each of its entries, extract the labels \n",
    "            if entry.label.strip():  # Only include non-empty transcriptions -> but should be handled above already\n",
    "                transcriptions.append(entry.label)\n",
    "\n",
    "    print(f\"Dirty transcription: {transcriptions}\")\n",
    "    # Clean the transcriptions\n",
    "    transcriptions_clean = clean_transcription(transcriptions)\n",
    "    print(f\"Clean transcription: {transcriptions_clean}\")\n",
    "    #print(\"\")\n",
    "\n",
    "    if len(transcriptions_clean) > 0:\n",
    "        # Save the transcriptions to a text file, append mode\n",
    "        with open(output_dir_train_text, 'a') as f:\n",
    "            f.write(f'{audio_filename}_{segment_index} {transcriptions_clean}\\n')\n",
    "\n",
    "        # Save the audio segment\n",
    "        audio_segment_path = os.path.join(output_dir_train_wav, f'{audio_filename}_{segment_index}.wav')\n",
    "        audio_segment.export(audio_segment_path, format=\"wav\")\n",
    "\n",
    "        start_time+=segment_duration_ms\n",
    "        segment_index+=1\n",
    "    else:\n",
    "        start_time+=segment_duration_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**```tar.gz``` file resources**\n",
    "\n",
    "- https://stackoverflow.com/questions/2032403/how-to-create-full-compressed-tar-file-using-python\n",
    "- https://www.tutorialspoint.com/how-to-create-a-tar-file-using-python\n",
    "- https://www.geeksforgeeks.org/python-os-path-relpath-method/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**```txt.gz file resources```**\n",
    "- https://stackoverflow.com/questions/8156707/gzip-a-file-in-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**```folder structure resources```**\n",
    "- https://huggingface.co/docs/datasets/en/audio_dataset#loading-script\n",
    "- https://huggingface.co/datasets/AILAB-VNUHCM/vivos/tree/main/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Iteration 3: Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Before running processing code</u>\n",
    "```\n",
    "dataset\n",
    "- testing\n",
    "    - data: Empty\n",
    "    - org_waves: Manually add in .wav files\n",
    "        - 3000-1.wav\n",
    "        - 3000-2.wav\n",
    "        - ...\n",
    "    - org_transcripts: Manually add in .TextGrid files\n",
    "        - 3000-1.TextGrid\n",
    "        - 3000-2.TextGrid\n",
    "        - ...\n",
    "    - train\n",
    "        - waves: Empty\n",
    "        - transcripts: Empty\n",
    "    - test\n",
    "        - waves: Empty\n",
    "        - transcripts: Empty\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "<u>After running processing code</u>\n",
    "```\n",
    "dataset\n",
    "- testing\n",
    "    - data: Empty\n",
    "    - org_waves: Manually add in .wav files\n",
    "        - 3000-1.wav\n",
    "        - 3000-2.wav\n",
    "        - ...\n",
    "    - org_transcripts: Manually add in .TextGrid files\n",
    "        - 3000-1.TextGrid\n",
    "        - 3000-2.TextGrid\n",
    "        - ...\n",
    "    - train\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in train\n",
    "        - waves\n",
    "            - 3000-1_1.wav\n",
    "            - 3000-1_2.wav\n",
    "            - 3000-1_3.wav\n",
    "            - ...\n",
    "            - 3000-2_1.wav\n",
    "            - 3000-2_2.wav\n",
    "            - 3000-2_3.wav\n",
    "        - transcripts\n",
    "            - 3000-1_1.txt\n",
    "            - 3000-1_2.txt\n",
    "            - 3000-1_3.txt\n",
    "            - ...\n",
    "            - 3000-2_1.txt\n",
    "            - 3000-2_2.txt\n",
    "            - 3000-2_3.txt\n",
    "    - test\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in test\n",
    "        - waves\n",
    "            - 3000-3_1.wav\n",
    "            - 3000-3_2.wav\n",
    "            - 3000-3_3.wav\n",
    "            - ...\n",
    "            - 3000-4_1.wav\n",
    "            - 3000-4_2.wav\n",
    "            - 3000-4_3.wav\n",
    "        - transcripts\n",
    "            - 3000-3_1.txt\n",
    "            - 3000-3_2.txt\n",
    "            - 3000-3_3.txt\n",
    "            - ...\n",
    "            - 3000-4_1.txt\n",
    "            - 3000-4_2.txt\n",
    "            - 3000-4_3.txt\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "<u>After running compression code</u>\n",
    "\n",
    "```\n",
    "data\n",
    "    - input_name.tar.gz\n",
    "        - train\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files\n",
    "            - waves\n",
    "                - 3000-1_1.wav\n",
    "                - 3000-1_2.wav\n",
    "                - 3000-1_3.wav\n",
    "                - ...\n",
    "                - 3000-2_1.wav\n",
    "                - 3000-2_2.wav\n",
    "                - 3000-2_3.wav\n",
    "        - test\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files\n",
    "            - waves\n",
    "                - 3000-3_1.wav\n",
    "                - 3000-3_2.wav\n",
    "                - 3000-3_3.wav\n",
    "                - ...\n",
    "                - 3000-4_1.wav\n",
    "                - 3000-4_2.wav\n",
    "                - 3000-4_3.wav\n",
    "    - prompts-train.txt.gz\n",
    "        - prompts-train.txt: Contains transcriptions for all the train .wav files -> take this from train/prompts.txt\n",
    "    - prompts-test.txt.gz\n",
    "        - prompts-test.txt: Contains transcriptions for all the test .wav files -> take this from test/prompts.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import gzip\n",
    "import math\n",
    "import random\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Relative Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio_path = ['dataset', 'testing', 'org_wavs']\n",
    "input_textgrid_path = ['dataset', 'testing', 'org_transcripts']\n",
    "output_train_path = ['dataset', 'testing', 'train']\n",
    "output_test_path = ['dataset', 'testing', 'test']\n",
    "output_compressed_path = ['dataset', 'testing']\n",
    "compressed_filename = 'imda_nsc_p3_testing.tar.gz'\n",
    "compressed_train_prompt_filename = 'prompts-train.txt.gz'\n",
    "compressed_test_prompt_filename = 'prompts-test.txt.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialise Paths and Create the directories**\n",
    "\n",
    "**IMPT**: Remember to add in the ```.wav``` and ```.TextGrid``` files to org_waves and org_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wav_folder = os.path.join(os.getcwd(), *input_audio_path)\n",
    "input_textgrid_folder = os.path.join(os.getcwd(), *input_textgrid_path)\n",
    "output_train_folder_waves = os.path.join(os.getcwd(), *output_train_path, 'waves')\n",
    "output_train_folder_transcripts = os.path.join(os.getcwd(), *output_train_path, 'transcripts')\n",
    "output_test_folder_waves  = os.path.join(os.getcwd(), *output_test_path, 'waves')\n",
    "output_test_folder_transcripts = os.path.join(os.getcwd(), *output_test_path, 'transcripts')\n",
    "output_textgrids_folder = os.path.join(os.getcwd(), *output_train_path, 'textgrids')\n",
    "output_compressed_folder = os.path.join(os.getcwd(), *output_compressed_path, 'data')\n",
    "output_compressed_file = os.path.join(output_compressed_folder, compressed_filename)\n",
    "output_compressed_train_prompt_file = os.path.join(output_compressed_folder, compressed_train_prompt_filename)\n",
    "output_compressed_test_prompt_file = os.path.join(output_compressed_folder, compressed_test_prompt_filename)\n",
    "\n",
    "create_dir = [input_wav_folder, input_textgrid_folder, output_train_folder_waves, output_train_folder_transcripts,\n",
    "              output_test_folder_waves, output_test_folder_transcripts, output_textgrids_folder, output_compressed_folder]\n",
    "\n",
    "for dir in create_dir:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper function to clean the transcription**\n",
    "\n",
    "1. Lower-case the text\n",
    "\n",
    "2. Remove and replace annotations\n",
    "\n",
    "- Paralinguistic Phenomena: Remove '(ppb)', '(ppc)', '(ppl)', '(ppo)'\n",
    "- Acronyms: Remove '_'\n",
    "- Multi-word nouns: Replace '-' with ' '\n",
    "- Discourse particles: Remove '[' and ']'\n",
    "- Fillers: Remove '(' and ')'\n",
    "- Interjections: Remove '!'\n",
    "- Other languages: Remove '#'\n",
    "- Unclear words: Remove ```'<unk>'```\n",
    "- Incomplete words: Remove '~'\n",
    "- Short pauses: Remove ```'<s>'```\n",
    "- Invalid: Remove ```'<z>'```\n",
    "- Long-running non-english utterances: Remove ```'<nen>'```\n",
    "- Fillers: Remove ```'<fil/>'```\n",
    "- Speaker Noise: Remove ```'<spk/>'```\n",
    "- Unknown: Remove '**'\n",
    "- Non-primary speaker sound: Remove ```'<non/>'```\n",
    "- End of sentence: Remove ```'<s/>'```\n",
    "- Comma: Remove ```'<c/>'```\n",
    "- Remove all instances of ```<whatever is inside>```\n",
    "\n",
    "3. Remove extra spaces created by ```<s>``` and stuff\n",
    "\n",
    "Refer to the Transcription Guidelines by IMDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcription(transcript):\n",
    "    transcript = ' '.join(line.strip() for line in transcript)\n",
    "    transcript = transcript.lower()\n",
    "    remove = [r'\\(ppb\\)|\\(ppc\\)|\\(ppl\\)|\\(ppo\\)', r'_', r'\\[|\\]', r'\\(|\\)', r'!', \n",
    "            r'#', r'<unk>', r'~', r'<s>', r'<z>', r'<nen>', r'<fil/>', r'<spk/>',\n",
    "            r'\\*', r'<non/>', r'<s/>', r'<c/>', r'<[^>]+>'] \n",
    "    replace = ['-']\n",
    "    for e in remove:\n",
    "        transcript = re.sub(e, '', transcript)\n",
    "    for e in replace:\n",
    "        transcript = re.sub(e, ' ', transcript)\n",
    "    transcript = re.sub(r'\\s+', ' ', transcript).strip()\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main function**\n",
    "\n",
    "Matches a single ```.wav``` file to its respective ```.TextGrid``` file\n",
    "\n",
    "- Break the ```.wav``` file and ```.TextGrid``` file into 30s segments\n",
    "- Clean the ```.TextGrid``` file\n",
    "- Only keep segments that have audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_transcript(audio_filename, input_audio_path, input_textgrid_path, output_path, sanity_check=False):\n",
    "    audio_path = os.path.join(os.getcwd(), *input_audio_path, f'{audio_filename}.wav')\n",
    "    textgrid_path = os.path.join(os.getcwd(), *input_textgrid_path, f'{audio_filename}.TextGrid')\n",
    "\n",
    "    output_dir_wav = os.path.join(os.getcwd(), *output_path, 'waves')\n",
    "    output_dir_transcript = os.path.join(os.getcwd(), *output_path, 'transcripts')\n",
    "\n",
    "    output_dir_textgrid = os.path.join(os.getcwd(), *output_path, 'textgrids')\n",
    "\n",
    "    audio = AudioSegment.from_wav(audio_path)\n",
    "    tg = textgrid.openTextgrid(textgrid_path, False) \n",
    "\n",
    "    segment_duration_ms = 30 * 1000  \n",
    "\n",
    "    audio_duration = len(audio)\n",
    "\n",
    "    start_time = 0\n",
    "    segment_index = 1\n",
    "\n",
    "    while start_time < audio_duration:\n",
    "        end_time = min(start_time + segment_duration_ms, audio_duration)\n",
    "\n",
    "        audio_segment = audio[start_time:end_time]\n",
    "        tg_segment = tg.crop(start_time / 1000, end_time / 1000, mode=\"truncated\", rebaseToZero=False)\n",
    "\n",
    "        transcriptions = []\n",
    "        for tier_name in tg_segment.tierNames: \n",
    "            tier = tg_segment.getTier(tier_name) \n",
    "            for entry in tier.entries:  \n",
    "                if entry.label.strip():  \n",
    "                    transcriptions.append(entry.label)\n",
    "\n",
    "        transcriptions_clean = clean_transcription(transcriptions)\n",
    "\n",
    "        if len(transcriptions_clean) > 0:\n",
    "            transcript_segment_path = os.path.join(output_dir_transcript, f'{audio_filename}_{segment_index}.txt')\n",
    "            with open(transcript_segment_path, 'w') as f:\n",
    "                f.write(f'{audio_filename}_{segment_index} {transcriptions_clean}')\n",
    "\n",
    "            if sanity_check:\n",
    "                tg_segment_path = os.path.join(output_dir_textgrid, f'{audio_filename}_{segment_index}.TextGrid')\n",
    "                tg_segment.save(tg_segment_path, \"long_textgrid\", True)\n",
    "            \n",
    "            audio_segment_path = os.path.join(output_dir_wav, f'{audio_filename}_{segment_index}.wav')\n",
    "            audio_segment.export(audio_segment_path, format=\"wav\")\n",
    "\n",
    "            start_time+=segment_duration_ms\n",
    "            segment_index+=1\n",
    "        else:\n",
    "            start_time+=segment_duration_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the main function to segment 30s chunks for each ```.wav``` and ```.TextGrid``` file**\n",
    "\n",
    "Output is the segmented ```.wav``` files and transcriptions for each ```.wav``` file stored in ```train/waves``` and ```train/transcripts``` respectively\n",
    "\n",
    "Note: We first put the files into the train folder\n",
    "\n",
    "A sanity check can be set to True to view the segmented ```.TextGrid``` files in ```./train/textgrids/```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = os.path.join(os.getcwd(), *input_audio_path)\n",
    "for filename in os.listdir(audio_path):\n",
    "    filename = filename.split('.')[0]\n",
    "    process_audio_transcript(filename, input_audio_path, input_textgrid_path, output_train_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Move a split of the ```.wav``` files and ```.txt``` file to test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.2\n",
    "\n",
    "sample_filenames = []\n",
    "for filename in os.listdir(output_train_folder_waves):\n",
    "    sample_filenames.append(filename.split('.')[0])\n",
    "\n",
    "samples = len(sample_filenames)\n",
    "\n",
    "num_train_samples = math.floor((1-test_split)*samples)\n",
    "num_test_samples = samples-num_train_samples\n",
    "\n",
    "print(f\"The total number of samples is {samples}\")\n",
    "print(f\"The total number of training samples will be {num_train_samples}\")\n",
    "print(f\"The total number of test samples will be {num_test_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(sample_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_test_samples):\n",
    "    filename = sample_filenames[i]\n",
    "\n",
    "    source_wav = os.path.join(output_train_folder_waves, filename + '.wav')\n",
    "    destination_wav = os.path.join(output_test_folder_waves)\n",
    "    shutil.move(source_wav, destination_wav)\n",
    "\n",
    "    source_transcript = os.path.join(output_train_folder_transcripts, filename + '.txt')\n",
    "    destination_transcript = os.path.join(output_test_folder_transcripts)\n",
    "    shutil.move(source_transcript, destination_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write the ```/train/prompts.txt``` and ```/test/prompts.txt``` files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_path = os.path.join(os.getcwd(), *output_train_path, 'prompts.txt')\n",
    "with open(train_prompts_path, 'a') as outfile:\n",
    "    for filename in os.listdir(output_train_folder_transcripts):\n",
    "        file_path = os.path.join(output_train_folder_transcripts, filename)\n",
    "        with open(file_path, \"r\") as infile:\n",
    "            outfile.write(infile.read() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_path = os.path.join(os.getcwd(), *output_test_path, 'prompts.txt')\n",
    "with open(test_prompts_path, 'a') as outfile:\n",
    "    for filename in os.listdir(output_test_folder_transcripts):\n",
    "        file_path = os.path.join(output_test_folder_transcripts, filename)\n",
    "        with open(file_path, \"r\") as infile:\n",
    "            outfile.write(infile.read() + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compress the folders into ```.tar.gzip```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_compress = [train_prompts_path, output_train_folder_waves, test_prompts_path, output_test_folder_waves]\n",
    "\n",
    "with tarfile.open(output_compressed_file, \"w:gz\") as tar_gz:\n",
    "    for path in paths_to_compress:\n",
    "        rel_path = os.path.relpath(path, os.path.join(os.getcwd(), *output_compressed_path))\n",
    "        tar_gz.add(path, arcname=rel_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_prompts_path, 'rb') as f_in, gzip.open(output_compressed_train_prompt_file, 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_prompts_path, 'rb') as f_in, gzip.open(output_compressed_test_prompt_file, 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_prompts_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    train_prompts_filenames = sorted([l.split(' ')[0] for l in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wavs_filenames = []\n",
    "for filename in os.listdir(output_train_folder_waves):\n",
    "    filename = filename.split('.')[0]\n",
    "    train_wavs_filenames.append(filename)\n",
    "train_waves_filename = sorted(train_wavs_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_waves_filename[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_filenames==train_waves_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_prompts_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    test_prompts_filenames = sorted([l.split(' ')[0] for l in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wavs_filenames = []\n",
    "for filename in os.listdir(output_test_folder_waves):\n",
    "    filename = filename.split('.')[0]\n",
    "    test_wavs_filenames.append(filename)\n",
    "test_waves_filename = sorted(test_wavs_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wavs_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_filenames==test_wavs_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Iteration 4: How to fix overlap between some audio files and transcriptions**\n",
    "\n",
    "Example: \n",
    "\n",
    "3000-1_12 and 3000-1_13\n",
    "\n",
    "Audio at the end of 3000-1_12 includes 3/4-ish of text in ```intervals[22]```\n",
    "\n",
    "Audio at the start of 3000-1_13 includes 1/4-ish of text in ```intervals[1]```\n",
    "\n",
    "Solution: Segment based on TextGrid files instead of Audio files?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "<u>Initialising the directory</u>\n",
    "```\n",
    "dataset\n",
    "- testing\n",
    "    - data: Used to store compression files\n",
    "    - org_waves: Manually add in .wav files\n",
    "        - 3000-1.wav\n",
    "        - 3000-2.wav\n",
    "        - ...\n",
    "    - org_transcripts: Manually add in .TextGrid files\n",
    "        - 3000-1.TextGrid\n",
    "        - 3000-2.TextGrid\n",
    "        - ...\n",
    "    - train\n",
    "        - waves: Empty\n",
    "        - transcripts: Empty\n",
    "    - test\n",
    "        - waves: Empty\n",
    "        - transcripts: Empty\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Step 2:\n",
    "<u>After running the processing code</u>\n",
    "```\n",
    "dataset\n",
    "- testing\n",
    "    - data: Used to store compression files\n",
    "    - org_waves: Manually add in .wav files\n",
    "        - 3000-1.wav\n",
    "        - 3000-2.wav\n",
    "        - ...\n",
    "    - org_transcripts: Manually add in .TextGrid files\n",
    "        - 3000-1.TextGrid\n",
    "        - 3000-2.TextGrid\n",
    "        - ...\n",
    "    - train\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in train\n",
    "        - waves\n",
    "            - 3000-1_1.wav\n",
    "            - 3000-1_2.wav\n",
    "            - 3000-1_3.wav\n",
    "            - ...\n",
    "            - 3000-2_1.wav\n",
    "            - 3000-2_2.wav\n",
    "            - 3000-2_3.wav\n",
    "        - transcripts\n",
    "            - 3000-1_1.txt\n",
    "            - 3000-1_2.txt\n",
    "            - 3000-1_3.txt\n",
    "            - ...\n",
    "            - 3000-2_1.txt\n",
    "            - 3000-2_2.txt\n",
    "            - 3000-2_3.txt\n",
    "    - test\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in test\n",
    "        - waves\n",
    "            - 3000-3_1.wav\n",
    "            - 3000-3_2.wav\n",
    "            - 3000-3_3.wav\n",
    "            - ...\n",
    "            - 3000-4_1.wav\n",
    "            - 3000-4_2.wav\n",
    "            - 3000-4_3.wav\n",
    "        - transcripts\n",
    "            - 3000-3_1.txt\n",
    "            - 3000-3_2.txt\n",
    "            - 3000-3_3.txt\n",
    "            - ...\n",
    "            - 3000-4_1.txt\n",
    "            - 3000-4_2.txt\n",
    "            - 3000-4_3.txt\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Step 3:\n",
    "<u>After running the compression code</u>\n",
    "\n",
    "```\n",
    "data\n",
    "    - input_name.tar.gz\n",
    "        - train\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files\n",
    "            - waves\n",
    "                - 3000-1_1.wav\n",
    "                - 3000-1_2.wav\n",
    "                - 3000-1_3.wav\n",
    "                - ...\n",
    "                - 3000-2_1.wav\n",
    "                - 3000-2_2.wav\n",
    "                - 3000-2_3.wav\n",
    "        - test\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files\n",
    "            - waves\n",
    "                - 3000-3_1.wav\n",
    "                - 3000-3_2.wav\n",
    "                - 3000-3_3.wav\n",
    "                - ...\n",
    "                - 3000-4_1.wav\n",
    "                - 3000-4_2.wav\n",
    "                - 3000-4_3.wav\n",
    "    - prompts-train.txt.gz\n",
    "        - prompts-train.txt: Contains transcriptions for all the train .wav files -> take this from train/prompts.txt\n",
    "    - prompts-test.txt.gz\n",
    "        - prompts-test.txt: Contains transcriptions for all the test .wav files -> take this from test/prompts.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import gzip\n",
    "import math\n",
    "import random\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>USER INPUT REQUIRED</u> Input Relative Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio_path = ['dataset', 'testing', 'org_wavs']\n",
    "input_textgrid_path = ['dataset', 'testing', 'org_transcripts']\n",
    "output_train_path = ['dataset', 'testing', 'train']\n",
    "output_test_path = ['dataset', 'testing', 'test']\n",
    "output_compressed_path = ['dataset', 'testing']\n",
    "compressed_filename = 'imda_nsc_p3_testing.tar.gz'\n",
    "compressed_train_prompt_filename = 'prompts-train.txt.gz'\n",
    "compressed_test_prompt_filename = 'prompts-test.txt.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialise Paths and Create the directories**\n",
    "\n",
    "**IMPT <u>USER INPUT REQUIRED</u>**: Remember to add in the ```.wav``` and ```.TextGrid``` files to org_waves and org_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wav_folder = os.path.join(os.getcwd(), *input_audio_path)\n",
    "input_textgrid_folder = os.path.join(os.getcwd(), *input_textgrid_path)\n",
    "output_train_folder_waves = os.path.join(os.getcwd(), *output_train_path, 'waves')\n",
    "output_train_folder_transcripts = os.path.join(os.getcwd(), *output_train_path, 'transcripts')\n",
    "output_test_folder_waves  = os.path.join(os.getcwd(), *output_test_path, 'waves')\n",
    "output_test_folder_transcripts = os.path.join(os.getcwd(), *output_test_path, 'transcripts')\n",
    "output_textgrids_folder = os.path.join(os.getcwd(), *output_train_path, 'textgrids')\n",
    "output_compressed_folder = os.path.join(os.getcwd(), *output_compressed_path, 'data')\n",
    "output_compressed_file = os.path.join(output_compressed_folder, compressed_filename)\n",
    "output_compressed_train_prompt_file = os.path.join(output_compressed_folder, compressed_train_prompt_filename)\n",
    "output_compressed_test_prompt_file = os.path.join(output_compressed_folder, compressed_test_prompt_filename)\n",
    "\n",
    "create_dir = [input_wav_folder, input_textgrid_folder, output_train_folder_waves, output_train_folder_transcripts,\n",
    "              output_test_folder_waves, output_test_folder_transcripts, output_textgrids_folder, output_compressed_folder]\n",
    "\n",
    "for dir in create_dir:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper function to clean the transcription**\n",
    "\n",
    "1. Lower-case the text\n",
    "\n",
    "2. Remove and replace annotations\n",
    "\n",
    "- Paralinguistic Phenomena: Remove '(ppb)', '(ppc)', '(ppl)', '(ppo)'\n",
    "- Acronyms: Remove '_'\n",
    "- Multi-word nouns: Replace '-' with ' '\n",
    "- Discourse particles: Remove '[' and ']'\n",
    "- Fillers: Remove '(' and ')'\n",
    "- Interjections: Remove '!'\n",
    "- Other languages: Remove '#'\n",
    "- Unclear words: Remove ```'<unk>'```\n",
    "- Incomplete words: Remove '~'\n",
    "- Short pauses: Remove ```'<s>'```\n",
    "- Invalid: Remove ```'<z>'```\n",
    "- Long-running non-english utterances: Remove ```'<nen>'```\n",
    "- Fillers: Remove ```'<fil/>'```\n",
    "- Speaker Noise: Remove ```'<spk/>'```\n",
    "- Unknown: Remove '**'\n",
    "- Non-primary speaker sound: Remove ```'<non/>'```\n",
    "- End of sentence: Remove ```'<s/>'```\n",
    "- Comma: Remove ```'<c/>'```\n",
    "- Remove all instances of ```<whatever is inside>```\n",
    "\n",
    "3. Remove extra spaces created by ```<s>``` and stuff\n",
    "\n",
    "Refer to the Transcription Guidelines by IMDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcription(transcript):\n",
    "    transcript = ' '.join(line.strip() for line in transcript)\n",
    "    transcript = transcript.lower()\n",
    "    remove = [r'\\(ppb\\)|\\(ppc\\)|\\(ppl\\)|\\(ppo\\)', r'_', r'\\[|\\]', r'\\(|\\)', r'!', \n",
    "            r'#', r'<unk>', r'~', r'<s>', r'<z>', r'<nen>', r'<fil/>', r'<spk/>',\n",
    "            r'\\*', r'<non/>', r'<s/>', r'<c/>', r'<[^>]+>'] \n",
    "    replace = ['-']\n",
    "    for e in remove:\n",
    "        transcript = re.sub(e, '', transcript)\n",
    "    for e in replace:\n",
    "        transcript = re.sub(e, ' ', transcript)\n",
    "    transcript = re.sub(r'\\s+', ' ', transcript).strip()\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main function**\n",
    "\n",
    "Matches a single ```.wav``` file to its respective ```.TextGrid``` file\n",
    "\n",
    "- Break the ```.wav``` file and ```.TextGrid``` file into 30s segments\n",
    "- Clean the ```.TextGrid``` file\n",
    "- Only keep segments that have audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to fix overlap between some audio files and transcriptions**\n",
    "\n",
    "Example: \n",
    "\n",
    "3000-1_12 and 3000-1_13\n",
    "\n",
    "Audio at the end of 3000-1_12 includes 3/4-ish of text in ```intervals[22]```\n",
    "\n",
    "Audio at the start of 3000-1_13 includes 1/4-ish of text in ```intervals[1]```\n",
    "\n",
    "```\n",
    "input_textgrid_path = ['dataset', 'testing', 'org_transcripts']\n",
    "test_textgrid_path = os.path.join(os.getcwd(), *input_textgrid_path, '3000-1.TextGrid')\n",
    "tg_test = textgrid.openTextgrid(test_textgrid_path, False) \n",
    "\n",
    "for tier_name in tg_test.tierNames: \n",
    "    print(tier_name)\n",
    "\n",
    ">>> 3000-1\n",
    "\n",
    "for tier_name in tg_test.tierNames: \n",
    "    tier = tg_test.getTier(tier_name) \n",
    "    for entry in tier.entries:  \n",
    "        print(entry)\n",
    "\n",
    ">>> Interval(start=0.0, end=1.556, label='<S>')\n",
    ">>> Interval(start=1.556, end=2.661, label='(um) you can go first')\n",
    ">>>...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_transcript(audio_filename, input_audio_path, input_textgrid_path, output_path, sanity_check=False):\n",
    "    audio_path = os.path.join(os.getcwd(), *input_audio_path, f'{audio_filename}.wav')\n",
    "    textgrid_path = os.path.join(os.getcwd(), *input_textgrid_path, f'{audio_filename}.TextGrid')\n",
    "\n",
    "    output_dir_wav = os.path.join(os.getcwd(), *output_path, 'waves')\n",
    "    output_dir_transcript = os.path.join(os.getcwd(), *output_path, 'transcripts')\n",
    "\n",
    "    output_dir_textgrid = os.path.join(os.getcwd(), *output_path, 'textgrids')\n",
    "\n",
    "    audio = AudioSegment.from_wav(audio_path)\n",
    "    tg = textgrid.openTextgrid(textgrid_path, False) \n",
    "\n",
    "    # Specify the duration of each segment\n",
    "    segment_duration_s = 30 \n",
    "    # Specify the current segment duration\n",
    "    curr_segment_duration = 0\n",
    "    # Specify the current segment index\n",
    "    segment_index = 1\n",
    "    # Specify the timestamps traversed for the current segment\n",
    "    curr_timestamps = []\n",
    "    # Specify the transcriptions for the current segment\n",
    "    curr_transcriptions = []\n",
    "\n",
    "    for tier_name in tg.tierNames: \n",
    "        tier = tg.getTier(tier_name) \n",
    "        for start,end,label in tier.entries:  \n",
    "            # Get the duration of this new entry\n",
    "            entry_duration = end-start\n",
    "            # If the addition of this new entry to the current segment duration does not exceed\n",
    "            # our specified duration of each segment, we can accumulate the current segment\n",
    "            if curr_segment_duration + entry_duration <= segment_duration_s:\n",
    "                # Update the current_segment_duration\n",
    "                curr_segment_duration+=entry_duration\n",
    "                # Update the timestamps and transcriptions\n",
    "                curr_timestamps.extend([start,end])\n",
    "                curr_transcriptions.append(label)\n",
    "\n",
    "            # If the addition of a new entry exceeds our specified duration of each segment\n",
    "            # that means the current segment is completed and\n",
    "            # we save the transcription and the segmented audio as well as\n",
    "            # perform resetting\n",
    "            else:\n",
    "                # Clean the transcription\n",
    "                curr_transcriptions_clean = clean_transcription(curr_transcriptions)\n",
    "                # If there are words after cleaning\n",
    "                if len(curr_transcriptions_clean) > 0:\n",
    "                    # Initialise the transcription segment path\n",
    "                    transcript_segment_path = os.path.join(output_dir_transcript, f'{audio_filename}_{segment_index}.txt')\n",
    "                    # Write the transcription to the transcription segment file\n",
    "                    with open(transcript_segment_path, 'w') as f:\n",
    "                        f.write(f'{audio_filename}_{segment_index} {curr_transcriptions_clean}')\n",
    "                    # Calculate the boundaries for the audio segment in ms\n",
    "                    segment_start = min(curr_timestamps)*1000\n",
    "                    segment_end = max(curr_timestamps)*1000\n",
    "\n",
    "                    # Sanity check on TextGrid Segments\n",
    "                    if sanity_check:\n",
    "                        tg_segment = tg.crop(segment_start / 1000, segment_end / 1000, mode=\"strict\", rebaseToZero=False)\n",
    "                        tg_segment_path = os.path.join(output_dir_textgrid, f'{audio_filename}_{segment_index}.TextGrid')\n",
    "                        tg_segment.save(tg_segment_path, \"long_textgrid\", True)\n",
    "\n",
    "                    # Segment the audio using the start and time from the TextGrid\n",
    "                    audio_segment = audio[segment_start:segment_end]\n",
    "\n",
    "                    # Save the audio segment\n",
    "                    audio_segment_path = os.path.join(output_dir_wav, f'{audio_filename}_{segment_index}.wav')\n",
    "                    audio_segment.export(audio_segment_path, format=\"wav\")\n",
    "\n",
    "                # Resetting\n",
    "                # If a single entry is <= than 30s\n",
    "                if entry_duration <= segment_duration_s:\n",
    "                    # Reset the current segment duration\n",
    "                    curr_segment_duration = entry_duration\n",
    "                    # Reset the current timestamps to include the start and end of this iteration\n",
    "                    curr_timestamps = [start,end]\n",
    "                    # Reset the current transcriptions to include the label of this iteration\n",
    "                    curr_transcriptions = [label]\n",
    "                # Skip the entry as a sample if it is > than 30s\n",
    "                else:\n",
    "                    # Reset the current segment duration\n",
    "                    curr_segment_duration = 0\n",
    "                    # Reset the current timestamps from empty\n",
    "                    curr_timestamps = []\n",
    "                    # Reset the current transcriptions from empty\n",
    "                    curr_transcriptions = []\n",
    "\n",
    "                # Increment the segment index only if there was transcriptions (and thus audio) to be saved\n",
    "                if len(curr_transcriptions_clean) > 0:\n",
    "                    # Increment the segment index\n",
    "                    segment_index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the main function to segment 30s chunks for each ```.wav``` and ```.TextGrid``` file**\n",
    "\n",
    "Output is the segmented ```.wav``` files and transcriptions for each ```.wav``` file stored in ```train/waves``` and ```train/transcripts``` respectively\n",
    "\n",
    "Note: We first put the files into the train folder\n",
    "\n",
    "A sanity check can be set to True to view the segmented ```.TextGrid``` files in ```./train/textgrids/```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = os.path.join(os.getcwd(), *input_audio_path)\n",
    "for filename in os.listdir(audio_path):\n",
    "    filename = filename.split('.')[0]\n",
    "    process_audio_transcript(filename, input_audio_path, input_textgrid_path, output_train_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Move a split of the ```.wav``` files and ```.txt``` file to test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.2\n",
    "\n",
    "sample_filenames = []\n",
    "for filename in os.listdir(output_train_folder_waves):\n",
    "    sample_filenames.append(filename.split('.')[0])\n",
    "\n",
    "samples = len(sample_filenames)\n",
    "\n",
    "num_train_samples = math.floor((1-test_split)*samples)\n",
    "num_test_samples = samples-num_train_samples\n",
    "\n",
    "print(f\"The total number of samples is {samples}\")\n",
    "print(f\"The total number of training samples will be {num_train_samples}\")\n",
    "print(f\"The total number of test samples will be {num_test_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(sample_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_test_samples):\n",
    "    filename = sample_filenames[i]\n",
    "\n",
    "    source_wav = os.path.join(output_train_folder_waves, filename + '.wav')\n",
    "    destination_wav = os.path.join(output_test_folder_waves)\n",
    "    shutil.move(source_wav, destination_wav)\n",
    "\n",
    "    source_transcript = os.path.join(output_train_folder_transcripts, filename + '.txt')\n",
    "    destination_transcript = os.path.join(output_test_folder_transcripts)\n",
    "    shutil.move(source_transcript, destination_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write the ```/train/prompts.txt``` and ```/test/prompts.txt``` files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_path = os.path.join(os.getcwd(), *output_train_path, 'prompts.txt')\n",
    "with open(train_prompts_path, 'a') as outfile:\n",
    "    for filename in os.listdir(output_train_folder_transcripts):\n",
    "        file_path = os.path.join(output_train_folder_transcripts, filename)\n",
    "        with open(file_path, \"r\") as infile:\n",
    "            outfile.write(infile.read() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_path = os.path.join(os.getcwd(), *output_test_path, 'prompts.txt')\n",
    "with open(test_prompts_path, 'a') as outfile:\n",
    "    for filename in os.listdir(output_test_folder_transcripts):\n",
    "        file_path = os.path.join(output_test_folder_transcripts, filename)\n",
    "        with open(file_path, \"r\") as infile:\n",
    "            outfile.write(infile.read() + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compress the folders into ```.tar.gzip```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_compress = [train_prompts_path, output_train_folder_waves, test_prompts_path, output_test_folder_waves]\n",
    "\n",
    "with tarfile.open(output_compressed_file, \"w:gz\") as tar_gz:\n",
    "    for path in paths_to_compress:\n",
    "        rel_path = os.path.relpath(path, os.path.join(os.getcwd(), *output_compressed_path))\n",
    "        tar_gz.add(path, arcname=rel_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_prompts_path, 'rb') as f_in, gzip.open(output_compressed_train_prompt_file, 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_prompts_path, 'rb') as f_in, gzip.open(output_compressed_test_prompt_file, 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_prompts_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    train_prompts_filenames = sorted([l.split(' ')[0] for l in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wavs_filenames = []\n",
    "for filename in os.listdir(output_train_folder_waves):\n",
    "    filename = filename.split('.')[0]\n",
    "    train_wavs_filenames.append(filename)\n",
    "train_waves_filename = sorted(train_wavs_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_waves_filename[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_filenames==train_waves_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_prompts_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    test_prompts_filenames = sorted([l.split(' ')[0] for l in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wavs_filenames = []\n",
    "for filename in os.listdir(output_test_folder_waves):\n",
    "    filename = filename.split('.')[0]\n",
    "    test_wavs_filenames.append(filename)\n",
    "test_waves_filename = sorted(test_wavs_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wavs_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_filenames==test_wavs_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Iteration 5: Segment audio to only include main speakers speech**\n",
    "\n",
    "Example: \n",
    "\n",
    "3000-1_27 previously from Iteration 4\n",
    "\n",
    "There was people (the non-main speaker) talking. For training, the ground truth from iteration 4 only includes the main speaker's speech but this is unfair to the ASR because it may transcribe the non-main speaker's speech as well which affects training and evaluation\n",
    "\n",
    "Solution: Segment based on entry and only if the entry has proper ground truth transcriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "<u>Initialising the directory</u>\n",
    "```\n",
    "dataset\n",
    "- testing\n",
    "    - data: Used to store compression files\n",
    "    - org_waves: Manually add in .wav files to be segmented\n",
    "        - 3000-1.wav\n",
    "        - 3000-2.wav\n",
    "        - ...\n",
    "    - org_transcripts: Manually add in .TextGrid files to be segmented\n",
    "        - 3000-1.TextGrid\n",
    "        - 3000-2.TextGrid\n",
    "        - ...\n",
    "    - train\n",
    "        - waves: Empty\n",
    "        - transcripts: Empty\n",
    "    - test\n",
    "        - waves: Empty\n",
    "        - transcripts: Empty\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Step 2:\n",
    "<u>After running the processing code</u>\n",
    "```\n",
    "dataset\n",
    "- testing\n",
    "    - data: Used to store compression files\n",
    "    - org_waves: Manually add in .wav files\n",
    "        - 3000-1.wav\n",
    "        - 3000-2.wav\n",
    "        - ...\n",
    "    - org_transcripts: Manually add in .TextGrid files\n",
    "        - 3000-1.TextGrid\n",
    "        - 3000-2.TextGrid\n",
    "        - ...\n",
    "    - train\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in train\n",
    "        - waves\n",
    "            - 3000-1_1.wav\n",
    "            - 3000-1_2.wav\n",
    "            - 3000-1_3.wav\n",
    "            - ...\n",
    "            - 3000-2_1.wav\n",
    "            - 3000-2_2.wav\n",
    "            - 3000-2_3.wav\n",
    "        - transcripts\n",
    "            - 3000-1_1.txt\n",
    "            - 3000-1_2.txt\n",
    "            - 3000-1_3.txt\n",
    "            - ...\n",
    "            - 3000-2_1.txt\n",
    "            - 3000-2_2.txt\n",
    "            - 3000-2_3.txt\n",
    "    - test\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in test\n",
    "        - waves\n",
    "            - 3000-3_1.wav\n",
    "            - 3000-3_2.wav\n",
    "            - 3000-3_3.wav\n",
    "            - ...\n",
    "            - 3000-4_1.wav\n",
    "            - 3000-4_2.wav\n",
    "            - 3000-4_3.wav\n",
    "        - transcripts\n",
    "            - 3000-3_1.txt\n",
    "            - 3000-3_2.txt\n",
    "            - 3000-3_3.txt\n",
    "            - ...\n",
    "            - 3000-4_1.txt\n",
    "            - 3000-4_2.txt\n",
    "            - 3000-4_3.txt\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Step 3:\n",
    "<u>After running the compression code</u>\n",
    "\n",
    "```\n",
    "data\n",
    "    - input_name.tar.gz\n",
    "        - train\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files in train\n",
    "            - waves\n",
    "                - 3000-1_1.wav\n",
    "                - 3000-1_2.wav\n",
    "                - 3000-1_3.wav\n",
    "                - ...\n",
    "                - 3000-2_1.wav\n",
    "                - 3000-2_2.wav\n",
    "                - 3000-2_3.wav\n",
    "        - test\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files in test\n",
    "            - waves\n",
    "                - 3000-3_1.wav\n",
    "                - 3000-3_2.wav\n",
    "                - 3000-3_3.wav\n",
    "                - ...\n",
    "                - 3000-4_1.wav\n",
    "                - 3000-4_2.wav\n",
    "                - 3000-4_3.wav\n",
    "    - prompts-train.txt.gz\n",
    "        - prompts-train.txt: Contains transcriptions for all the train .wav files -> taken from train/prompts.txt\n",
    "    - prompts-test.txt.gz\n",
    "        - prompts-test.txt: Contains transcriptions for all the test .wav files -> take from test/prompts.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import gzip\n",
    "import math\n",
    "import random\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>USER INPUT REQUIRED</u> Input Relative Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio_path = ['dataset', 'testing', 'org_wavs']\n",
    "input_textgrid_path = ['dataset', 'testing', 'org_transcripts']\n",
    "output_train_path = ['dataset', 'testing', 'train']\n",
    "output_test_path = ['dataset', 'testing', 'test']\n",
    "output_compressed_path = ['dataset', 'testing']\n",
    "compressed_filename = 'imda_nsc_p3_testing.tar.gz'\n",
    "compressed_train_prompt_filename = 'prompts-train.txt.gz'\n",
    "compressed_test_prompt_filename = 'prompts-test.txt.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialise Paths and Create the directories**\n",
    "\n",
    "**IMPT <u>USER INPUT REQUIRED</u>**: Remember to add in the ```.wav``` and ```.TextGrid``` files to org_waves and org_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wav_folder = os.path.join(os.getcwd(), *input_audio_path)\n",
    "input_textgrid_folder = os.path.join(os.getcwd(), *input_textgrid_path)\n",
    "output_train_folder_waves = os.path.join(os.getcwd(), *output_train_path, 'waves')\n",
    "output_train_folder_transcripts = os.path.join(os.getcwd(), *output_train_path, 'transcripts')\n",
    "output_test_folder_waves  = os.path.join(os.getcwd(), *output_test_path, 'waves')\n",
    "output_test_folder_transcripts = os.path.join(os.getcwd(), *output_test_path, 'transcripts')\n",
    "output_textgrids_folder = os.path.join(os.getcwd(), *output_train_path, 'textgrids')\n",
    "output_compressed_folder = os.path.join(os.getcwd(), *output_compressed_path, 'data')\n",
    "output_compressed_file = os.path.join(output_compressed_folder, compressed_filename)\n",
    "output_compressed_train_prompt_file = os.path.join(output_compressed_folder, compressed_train_prompt_filename)\n",
    "output_compressed_test_prompt_file = os.path.join(output_compressed_folder, compressed_test_prompt_filename)\n",
    "\n",
    "create_dir = [input_wav_folder, input_textgrid_folder, output_train_folder_waves, output_train_folder_transcripts,\n",
    "              output_test_folder_waves, output_test_folder_transcripts, output_textgrids_folder, output_compressed_folder]\n",
    "\n",
    "for dir in create_dir:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper function to clean the transcription**\n",
    "\n",
    "1. Lower-case the text\n",
    "\n",
    "2. Remove and replace annotations\n",
    "\n",
    "- Paralinguistic Phenomena: Remove '(ppb)', '(ppc)', '(ppl)', '(ppo)'\n",
    "- Acronyms: Remove '_'\n",
    "- Multi-word nouns: Replace '-' with ' '\n",
    "- Discourse particles: Remove '[' and ']'\n",
    "- Fillers: Remove '(' and ')'\n",
    "- Interjections: Remove '!'\n",
    "- Other languages: Remove '#'\n",
    "- Unclear words: Remove ```'<unk>'```\n",
    "- Incomplete words: Remove '~'\n",
    "- Short pauses: Remove ```'<s>'```\n",
    "- Invalid: Remove ```'<z>'```\n",
    "- Long-running non-english utterances: Remove ```'<nen>'```\n",
    "- Fillers: Remove ```'<fil/>'```\n",
    "- Speaker Noise: Remove ```'<spk/>'```\n",
    "- Unknown: Remove '**'\n",
    "- Non-primary speaker sound: Remove ```'<non/>'```\n",
    "- End of sentence: Remove ```'<s/>'```\n",
    "- Comma: Remove ```'<c/>'```\n",
    "- Remove all instances of ```<whatever is inside>```\n",
    "\n",
    "3. Remove extra spaces created by ```<s>``` and stuff\n",
    "\n",
    "Refer to the Transcription Guidelines by IMDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcription(transcript):\n",
    "    transcript = transcript.strip()\n",
    "    transcript = transcript.lower()\n",
    "    remove = [r'\\(ppb\\)|\\(ppc\\)|\\(ppl\\)|\\(ppo\\)', r'_', r'\\[|\\]', r'\\(|\\)', r'!', \n",
    "            r'#', r'<unk>', r'~', r'<s>', r'<z>', r'<nen>', r'<fil/>', r'<spk/>',\n",
    "            r'\\*', r'<non/>', r'<s/>', r'<c/>', r'<[^>]+>'] \n",
    "    replace = ['-']\n",
    "    for e in remove:\n",
    "        transcript = re.sub(e, '', transcript)\n",
    "    for e in replace:\n",
    "        transcript = re.sub(e, ' ', transcript)\n",
    "    transcript = re.sub(r'\\s+', ' ', transcript).strip()\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main function**\n",
    "\n",
    "- Matches a single ```.wav``` file to its respective ```.TextGrid``` file\n",
    "\n",
    "- Break the ```.wav``` file and ```.TextGrid``` files into segments such that each segment only contains a transcription that is <= 30s long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_transcript(audio_filename, input_audio_path, input_textgrid_path, output_path, sanity_check=False):\n",
    "    audio_path = os.path.join(os.getcwd(), *input_audio_path, f'{audio_filename}.wav')\n",
    "    textgrid_path = os.path.join(os.getcwd(), *input_textgrid_path, f'{audio_filename}.TextGrid')\n",
    "\n",
    "    output_dir_wav = os.path.join(os.getcwd(), *output_path, 'waves')\n",
    "    output_dir_transcript = os.path.join(os.getcwd(), *output_path, 'transcripts')\n",
    "\n",
    "    output_dir_textgrid = os.path.join(os.getcwd(), *output_path, 'textgrids')\n",
    "\n",
    "    audio = AudioSegment.from_wav(audio_path)\n",
    "    tg = textgrid.openTextgrid(textgrid_path, False) \n",
    "\n",
    "    # Specify the duration of each segment\n",
    "    segment_duration_s = 30 \n",
    "    # Specify the current segment index\n",
    "    segment_index = 1\n",
    "\n",
    "    for tier_name in tg.tierNames: \n",
    "        tier = tg.getTier(tier_name) \n",
    "        for start,end,label in tier.entries:  \n",
    "            # Get the duration of this new entry\n",
    "            entry_duration = end-start\n",
    "            # If the entry's duration is less than our specified duration of each segment\n",
    "            if entry_duration <= segment_duration_s:\n",
    "                # Clean the transcription/label of this entry\n",
    "                curr_transcriptions_clean = clean_transcription(label)\n",
    "                # If this entry has text after cleaning i.e. contains proper ground truth transcription\n",
    "                if len(curr_transcriptions_clean) > 0:\n",
    "                    # Initialise the transcription segment path\n",
    "                    transcript_segment_path = os.path.join(output_dir_transcript, f'{audio_filename}_{segment_index}.txt')\n",
    "                    # Write the transcription to the transcription segment file\n",
    "                    with open(transcript_segment_path, 'w') as f:\n",
    "                        f.write(f'{audio_filename}_{segment_index} {curr_transcriptions_clean}')\n",
    "\n",
    "                    # Calculate the boundaries for the audio segment in ms\n",
    "                    segment_start = start*1000\n",
    "                    segment_end = end*1000\n",
    "\n",
    "                    # Sanity check on TextGrid Segments\n",
    "                    if sanity_check:\n",
    "                        tg_segment = tg.crop(segment_start / 1000, segment_end / 1000, mode=\"strict\", rebaseToZero=False)\n",
    "                        tg_segment_path = os.path.join(output_dir_textgrid, f'{audio_filename}_{segment_index}.TextGrid')\n",
    "                        tg_segment.save(tg_segment_path, \"long_textgrid\", True)\n",
    "\n",
    "                    # Segment the audio using the start and time from the current TextGrid entry\n",
    "                    audio_segment = audio[segment_start:segment_end+1] # Add 1 ms s.t the end timing is inclusive\n",
    "\n",
    "                    # Save the audio segment\n",
    "                    audio_segment_path = os.path.join(output_dir_wav, f'{audio_filename}_{segment_index}.wav')\n",
    "                    audio_segment.export(audio_segment_path, format=\"wav\")\n",
    "\n",
    "                    # Increment the segment index\n",
    "                    segment_index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the main function to create segments for each ```.wav``` and ```.TextGrid``` file**\n",
    "\n",
    "Output is the segmented ```.wav``` audio files and corresponding ```.txt``` transcription files that is stored in ```train/waves``` and ```train/transcripts``` respectively\n",
    "\n",
    "Note: We first put the files into the train folder\n",
    "\n",
    "A sanity check can be set to ```True``` to view the corresponding segmented ```.TextGrid``` files in ```./train/textgrids/```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = os.path.join(os.getcwd(), *input_audio_path)\n",
    "for filename in os.listdir(audio_path):\n",
    "    filename = filename.split('.')[0]\n",
    "    process_audio_transcript(filename, input_audio_path, input_textgrid_path, output_train_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Move a split of the ```.wav``` files and ```.txt``` file to test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.2\n",
    "\n",
    "sample_filenames = []\n",
    "for filename in os.listdir(output_train_folder_waves):\n",
    "    sample_filenames.append(filename.split('.')[0])\n",
    "\n",
    "samples = len(sample_filenames)\n",
    "\n",
    "num_train_samples = math.floor((1-test_split)*samples)\n",
    "num_test_samples = samples-num_train_samples\n",
    "\n",
    "print(f\"The total number of samples is {samples}\")\n",
    "print(f\"The total number of training samples will be {num_train_samples}\")\n",
    "print(f\"The total number of test samples will be {num_test_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(sample_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_test_samples):\n",
    "    filename = sample_filenames[i]\n",
    "\n",
    "    source_wav = os.path.join(output_train_folder_waves, filename + '.wav')\n",
    "    destination_wav = os.path.join(output_test_folder_waves)\n",
    "    shutil.move(source_wav, destination_wav)\n",
    "\n",
    "    source_transcript = os.path.join(output_train_folder_transcripts, filename + '.txt')\n",
    "    destination_transcript = os.path.join(output_test_folder_transcripts)\n",
    "    shutil.move(source_transcript, destination_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write the ```/train/prompts.txt``` and ```/test/prompts.txt``` files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_path = os.path.join(os.getcwd(), *output_train_path, 'prompts.txt')\n",
    "with open(train_prompts_path, 'a') as outfile:\n",
    "    for filename in os.listdir(output_train_folder_transcripts):\n",
    "        file_path = os.path.join(output_train_folder_transcripts, filename)\n",
    "        with open(file_path, \"r\") as infile:\n",
    "            outfile.write(infile.read() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_path = os.path.join(os.getcwd(), *output_test_path, 'prompts.txt')\n",
    "with open(test_prompts_path, 'a') as outfile:\n",
    "    for filename in os.listdir(output_test_folder_transcripts):\n",
    "        file_path = os.path.join(output_test_folder_transcripts, filename)\n",
    "        with open(file_path, \"r\") as infile:\n",
    "            outfile.write(infile.read() + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compress the folders into ```.tar.gzip```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_compress = [train_prompts_path, output_train_folder_waves, test_prompts_path, output_test_folder_waves]\n",
    "\n",
    "with tarfile.open(output_compressed_file, \"w:gz\") as tar_gz:\n",
    "    for path in paths_to_compress:\n",
    "        rel_path = os.path.relpath(path, os.path.join(os.getcwd(), *output_compressed_path))\n",
    "        tar_gz.add(path, arcname=rel_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_prompts_path, 'rb') as f_in, gzip.open(output_compressed_train_prompt_file, 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_prompts_path, 'rb') as f_in, gzip.open(output_compressed_test_prompt_file, 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_prompts_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    train_prompts_filenames = sorted([l.split(' ')[0] for l in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wavs_filenames = []\n",
    "for filename in os.listdir(output_train_folder_waves):\n",
    "    filename = filename.split('.')[0]\n",
    "    train_wavs_filenames.append(filename)\n",
    "train_waves_filename = sorted(train_wavs_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_waves_filename[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_filenames==train_waves_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_prompts_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    test_prompts_filenames = sorted([l.split(' ')[0] for l in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wavs_filenames = []\n",
    "for filename in os.listdir(output_test_folder_waves):\n",
    "    filename = filename.split('.')[0]\n",
    "    test_wavs_filenames.append(filename)\n",
    "test_waves_filename = sorted(test_wavs_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wavs_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_filenames==test_wavs_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Iteration 6: Fix error ```ParsingError: Expected field in Textgrid missing```**\n",
    "\n",
    "TODOs\n",
    "- Change input paths of non-hard drive file\n",
    "- Check why there is an error with the file\n",
    "- Combine the files into 30s?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of code flow\n",
    "\n",
    "### Step 1:\n",
    "<u>After running the code to initialise the directory</u>\n",
    "```\n",
    "D:\\\n",
    "- org_wavs: Manually add in .wav files to be segmented\n",
    "    - 3000-1.wav\n",
    "    - 3000-2.wav\n",
    "    - ...\n",
    "- org_transcripts: Manually add in .TextGrid files to be segmented\n",
    "    - 3000-1.TextGrid\n",
    "    - 3000-2.TextGrid\n",
    "    - ...\n",
    "\n",
    "dataset\n",
    "- data: Used to store compression files\n",
    "- train\n",
    "    - waves: Empty\n",
    "    - transcripts: Empty\n",
    "- test\n",
    "    - waves: Empty\n",
    "    - transcripts: Empty\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Step 2:\n",
    "<u>After running the processing code</u>\n",
    "```\n",
    "D:\\\n",
    "- org_wavs: Manually add in .wav files to be segmented\n",
    "    - 3000-1.wav\n",
    "    - 3000-2.wav\n",
    "    - ...\n",
    "- org_transcripts: Manually add in .TextGrid files to be segmented\n",
    "    - 3000-1.TextGrid\n",
    "    - 3000-2.TextGrid\n",
    "    - ...\n",
    "\n",
    "dataset\n",
    "- data: Used to store compression files\n",
    "- train\n",
    "    - prompts.txt: Contains transcriptions for all the .wav files in train\n",
    "    - waves\n",
    "        - 3000-1_1.wav\n",
    "        - 3000-1_2.wav\n",
    "        - 3000-1_3.wav\n",
    "        - ...\n",
    "        - 3000-2_1.wav\n",
    "        - 3000-2_2.wav\n",
    "        - 3000-2_3.wav\n",
    "    - transcripts\n",
    "        - 3000-1_1.txt\n",
    "        - 3000-1_2.txt\n",
    "        - 3000-1_3.txt\n",
    "        - ...\n",
    "        - 3000-2_1.txt\n",
    "        - 3000-2_2.txt\n",
    "        - 3000-2_3.txt\n",
    "- test\n",
    "    - prompts.txt: Contains transcriptions for all the .wav files in test\n",
    "    - waves\n",
    "        - 3000-3_1.wav\n",
    "        - 3000-3_2.wav\n",
    "        - 3000-3_3.wav\n",
    "        - ...\n",
    "        - 3000-4_1.wav\n",
    "        - 3000-4_2.wav\n",
    "        - 3000-4_3.wav\n",
    "    - transcripts\n",
    "        - 3000-3_1.txt\n",
    "        - 3000-3_2.txt\n",
    "        - 3000-3_3.txt\n",
    "        - ...\n",
    "        - 3000-4_1.txt\n",
    "        - 3000-4_2.txt\n",
    "        - 3000-4_3.txt\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Step 3:\n",
    "<u>After running the compression code</u>\n",
    "\n",
    "```\n",
    "data\n",
    "- imda_nsc_p3.tar.gz\n",
    "    - train\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in train\n",
    "        - waves\n",
    "            - 3000-1_1.wav\n",
    "            - 3000-1_2.wav\n",
    "            - 3000-1_3.wav\n",
    "            - ...\n",
    "            - 3000-2_1.wav\n",
    "            - 3000-2_2.wav\n",
    "            - 3000-2_3.wav\n",
    "    - test\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in test\n",
    "        - waves\n",
    "            - 3000-3_1.wav\n",
    "            - 3000-3_2.wav\n",
    "            - 3000-3_3.wav\n",
    "            - ...\n",
    "            - 3000-4_1.wav\n",
    "            - 3000-4_2.wav\n",
    "            - 3000-4_3.wav\n",
    "- prompts-train.txt.gz\n",
    "    - prompts-train.txt: Contains transcriptions for all the train .wav files -> taken from train/prompts.txt\n",
    "- prompts-test.txt.gz\n",
    "    - prompts-test.txt: Contains transcriptions for all the test .wav files -> take from test/prompts.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking file 3025-1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import gzip\n",
    "import math\n",
    "import random\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_textgrid_path = ['dataset', 'testing', 'org_transcripts']\n",
    "input_textgrid_folder = os.path.join(os.getcwd(), *input_textgrid_path)\n",
    "create_dir = [input_textgrid_folder]\n",
    "\n",
    "for dir in create_dir:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgrid_path = os.path.join(input_textgrid_folder, '3025-1-test-2.TextGrid')\n",
    "tg = textgrid.openTextgrid(textgrid_path, False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fails with the addition of \n",
    "\n",
    "```\n",
    "intervals [1115]:\n",
    "            xmin = 3925.5698506061176 \n",
    "            xmax = 3928.472 \n",
    "            text = \"to the item [lah] that that the that the owner has\"\n",
    "\n",
    "onwards\n",
    "```\n",
    "\n",
    "Conclusion: cannot have ```item [something]``` in the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\n",
    "\n",
    "```\n",
    "File type = \"ooTextFile\"\n",
    "Object class = \"TextGrid\"\n",
    "\n",
    "xmin = 0 \n",
    "xmax = 8245.897 \n",
    "tiers? <exists> \n",
    "size = 1 \n",
    "item []: \n",
    "    item [1]:\n",
    "        class = \"IntervalTier\" \n",
    "        name = \"3025-1\" \n",
    "        xmin = 0 \n",
    "        xmax = 8245.897 \n",
    "        intervals: size = 2603 \n",
    "        intervals [1]:\n",
    "            xmin = 0 \n",
    "            xmax = 2.706 \n",
    "            text = \"<S>\" \n",
    "        intervals [2]:\n",
    "            xmin = 2.706 \n",
    "            xmax = 4.018 \n",
    "            text = \"okay item [testing] hi Joshua\" \n",
    "        intervals [3]:\n",
    "            xmin = 4.018 \n",
    "            xmax = 6.268 \n",
    "            text = \"<S>\"\n",
    "```\n",
    "\n",
    "Probably because of the way the function ```praatIO/praatio/utilities/textgrid_io.py/_parseNormalTextgrid(data: str)``` segments: it splits on item and [ ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution 1: Remove all instances of the ```[,]``` in ```text = \"... item [something]...\"```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_restriction = r'text = \"(.*?item \\[.*?\\].*?)\"'\n",
    "test_text = 'text = \"to the item [lah] that that the that the owner has\"'\n",
    "\n",
    "def replace_brackets(match):\n",
    "    print(\"Match\")\n",
    "    print(match.group(0))\n",
    "    text_content = match.group(1)\n",
    "    text_content = text_content.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    return f'text = \"{text_content}\"'\n",
    "\n",
    "# Receives regex pattern, function to do replacement for matched patterns \n",
    "# (res of function is used as replacement text), input string where the replacement will occur\n",
    "\n",
    "# function receives a match object. It is called for each match found in the content string\n",
    "# match object represents a specific occurence of the matched pattern\n",
    "test_text_fixed = re.sub(text_restriction, replace_brackets, test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.join(input_textgrid_folder, '3025-1-test-2.TextGrid')\n",
    "output_path = os.path.join(input_textgrid_folder, '3025-1-test-2-fixed.TextGrid')\n",
    "\n",
    "# PraatIO seems to try utf-8 and utf-16\n",
    "try:\n",
    "    with open(input_path, \"r\", encoding=\"utf-16\") as file:\n",
    "        content = file.read()\n",
    "    encoding = \"utf-16\"\n",
    "except UnicodeError:\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "    encoding = \"utf-8\"\n",
    "\n",
    "print(\"The content is: \")\n",
    "print(content)\n",
    "print(\"\")\n",
    "\n",
    "text_restriction = r'text = \"(.*?item \\[.*?\\].*?)\"'\n",
    "\n",
    "def replace_brackets(match):\n",
    "    print(\"Match:\")\n",
    "    print(match)\n",
    "    print(\"Match group 0\")\n",
    "    print(match.group(0))\n",
    "    print(\"Match group 1\")\n",
    "    print(match.group(1))\n",
    "    text_content = match.group(1)\n",
    "    text_content = text_content.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    return f'text = \"{text_content}\"'\n",
    "\n",
    "content_fixed = re.sub(text_restriction, replace_brackets, content)\n",
    "\n",
    "with open(output_path, \"w\", encoding=encoding) as file:\n",
    "    file.write(content_fixed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test on 3025-1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_text_restriction(textgrid_path):\n",
    "    try:\n",
    "        with open(textgrid_path, \"r\", encoding=\"utf-16\") as file:\n",
    "            textgrid = file.read()\n",
    "        encoding = \"utf-16\"\n",
    "    except UnicodeError:\n",
    "        with open(textgrid_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            textgrid = file.read()\n",
    "        encoding = \"utf-8\"\n",
    "\n",
    "    text_restriction = r'text = \"(.*?item \\[.*?\\].*?)\"'\n",
    "\n",
    "    def replace_brackets(match):\n",
    "        print(\"Match:\")\n",
    "        print(match.group(0))\n",
    "        print(\"\")\n",
    "        text_content = match.group(1)\n",
    "        text_content = text_content.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        return f'text = \"{text_content}\"'\n",
    "\n",
    "    textgrid_fixed = re.sub(text_restriction, replace_brackets, textgrid)\n",
    "\n",
    "    with open(textgrid_path, \"w\", encoding=encoding) as file:\n",
    "        file.write(textgrid_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgrid_path = os.path.join(input_textgrid_folder, '3025-1.TextGrid')\n",
    "remove_text_restriction(textgrid_path)\n",
    "tg = textgrid.openTextgrid(textgrid_path, False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Iteration 7: Fix more TextGrid errors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import gzip\n",
    "import math\n",
    "import random\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>USER INPUT REQUIRED</u> Change Relative Paths and Naming Conventions if you want**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_transcripts_path = ['clean_textgrid', 'org_transcripts']\n",
    "testing_transcripts_path = ['clean_textgrid', 'testing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialise Paths and Create the directories**\n",
    "\n",
    "**<u>USER INPUT REQUIRED</u>**: Remember to add in the <u>original</u> ```.TextGrid``` files provided by IMDA NSC to ```org_transcripts``` in the directory below after running the code block below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_transcripts_folder = os.path.join(os.getcwd(), *org_transcripts_path)\n",
    "testing_transcripts_folder = os.path.join(os.getcwd(), *testing_transcripts_path)\n",
    "create_dir = [org_transcripts_folder,testing_transcripts_folder]\n",
    "\n",
    "for dir in create_dir:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper function to remove instances of ```text = \"...item [something]...\"``` from a single TextGrid file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_text_restriction(textgrid_path):\n",
    "    try:\n",
    "        with open(textgrid_path, \"r\", encoding=\"utf-16\") as file:\n",
    "            textgrid = file.read()\n",
    "        encoding = \"utf-16\"\n",
    "    except UnicodeError:\n",
    "        with open(textgrid_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            textgrid = file.read()\n",
    "        encoding = \"utf-8\"\n",
    "\n",
    "    text_restriction = r'text = \"(.*?item \\[.*?\\].*?)\"'\n",
    "\n",
    "    def replace_brackets(match):\n",
    "        print(textgrid_path)\n",
    "        print(\"Match:\")\n",
    "        print(match.group(0))\n",
    "        print(\"\")\n",
    "        text_content = match.group(1)\n",
    "        text_content = text_content.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        return f'text = \"{text_content}\"'\n",
    "\n",
    "    textgrid_fixed = re.sub(text_restriction, replace_brackets, textgrid)\n",
    "\n",
    "    with open(textgrid_path, \"w\", encoding=encoding) as file:\n",
    "        file.write(textgrid_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_successfully = []\n",
    "cleaned_unsuccessfully = []\n",
    "for filename in os.listdir(org_transcripts_folder):\n",
    "    try:\n",
    "        textgrid_path = os.path.join(org_transcripts_folder, filename)\n",
    "        tg = textgrid.openTextgrid(textgrid_path, False)\n",
    "    except:\n",
    "        remove_text_restriction(textgrid_path)\n",
    "        try:\n",
    "            tg = textgrid.openTextgrid(textgrid_path, False)\n",
    "            cleaned_successfully.append(filename)\n",
    "        except:\n",
    "            cleaned_unsuccessfully.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_unsuccessfully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File 3035-2**\n",
    "\n",
    "Conclusion: Skip it because the instantaneous timing and transcription don't match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '3035-2.TextGrid'\n",
    "textgrid_path = os.path.join(testing_transcripts_folder, filename)\n",
    "tg = textgrid.openTextgrid(textgrid_path, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "intervals [1216]:\n",
    "    xmin = 3059.354 \n",
    "    xmax = 3059.354 \n",
    "    text = \"that time got p_s_l_e or not\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File 3075-2**\n",
    "\n",
    "Conclusion: Skip it because the instantaneous timing and transcription don't match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '3075-2.TextGrid'\n",
    "textgrid_path = os.path.join(testing_transcripts_folder, filename)\n",
    "tg = textgrid.openTextgrid(textgrid_path, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "intervals [385]:\n",
    "    xmin = 894.703\n",
    "    xmax = 894.703\n",
    "    text = \"what is your [eh] what is a deal maker in your search for a partner\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File 3083-1**\n",
    "\n",
    "Conclusion: Account for ```text = \"...intervals [something]...\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '3083-1.TextGrid'\n",
    "textgrid_path = os.path.join(testing_transcripts_folder, filename)\n",
    "tg = textgrid.openTextgrid(textgrid_path, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found a ```text = \"<UNK ya the the bush is green\"```. Need to update cleaning to account for ```<UNK``` ? nevermind, feels like a rare occurence. removing ```< and >``` by themselves will mess things up more for the single character annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '3083-1-test.TextGrid'\n",
    "textgrid_path = os.path.join(testing_transcripts_folder, filename)\n",
    "tg = textgrid.openTextgrid(textgrid_path, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of ```intervals [something]```, similar to item\n",
    "\n",
    "```\n",
    "intervals [2002]:\n",
    "    xmin = 5548.948 \n",
    "    xmax = 5550.81 \n",
    "    text = \"what's it called intervals [ah] they call it intervals\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_restriction = r'text = \"(.*?intervals \\[.*?\\].*?)\"'\n",
    "test_text = 'text = \"whats it called intervals [ah] they call it intervals\"'\n",
    "\n",
    "def replace_brackets(match):\n",
    "    print(\"Match\")\n",
    "    print(match.group(0))\n",
    "    text_content = match.group(1)\n",
    "    text_content = text_content.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    return f'text = \"{text_content}\"'\n",
    "\n",
    "# Receives regex pattern, function to do replacement for matched patterns \n",
    "# (res of function is used as replacement text), input string where the replacement will occur\n",
    "\n",
    "# function receives a match object. It is called for each match found in the content string\n",
    "# match object represents a specific occurence of the matched pattern\n",
    "test_text_fixed = re.sub(text_restriction, replace_brackets, test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File 3143-2**\n",
    "\n",
    "Conclusion: Skip it because there is an overlap in transcription timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '3143-2.TextGrid'\n",
    "textgrid_path = os.path.join(testing_transcripts_folder, filename)\n",
    "tg = textgrid.openTextgrid(textgrid_path, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "intervals [2116]:\n",
    "    xmin = 6414.084\n",
    "    xmax = 6418.1359\n",
    "    text = \"I dare not talk one [ah] you know I I been through my life (uh)\"\n",
    "intervals [2117]:\n",
    "    xmin = 6418.135\n",
    "    xmax = 6419.022\n",
    "    text = \"first\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File 3201-1**\n",
    "\n",
    "Conclusion: Skip it because the instantaneous timing and transcription don't match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '3201-1.TextGrid'\n",
    "textgrid_path = os.path.join(testing_transcripts_folder, filename)\n",
    "tg = textgrid.openTextgrid(textgrid_path, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "intervals [251]:\n",
    "    xmin = 561.919\n",
    "    xmax = 561.919\n",
    "    text = \"(uh) so for mine\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File 3250-2**\n",
    "\n",
    "Conclusion: Skip it because there is an overlap in transcription timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '3250-2.TextGrid'\n",
    "textgrid_path = os.path.join(testing_transcripts_folder, filename)\n",
    "tg = textgrid.openTextgrid(textgrid_path, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "intervals [2004]:\n",
    "    xmin = 5813.161\n",
    "    xmax = 55816.75\n",
    "    text = \"I will do it at night (ppo)\"\n",
    "intervals [2005]:\n",
    "    xmin = 5814.861\n",
    "    xmax = 5815.399\n",
    "    text = \"<S>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Files to Ignore</u>**\n",
    "\n",
    "- 3035-2: Instantaneous timing and transcription don't match\n",
    "- 3075-2: Instantaneous timing and transcription don't match\n",
    "- 3143-2: Overlap in transcription timing\n",
    "- 3201-1: Instantaneous timing and transcription don't match\n",
    "- 3250-2: Overlap in transcription timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Files to Rename and Delete to match the ```.wav``` files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(org_transcripts_folder):\n",
    "    if len(filename.split(\".\")[0])>6:\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Iteration 8: Solve the TextGrid errors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import gzip\n",
    "import math\n",
    "import random\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>USER INPUT REQUIRED</u>**\n",
    "\n",
    "Change Relative Paths and Naming Conventions if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_transcripts_path = ['clean_textgrid', 'org_transcripts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialise Paths and Create the directories**\n",
    "\n",
    "**<u>USER INPUT REQUIRED</u>**: \n",
    "\n",
    "Remember to add in the <u>original</u> ```.TextGrid``` files provided by IMDA NSC to ```clean_textgrid/org_transcripts``` in the directory below after running the code block below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_transcripts_folder = os.path.join(os.getcwd(), *org_transcripts_path)\n",
    "create_dir = [org_transcripts_folder]\n",
    "\n",
    "for dir in create_dir:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the following files:\n",
    "- 3108-1_edited.TextGrid: Rename to 3108-1.TextGrid\n",
    "- 3115-1 9 (Update 2.05).TextGrid: Rename to 3115-1.TextGrid\n",
    "- 3115-2 (Update 2.05).TextGrid: Rename to 3115-2.TextGrid\n",
    "- 3209-1_edited.TextGrid: Rename to 3209-1.TextGrid\n",
    "\n",
    "Delete the following files: \n",
    "- 3115-1 (Update 2.04).TextGrid: Delete because outdated\n",
    "- 3115-2 (Update 2.04).TextGrid -> Delete because outdated\n",
    "- 3035-2.TextGrid: Instantaneous timing and transcription don't match\n",
    "- 3075-2.TextGrid: Instantaneous timing and transcription don't match\n",
    "- 3143-2.TextGrid: Overlap in transcription timing\n",
    "- 3201-1.TextGrid: Instantaneous timing and transcription don't match\n",
    "- 3250-2.TextGrid: Overlap in transcription timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_delete = ['3115-1 (Update 2.04).TextGrid', '3115-2 (Update 2.04).TextGrid', '3035-2.TextGrid', \n",
    "                   '3075-2.TextGrid', '3143-2.TextGrid', '3201-1.TextGrid', '3250-2.TextGrid']\n",
    "\n",
    "files_to_rename = {\n",
    "    \"3108-1_edited.TextGrid\": \"3108-1.TextGrid\",\n",
    "    \"3115-1 9 (Update 2.05).TextGrid\": \"3115-1.TextGrid\",\n",
    "    \"3115-2 (Update 2.05).TextGrid\": \"3115-2.TextGrid\",\n",
    "    \"3209-1_edited.TextGrid\": \"3209-1.TextGrid\"\n",
    "}\n",
    "\n",
    "for filename in files_to_delete:\n",
    "    file_path = os.path.join(org_transcripts_folder, filename)\n",
    "    os.remove(file_path)\n",
    "    print(f\"Deleted {filename}\")\n",
    "\n",
    "for old_name, new_name in files_to_rename.items():\n",
    "    old_path = os.path.join(org_transcripts_folder, old_name)\n",
    "    new_path = os.path.join(org_transcripts_folder, new_name)\n",
    "    os.rename(old_path, new_path)\n",
    "    print(f\"Renamed {old_name} to {new_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper function to remove instances of ```text = \"...item [something]...\"``` and ```text = \"...intervals [something]...\"``` from a single TextGrid file**\n",
    "\n",
    "- To not interfere with praatio library's splitting logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_text_restriction(textgrid_path):\n",
    "    try:\n",
    "        with open(textgrid_path, \"r\", encoding=\"utf-16\") as file:\n",
    "            textgrid = file.read()\n",
    "        encoding = \"utf-16\"\n",
    "    except UnicodeError:\n",
    "        with open(textgrid_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            textgrid = file.read()\n",
    "        encoding = \"utf-8\"\n",
    "\n",
    "    text_restriction_1 = r'text = \"(.*?item \\[.*?\\].*?)\"'\n",
    "    text_restriction_2 = r'text = \"(.*?intervals \\[.*?\\].*?)\"'\n",
    "\n",
    "    def replace_brackets(match):\n",
    "        text_content = match.group(1)\n",
    "        text_content = text_content.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        return f'text = \"{text_content}\"'\n",
    "\n",
    "    textgrid_fixed = re.sub(text_restriction_1, replace_brackets, textgrid)\n",
    "    textgrid_fixed_final = re.sub(text_restriction_2, replace_brackets, textgrid_fixed)\n",
    "\n",
    "    with open(textgrid_path, \"w\", encoding=encoding) as file:\n",
    "        file.write(textgrid_fixed_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove text restrictions to let praatio library run properly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_successfully = []\n",
    "cleaned_unsuccessfully = []\n",
    "for filename in os.listdir(org_transcripts_folder):\n",
    "    try:\n",
    "        textgrid_path = os.path.join(org_transcripts_folder, filename)\n",
    "        tg = textgrid.openTextgrid(textgrid_path, False)\n",
    "    except:\n",
    "        remove_text_restriction(textgrid_path)\n",
    "        try:\n",
    "            tg = textgrid.openTextgrid(textgrid_path, False)\n",
    "            cleaned_successfully.append(filename)\n",
    "        except:\n",
    "            cleaned_unsuccessfully.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_unsuccessfully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Iteration 9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcription(transcript):\n",
    "    transcript = transcript.strip()\n",
    "    transcript = transcript.lower()\n",
    "    remove = [r'\\(ppb\\)|\\(ppc\\)|\\(ppl\\)|\\(ppo\\)', r'_', r'\\[|\\]', r'\\(|\\)', r'!', \n",
    "            r'#', r'<unk>', r'~', r'<s>', r'<z>', r'<nen>', r'<fil/>', r'<spk/>',\n",
    "            r'\\*', r'<non/>', r'<s/>', r'<c/>', r'<[^>]+>'] \n",
    "    replace = ['-']\n",
    "    for e in remove:\n",
    "        transcript = re.sub(e, '', transcript)\n",
    "    for e in replace:\n",
    "        transcript = re.sub(e, ' ', transcript)\n",
    "    transcript = re.sub(r'\\s+', ' ', transcript).strip()\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_transcript(audio_filename, input_audio_path, input_textgrid_path, output_dir_wav, output_dir_transcript, output_dir_textgrid, sanity_check=False):\n",
    "    audio_path = os.path.join(input_audio_path, f'{audio_filename}.wav')\n",
    "    textgrid_path = os.path.join(input_textgrid_path, f'{audio_filename}.TextGrid')\n",
    "\n",
    "    audio = AudioSegment.from_wav(audio_path)\n",
    "    tg = textgrid.openTextgrid(textgrid_path, False) \n",
    "\n",
    "    # Specify the duration of each segment\n",
    "    segment_duration_s = 30 \n",
    "    # Specify the current segment index\n",
    "    segment_index = 1\n",
    "\n",
    "    for tier_name in tg.tierNames: \n",
    "        tier = tg.getTier(tier_name) \n",
    "        for start,end,label in tier.entries:  \n",
    "            # Get the duration of this new entry\n",
    "            entry_duration = end-start\n",
    "            # If the entry's duration is less than our specified duration of each segment\n",
    "            if entry_duration <= segment_duration_s:\n",
    "                # Clean the transcription/label of this entry\n",
    "                curr_transcriptions_clean = clean_transcription(label)\n",
    "                # If this entry has text after cleaning i.e. contains proper ground truth transcription\n",
    "                if len(curr_transcriptions_clean) > 0:\n",
    "                    # Initialise the transcription segment path\n",
    "                    transcript_segment_path = os.path.join(output_dir_transcript, f'{audio_filename}_{segment_index}.txt')\n",
    "                    # Write the transcription to the transcription segment file\n",
    "                    with open(transcript_segment_path, 'w') as f:\n",
    "                        f.write(f'{audio_filename}_{segment_index} {curr_transcriptions_clean}')\n",
    "\n",
    "                    # Calculate the boundaries for the audio segment in ms\n",
    "                    segment_start = start*1000\n",
    "                    segment_end = end*1000\n",
    "\n",
    "                    # Sanity check on TextGrid Segments\n",
    "                    if sanity_check:\n",
    "                        tg_segment = tg.crop(segment_start / 1000, segment_end / 1000, mode=\"strict\", rebaseToZero=False)\n",
    "                        tg_segment_path = os.path.join(output_dir_textgrid, f'{audio_filename}_{segment_index}.TextGrid')\n",
    "                        tg_segment.save(tg_segment_path, \"long_textgrid\", True)\n",
    "\n",
    "                    # Segment the audio using the start and time from the current TextGrid entry\n",
    "                    audio_segment = audio[segment_start:segment_end+1] # Add 1 ms s.t the end timing is inclusive\n",
    "\n",
    "                    # Save the audio segment\n",
    "                    audio_segment_path = os.path.join(output_dir_wav, f'{audio_filename}_{segment_index}.wav')\n",
    "                    audio_segment.export(audio_segment_path, format=\"wav\")\n",
    "\n",
    "                    # Increment the segment index\n",
    "                    segment_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio_path = ['org_wavs']\n",
    "input_textgrid_path = ['org_transcripts']\n",
    "output_train_path = ['dataset', 'train']\n",
    "output_test_path = ['dataset', 'test']\n",
    "output_compressed_path = ['dataset','data']\n",
    "compressed_filename = 'imda_nsc_p3.tar.gz'\n",
    "compressed_train_prompt_filename = 'prompts-train.txt.gz'\n",
    "compressed_test_prompt_filename = 'prompts-test.txt.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_drive_path = 'D:\\\\'\n",
    "input_wav_folder = os.path.join(hard_drive_path, *input_audio_path)\n",
    "input_textgrid_folder = os.path.join(hard_drive_path, *input_textgrid_path)\n",
    "output_train_folder_waves = os.path.join(hard_drive_path, *output_train_path, 'waves')\n",
    "output_train_folder_transcripts = os.path.join(hard_drive_path, *output_train_path, 'transcripts')\n",
    "output_test_folder_waves  = os.path.join(hard_drive_path, *output_test_path, 'waves')\n",
    "output_test_folder_transcripts = os.path.join(hard_drive_path, *output_test_path, 'transcripts')\n",
    "output_textgrids_folder = os.path.join(hard_drive_path, *output_train_path, 'textgrids')\n",
    "output_compressed_folder = os.path.join(hard_drive_path, *output_compressed_path)\n",
    "output_compressed_file = os.path.join(output_compressed_folder, compressed_filename)\n",
    "output_compressed_train_prompt_file = os.path.join(output_compressed_folder, compressed_train_prompt_filename)\n",
    "output_compressed_test_prompt_file = os.path.join(output_compressed_folder, compressed_test_prompt_filename)\n",
    "\n",
    "create_dir = [output_train_folder_waves, output_train_folder_transcripts,\n",
    "              output_test_folder_waves, output_test_folder_transcripts, output_textgrids_folder, output_compressed_folder]\n",
    "\n",
    "for dir in create_dir:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_audio_transcript('3009-1', input_wav_folder, input_textgrid_folder, output_train_folder_waves, output_train_folder_transcripts, output_textgrids_folder, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like hard drive disconnected itself after the operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Iteration 10: Make into 30s long**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johnl\\miniconda3\\envs\\myenv2\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import gzip\n",
    "import math\n",
    "import random\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio_path = ['org_wavs']\n",
    "input_textgrid_path = ['org_transcripts']\n",
    "output_train_path = ['dataset', 'train']\n",
    "output_test_path = ['dataset', 'test']\n",
    "output_compressed_path = ['dataset','data']\n",
    "compressed_filename = 'imda_nsc_p3.tar.gz'\n",
    "compressed_train_prompt_filename = 'prompts-train.txt.gz'\n",
    "compressed_test_prompt_filename = 'prompts-test.txt.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_drive_path = os.getcwd() #'D:\\\\'\n",
    "output_drive_path = os.getcwd()\n",
    "input_wav_folder = os.path.join(input_drive_path, *input_audio_path)\n",
    "input_textgrid_folder = os.path.join(input_drive_path, *input_textgrid_path)\n",
    "output_train_folder_waves = os.path.join(output_drive_path, *output_train_path, 'waves')\n",
    "output_train_folder_transcripts = os.path.join(output_drive_path, *output_train_path, 'transcripts')\n",
    "output_test_folder_waves  = os.path.join(output_drive_path, *output_test_path, 'waves')\n",
    "output_test_folder_transcripts = os.path.join(output_drive_path, *output_test_path, 'transcripts')\n",
    "output_textgrids_folder = os.path.join(output_drive_path, *output_train_path, 'textgrids')\n",
    "output_compressed_folder = os.path.join(output_drive_path, *output_compressed_path)\n",
    "output_compressed_file = os.path.join(output_compressed_folder, compressed_filename)\n",
    "output_compressed_train_prompt_file = os.path.join(output_compressed_folder, compressed_train_prompt_filename)\n",
    "output_compressed_test_prompt_file = os.path.join(output_compressed_folder, compressed_test_prompt_filename)\n",
    "\n",
    "create_dir = [input_wav_folder, input_textgrid_folder, output_train_folder_waves, output_train_folder_transcripts,\n",
    "              output_test_folder_waves, output_test_folder_transcripts, output_textgrids_folder, output_compressed_folder]\n",
    "\n",
    "for dir in create_dir:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcription(transcript):\n",
    "    transcript = transcript.strip()\n",
    "    transcript = transcript.lower()\n",
    "    remove = [r'\\(ppb\\)|\\(ppc\\)|\\(ppl\\)|\\(ppo\\)', r'_', r'\\[|\\]', r'\\(|\\)', r'!', \n",
    "            r'#', r'<unk>', r'~', r'<s>', r'<z>', r'<nen>', r'<fil/>', r'<spk/>',\n",
    "            r'\\*', r'<non/>', r'<s/>', r'<c/>', r'<[^>]+>'] \n",
    "    replace = ['-']\n",
    "    for e in remove:\n",
    "        transcript = re.sub(e, '', transcript)\n",
    "    for e in replace:\n",
    "        transcript = re.sub(e, ' ', transcript)\n",
    "    transcript = re.sub(r'\\s+', ' ', transcript).strip()\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_transcript(audio_filename, input_audio_path, input_textgrid_path, output_dir_wav, output_dir_transcript, segment_duration_s, buffer):\n",
    "    # Initialise the wav and TextGrid paths of the current file\n",
    "    audio_path = os.path.join(input_audio_path, f'{audio_filename}.wav')\n",
    "    textgrid_path = os.path.join(input_textgrid_path, f'{audio_filename}.TextGrid')\n",
    "\n",
    "    audio = AudioSegment.from_wav(audio_path)\n",
    "    tg = textgrid.openTextgrid(textgrid_path, False) \n",
    "\n",
    "    # Specify the current segment index\n",
    "    segment_index = 1\n",
    "\n",
    "    # Initialise the current segment duration\n",
    "    curr_segment_duration = 0\n",
    "    # Initialise a list to hold the transcriptions for the current segment\n",
    "    curr_transcriptions = []\n",
    "    # Initialise a list to hold the audios for the current segment\n",
    "    curr_wavs = []\n",
    "    # Get the buffer in seconds -> To separate potentially unrelated speech\n",
    "    buffer_s = buffer/1000 \n",
    "    # Initialise audio buffer\n",
    "    buffer_audio = AudioSegment.silent(duration=buffer)\n",
    "\n",
    "    for tier_name in tg.tierNames: \n",
    "        tier = tg.getTier(tier_name) \n",
    "        for start,end,label in tier.entries:  \n",
    "            # Get the duration of this new entry\n",
    "            entry_duration = end-start\n",
    "\n",
    "            # if entry_duration <= segment_duration_s -> don't need to consider and\n",
    "\n",
    "            # If the new entry does not exceed our sepcified duration of each segment and\n",
    "            # adding a buffer and new entry to the current segment does not exceed our specified duration of each segment\n",
    "            # we can try accumulating the current segment\n",
    "            if entry_duration < segment_duration_s and curr_segment_duration + buffer_s + entry_duration <= segment_duration_s:\n",
    "                # Clean the transcription/label of this entry\n",
    "                curr_transcription_clean = clean_transcription(label)\n",
    "                # If this entry has text after cleaning i.e. contains proper ground truth transcription,\n",
    "                # it is a valid sample\n",
    "                if len(curr_transcription_clean) > 0:\n",
    "                    # Update the current_segment_duration\n",
    "                    curr_segment_duration = curr_segment_duration + buffer_s + entry_duration\n",
    "                    # Add the current cleaned transcription of this entry\n",
    "                    curr_transcriptions.append(curr_transcription_clean)\n",
    "                    # Add the audio of this entry: Segment the audio using the start and end time from the current TextGrid entry\n",
    "                    curr_wavs.append(audio[start*1000:(end*1000)+1]) # Add 1 ms s.t the end timing is inclusive\n",
    "\n",
    "            # If adding a buffer and new entry exceeds our specified duration of each segment,\n",
    "            # that means the current segment is completed and\n",
    "            # we save the current transcription and the segmented audio as well as perform resetting\n",
    "            elif curr_segment_duration > 0:\n",
    "                    # Join the current transcription for the segment\n",
    "                    transcript_segment = ' '.join(curr_transcriptions)\n",
    "\n",
    "                    # Initialise the transcription segment path\n",
    "                    transcript_segment_path = os.path.join(output_dir_transcript, f'{audio_filename}_{segment_index}.txt')\n",
    "                    # Write the transcription to the transcription segment file\n",
    "                    with open(transcript_segment_path, 'w') as f:\n",
    "                        f.write(f'{audio_filename}_{segment_index} {transcript_segment}')\n",
    "\n",
    "                    # Join the audio segments together with an audio buffer between them\n",
    "                    audio_segment = curr_wavs[0]\n",
    "                    for wav in curr_wavs[1:]:\n",
    "                        audio_segment = audio_segment + buffer_audio + wav\n",
    "\n",
    "                    # Initialise the audio segment path\n",
    "                    audio_segment_path = os.path.join(output_dir_wav, f'{audio_filename}_{segment_index}.wav')\n",
    "                    # Save the audio segment\n",
    "                    audio_segment.export(audio_segment_path, format=\"wav\")\n",
    "\n",
    "                    # Increment the segment index\n",
    "                    segment_index+=1\n",
    "\n",
    "                    # Resetting\n",
    "                    curr_transcription_clean = clean_transcription(label)\n",
    "                    # If the entry in the current iteration is <= than our specified duration of each segment and has text after cleaning i.e. contains proper ground truth transcription\n",
    "                    if entry_duration <= segment_duration_s and len(curr_transcription_clean) > 0:\n",
    "                        # Reset the current segment duration\n",
    "                        curr_segment_duration = entry_duration\n",
    "                        # Reset the list to hold the transcriptions for the new segment\n",
    "                        curr_transcriptions = [curr_transcription_clean]\n",
    "                        # Reset the list to hold the audios for the new segment\n",
    "                        curr_wavs = [audio[start*1000:(end*1000)+1]] # Add 1 ms s.t the end timing is inclusive\n",
    "                    # Skip the entry as a sample if it is > than our specified duration of each segment\n",
    "                    else:\n",
    "                        # Reset the new segment duration\n",
    "                        curr_segment_duration = 0\n",
    "                        # Reset the list to hold the transcriptions for the new segment\n",
    "                        curr_transcriptions = []\n",
    "                        # Reset the list to hold the audios for the new segment\n",
    "                        curr_wavs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error happened because curr_segment was empty but entry_duration exceeded in this iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_wav_folder):\n",
    "    try:\n",
    "        filename = filename.split('.')[0]\n",
    "        process_audio_transcript(filename, input_wav_folder, input_textgrid_folder, output_train_folder_waves, output_train_folder_transcripts, 30, 1000)\n",
    "    except Exception as e:\n",
    "        print(f\"Filename {filename}\")\n",
    "        print(f\"Exception {e}\")\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56992"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimated wav storage for script same: 274*2 samples, each sample around 104MB\n",
    "# 56992 MB which is 57GB\n",
    "274*2*104"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation: Text can get a little cut off sometimes**\n",
    "\n",
    "```\n",
    "intervals [598]:\n",
    "    xmin = 3013.472 \n",
    "    xmax = 3019.4779488360505 \n",
    "    text = \"on Sunday right I did set up there was only two people okay including me so me and this uncle\" \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='testing.wav'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio = AudioSegment.from_wav(os.path.join(input_wav_folder,'3003-1.wav'))\n",
    "test_audio = audio[3013.472*1000:3019.4779488360505*1000 + 1]\n",
    "test_audio.export('testing.wav', format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Upload to HF\n",
    "\n",
    "<u>Upload to HuggingFace</u>\n",
    "\n",
    "Prepare our own audio dataset and upload it to HF\n",
    "\n",
    "Stream data during the training process\n",
    "\n",
    "Each file is around 112770 KB which is 0.11 GB\n",
    "\n",
    "Part 3 consists of 1000 hours, which is maybe 110 GB ish\n",
    "\n",
    "But maybe half of it is not the enviornment we want\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "Folder structure\n",
    "\n",
    "Configure your dataset repository with audio files\n",
    "\n",
    "- https://huggingface.co/docs/datasets/audio_dataset#audiofolder\n",
    "- https://huggingface.co/docs/datasets/en/repository_structure#split-pattern-hierarchy\n",
    "- https://huggingface.co/docs/hub/datasets-audio\n",
    "\n",
    "```\n",
    "test_dataset\n",
    "    - metadata.csv: file_name (full relative path to audio file), transcription\n",
    "    - data\n",
    "        - train\n",
    "            - first_train_audio_file.wav\n",
    "            - second_train_audio_file.wav\n",
    "            - ...\n",
    "```\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "### <u>Approach 1</u>\n",
    "\n",
    "**<u>Part 1: Folder-based builders: Build dataset locally</u>**\n",
    "\n",
    "https://huggingface.co/docs/datasets/create_dataset\n",
    "\n",
    "https://huggingface.co/docs/datasets/audio_dataset#audiofolder\n",
    "\n",
    "https://huggingface.co/docs/datasets/en/repository_structure#split-pattern-hierarchy\n",
    "\n",
    "AudioFolder is a dataset builder to load an audio dataset with several thousand audio files. Additional information such as transcription is loaded by AudioFolder if its included in the metadata file\n",
    "\n",
    "AudioFolder creates splits based on split pattern hierarchy \n",
    "\n",
    "```\n",
    "# After structuring the data\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"audiofolder\", data_dir=\"/path/to/data\")\n",
    "```\n",
    "\n",
    "**<u>Part 2: Push local dataset to Hub</u>**\n",
    "\n",
    "https://huggingface.co/docs/datasets/upload_dataset\n",
    "\n",
    "```\n",
    "pip install huggingface_hub\n",
    "\n",
    "huggingface-cli login\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"stevhliu/demo\")\n",
    "\n",
    "dataset.push_to_hub(\"stevhliu/processed_demo\")\n",
    "```\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "### <u>Approach 2</u>\n",
    "\n",
    "https://huggingface.co/docs/datasets/audio_dataset#audiofolder\n",
    "\n",
    "https://huggingface.co/docs/hub/datasets-adding\n",
    "\n",
    "**<u>Part 1: Upload local dataset directory to Hub</u>**\n",
    "\n",
    "**<u>Uploading Datasets in general</u>**\n",
    "\n",
    "https://huggingface.co/docs/hub/datasets-adding\n",
    "\n",
    "- Dataset repos are Git repos, so we can use Git to push data files to the Hub\n",
    "- Starter: https://huggingface.co/docs/hub/repositories-getting-started\n",
    "- Parquet is the recommended format due to its efficient compression etc.\n",
    "    - For more general use cases involving analytics, data filtering or metadata parsing, Parquet is the recommended option for large scale image and audio datasets.\n",
    "- For large scale image and audio datasets streaming, WebDataset should be preferred over raw image and audio files to avoid the overhead of accessing individual files\n",
    "- Hugging Face Hub supports large scale datasets, usually uploaded in Parquet via push_to_hub() or WebDataset format\n",
    "\n",
    "**<u>Creating audio datasets</u>**\n",
    "\n",
    "- https://huggingface.co/docs/hub/datasets-audio\n",
    "- https://huggingface.co/collections/datasets-examples/audio-dataset-66aca0b73e8f69e3d069e607\n",
    "\n",
    "**<u>Uploading large folders</u>**\n",
    "\n",
    "https://huggingface.co/docs/huggingface_hub/guides/upload#upload-a-folder-by-chunks\n",
    "\n",
    "- Upload folder normally: ```upload_folder()```\n",
    "    - Upload a local folder to an existing repo\n",
    "    - Specify the path of the local folder to upload, where you want to upload the folder to in the repository, and the name of the repository you want to add the folder to. Depending on your repository type, you can optionally set the repository type as a dataset, model, or space\n",
    "\n",
    "    ```\n",
    "    from huggingface_hub import HfApi\n",
    "    api = HfApi()\n",
    "\n",
    "    api.upload_folder(\n",
    "        folder_path=\"/path/to/local/space\",\n",
    "        repo_id=\"username/my-cool-space\",\n",
    "        repo_type=\"space\",\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    - By default, the .gitignore file will be taken into account to know which files should be committed or not. By default we check if a .gitignore file is present in a commit, and if not, we check if it exists on the Hub. Please be aware that only a .gitignore file present at the root of the directory with be used. We do not check for .gitignore files in subdirectories.\n",
    "\n",
    "    - Makes a single commit, fails explicitly when something wrong happens\n",
    "\n",
    "- Upload a large folder: ```upload_large_folder()```\n",
    "    - Resumable\n",
    "        - Upload process is split into many small tasks\n",
    "        - Each time a task is completed, result is cached locally in ```./cache/huggingface``` inside the folder you're trying to upload\n",
    "    - Multi-threaded\n",
    "    - Resilient to errors: High-level retry-mechanism\n",
    "        - Downside: If transient errors happen, the process will continue and retry. If permanent errors happen (e.g. permission denied), it will retry indefinitely without solving the root cause.\n",
    "    - Limitations\n",
    "        - ...\n",
    "\n",
    "\n",
    "    ```\n",
    "    api.upload_large_folder(\n",
    "        repo_id=\"HuggingFaceM4/Docmatix\",\n",
    "        repo_type=\"dataset\",\n",
    "        folder_path=\"/path/to/local/docmatix\",\n",
    "    )\n",
    "    ```\n",
    "\n",
    "- Recommendations\n",
    "    - Start small\n",
    "\n",
    "- Upload a folder by chunks: ```upload_folder()```\n",
    "    - Upload a folder in serveral commits so we don't have to resume the process from the beginning: Pass ```multi_commits=True``` as a argument\n",
    "    - Recommended to pass ```multi_commits_verbose=True```\n",
    "    - Upload will resume from where it stopped\n",
    "        - If the process is interrupted before completing, you can rerun your script to resume the upload. The created PR will be automatically detected and the upload will resume from where it stopped\n",
    "    - ```multi_commits``` is still an experimental feature\n",
    "\n",
    "**<u>Repo Limits and recommendations</u>**\n",
    "\n",
    "https://huggingface.co/docs/hub/repositories-recommendations\n",
    "\n",
    "- Repo size: Generally support repos up to 300GB\n",
    "- Number of files: Keep total number of files under 100k\n",
    "    - Large datasets can be exported as Parque files or in WebDataset format\n",
    "    - Cannot exceed 10k files per folder. Solution is to create a repo structure that uses subdirectories \n",
    "\n",
    "\n",
    "**<u>Part 2: Load dataset from the hub using audiofolder</u>**\n",
    "\n",
    "```\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"audiofolder\", data_dir=\"/path/to/data\") # There's a streaming option: https://huggingface.co/docs/datasets/en/stream\n",
    "```\n",
    "\n",
    "### <u>Approach 3</u>\n",
    "\n",
    "https://huggingface.co/docs/hub/repositories-getting-started\n",
    "\n",
    "https://huggingface.co/docs/datasets/en/audio_dataset#loading-script ((Legacy) Loading script)\n",
    "\n",
    "https://huggingface.co/docs/hub/datasets-audio\n",
    "\n",
    "https://huggingface.co/collections/datasets-examples/audio-dataset-66aca0b73e8f69e3d069e607\n",
    "\n",
    "https://medium.com/htx-dsai/finetuning-whisper-for-the-singaporean-home-team-context-a3ae1a6ae809\n",
    "\n",
    "https://huggingface.co/docs/hub/datasets-webdataset\n",
    "\n",
    "Custom loading script\n",
    "\n",
    "Reasons\n",
    "- For large scale image and audio datasets streaming, WebDataset should be preferred over raw image and audio files to avoid the overhead of accessing individual files. \n",
    "- Audio datasets are commonly stored in tar.gz archives which requires a particular approach to support streaming mode. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dataset loading script for audio datasets\n",
    "\n",
    "Audio datasets are commonly stored in tar.gz archives which requires a particular approach to support streaming mode\n",
    "\n",
    "see ```new_dataset_script tutorial.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Put the dataset into WebDataset format\n",
    "\n",
    "vivos format:\n",
    "\n",
    "```\n",
    "- vivos.tar.gz\n",
    "    - vivos.tar\n",
    "        - train\n",
    "            - genders.txt: Contains the gender type for each waves folder\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files\n",
    "            - waves\n",
    "                - VIVOSSPK01 -> Speaker ID\n",
    "                    - VIVOSSPK01_R001.wav\n",
    "                    - VIVOSSPK01_R002.wav\n",
    "                    - VIVOSSPK01_R003.wav\n",
    "\n",
    "            - test\n",
    "    - prompts-train.txt.gz\n",
    "        - prompts-train.txt: Contains transcriptions for all the .wav files\n",
    "    - prompts-test.txt.gz\n",
    "```\n",
    "\n",
    "Usual size per archive is generally around 1GB?\n",
    "\n",
    "```\n",
    "- imda_nsc_p3.tar.gz\n",
    "    - imda_nsc_p3.tar\n",
    "        - train\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files\n",
    "            - waves\n",
    "                - 3000-1.tar\n",
    "                    - 3000-1_1.wav\n",
    "                    - 3000-1_2.wav\n",
    "                    - 3000-1_3.wav\n",
    "- prompts-train.txt.gz\n",
    "    - prompts-train.txt: Contains transcriptions for all the train .wav files\n",
    "```\n",
    "\n",
    "try this first\n",
    "\n",
    "```\n",
    "- imda_nsc_p3.tar.gz\n",
    "    - imda_nsc_p3.tar\n",
    "        - train\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files\n",
    "            - waves\n",
    "                - 3000-1_1.wav\n",
    "                - 3000-1_2.wav\n",
    "                - 3000-1_3.wav\n",
    "- prompts-train.txt.gz\n",
    "    - prompts-train.txt: Contains transcriptions for all the train .wav files\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
