{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Prepare Full Dataset: Segment audio and transcriptions based on main speaker's speech**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of code flow\n",
    "\n",
    "### Step 0:\n",
    "\n",
    "<u>Run the processing code to clean the textgrid files</u>\n",
    "- Renames a minority of files for convention purposes and delete outdated files\n",
    "- Remove instances of ```text = \"...item [something]...\"```, ```text = \"...intervals [something]...\"``` to let TextGrid library run properly\n",
    "- Remove files with instantenous timings given a proper transcription and files with overlap timings\n",
    "\n",
    "```\n",
    "local drive\n",
    "- clean_textgrid\n",
    "    - org_transcripts\n",
    "        - 3000-1.TextGrid\n",
    "        - 3000-2.TextGrid\n",
    "        - ...\n",
    "```\n",
    "\n",
    "### Step 1:\n",
    "<u>After manually creating the directory in the input drive and running the code to initialise the directory in the output drive</u>\n",
    "```\n",
    "input drive\n",
    "- org_wavs: Manually add in .wav files to be segmented\n",
    "    - 3000-1.wav\n",
    "    - 3000-2.wav\n",
    "    - ...\n",
    "- org_transcripts: Manually add in cleaned .TextGrid files to be segmented\n",
    "    - 3000-1.TextGrid\n",
    "    - 3000-2.TextGrid\n",
    "    - ...\n",
    "- invalid_wavs: Manually move the following invalid wav files from org_wavs\n",
    "    - 3035-2.wav: Instantaneous timing and transcription don't match\n",
    "    - 3075-2.wav: Instantaneous timing and transcription don't match\n",
    "    - 3143-2.wav: Overlap in transcription timing\n",
    "    - 3201-1.wav: Instantaneous timing and transcription don't match\n",
    "    - 3250-2.wav: Overlap in transcription timing\n",
    "\n",
    "output drive\n",
    "- dataset\n",
    "    - data: Used to store compression files\n",
    "    - train\n",
    "        - waves: Empty\n",
    "        - transcripts: Empty\n",
    "        - textgrids: Empty\n",
    "    - test\n",
    "        - waves: Empty\n",
    "        - transcripts: Empty\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Step 2:\n",
    "<u>After running the processing code</u>\n",
    "```\n",
    "input drive\n",
    "- org_wavs: Manually add in .wav files to be segmented\n",
    "    - 3000-1.wav\n",
    "    - 3000-2.wav\n",
    "    - ...\n",
    "- org_transcripts: Manually add in .TextGrid files to be segmented\n",
    "    - 3000-1.TextGrid\n",
    "    - 3000-2.TextGrid\n",
    "    - ...\n",
    "- invalid_wavs: Manually move the following invalid wav files from org_wavs\n",
    "    - 3035-2.wav: Instantaneous timing and transcription don't match\n",
    "    - 3075-2.wav: Instantaneous timing and transcription don't match\n",
    "    - 3143-2.wav: Overlap in transcription timing\n",
    "    - 3201-1.wav: Instantaneous timing and transcription don't match\n",
    "    - 3250-2.wav: Overlap in transcription timing\n",
    "\n",
    "output drive\n",
    "- dataset\n",
    "    - data: Used to store compression files\n",
    "    - train\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in train\n",
    "        - waves\n",
    "            - 3000-1_1.wav\n",
    "            - 3000-1_2.wav\n",
    "            - 3000-1_3.wav\n",
    "            - ...\n",
    "            - 3000-2_1.wav\n",
    "            - 3000-2_2.wav\n",
    "            - 3000-2_3.wav\n",
    "        - transcripts\n",
    "            - 3000-1_1.txt\n",
    "            - 3000-1_2.txt\n",
    "            - 3000-1_3.txt\n",
    "            - ...\n",
    "            - 3000-2_1.txt\n",
    "            - 3000-2_2.txt\n",
    "            - 3000-2_3.txt\n",
    "    - test\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in test\n",
    "        - waves\n",
    "            - 3000-3_1.wav\n",
    "            - 3000-3_2.wav\n",
    "            - 3000-3_3.wav\n",
    "            - ...\n",
    "            - 3000-4_1.wav\n",
    "            - 3000-4_2.wav\n",
    "            - 3000-4_3.wav\n",
    "        - transcripts\n",
    "            - 3000-3_1.txt\n",
    "            - 3000-3_2.txt\n",
    "            - 3000-3_3.txt\n",
    "            - ...\n",
    "            - 3000-4_1.txt\n",
    "            - 3000-4_2.txt\n",
    "            - 3000-4_3.txt\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Step 3:\n",
    "<u>After running the compression code</u>\n",
    "\n",
    "```\n",
    "output drive\n",
    "- data: Used to store compression files\n",
    "    - imda_nsc_p3.tar.gz\n",
    "        - train\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files in train\n",
    "            - waves\n",
    "                - 3000-1_1.wav\n",
    "                - 3000-1_2.wav\n",
    "                - 3000-1_3.wav\n",
    "                - ...\n",
    "                - 3000-2_1.wav\n",
    "                - 3000-2_2.wav\n",
    "                - 3000-2_3.wav\n",
    "        - test\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files in test\n",
    "            - waves\n",
    "                - 3000-3_1.wav\n",
    "                - 3000-3_2.wav\n",
    "                - 3000-3_3.wav\n",
    "                - ...\n",
    "                - 3000-4_1.wav\n",
    "                - 3000-4_2.wav\n",
    "                - 3000-4_3.wav\n",
    "    - prompts-train.txt.gz\n",
    "        - prompts-train.txt: Contains transcriptions for all the train .wav files -> taken from train/prompts.txt\n",
    "    - prompts-test.txt.gz\n",
    "        - prompts-test.txt: Contains transcriptions for all the test .wav files -> take from test/prompts.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Code to clean TextGrid files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johnl\\miniconda3\\envs\\myenv2\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import gzip\n",
    "import math\n",
    "import random\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>USER ACTION REQUIRED</u>**\n",
    "\n",
    "Change Relative Paths and Naming Conventions if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_transcripts_path = ['clean_textgrid', 'org_transcripts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialise Paths and Create the directories**\n",
    "\n",
    "**<u>USER ACTION REQUIRED</u>**: \n",
    "\n",
    "- Add in the <u>original</u> ```.TextGrid``` files provided by IMDA NSC to ```clean_textgrid/org_transcripts``` <u>after</u> running the code block directly below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_transcripts_folder = os.path.join(os.getcwd(), *org_transcripts_path)\n",
    "create_dir = [org_transcripts_folder]\n",
    "\n",
    "for dir in create_dir:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code that\n",
    "\n",
    "Renames the following files:\n",
    "- 3108-1_edited.TextGrid: Rename to 3108-1.TextGrid\n",
    "- 3115-1 9 (Update 2.05).TextGrid: Rename to 3115-1.TextGrid\n",
    "- 3115-2 (Update 2.05).TextGrid: Rename to 3115-2.TextGrid\n",
    "- 3209-1_edited.TextGrid: Rename to 3209-1.TextGrid\n",
    "\n",
    "Deletes the following files: \n",
    "- 3115-1 (Update 2.04).TextGrid: Delete because outdated\n",
    "- 3115-2 (Update 2.04).TextGrid -> Delete because outdated\n",
    "- 3035-2.TextGrid: Instantaneous timing and transcription don't match\n",
    "- 3075-2.TextGrid: Instantaneous timing and transcription don't match\n",
    "- 3143-2.TextGrid: Overlap in transcription timing\n",
    "- 3201-1.TextGrid: Instantaneous timing and transcription don't match\n",
    "- 3250-2.TextGrid: Overlap in transcription timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 3115-1 (Update 2.04).TextGrid\n",
      "Deleted 3115-2 (Update 2.04).TextGrid\n",
      "Deleted 3035-2.TextGrid\n",
      "Deleted 3075-2.TextGrid\n",
      "Deleted 3143-2.TextGrid\n",
      "Deleted 3201-1.TextGrid\n",
      "Deleted 3250-2.TextGrid\n",
      "Renamed 3108-1_edited.TextGrid to 3108-1.TextGrid\n",
      "Renamed 3115-1 9 (Update 2.05).TextGrid to 3115-1.TextGrid\n",
      "Renamed 3115-2 (Update 2.05).TextGrid to 3115-2.TextGrid\n",
      "Renamed 3209-1_edited.TextGrid to 3209-1.TextGrid\n"
     ]
    }
   ],
   "source": [
    "files_to_delete = ['3115-1 (Update 2.04).TextGrid', '3115-2 (Update 2.04).TextGrid', '3035-2.TextGrid', \n",
    "                   '3075-2.TextGrid', '3143-2.TextGrid', '3201-1.TextGrid', '3250-2.TextGrid']\n",
    "\n",
    "files_to_rename = {\n",
    "    \"3108-1_edited.TextGrid\": \"3108-1.TextGrid\",\n",
    "    \"3115-1 9 (Update 2.05).TextGrid\": \"3115-1.TextGrid\",\n",
    "    \"3115-2 (Update 2.05).TextGrid\": \"3115-2.TextGrid\",\n",
    "    \"3209-1_edited.TextGrid\": \"3209-1.TextGrid\"\n",
    "}\n",
    "\n",
    "for filename in files_to_delete:\n",
    "    file_path = os.path.join(org_transcripts_folder, filename)\n",
    "    os.remove(file_path)\n",
    "    print(f\"Deleted {filename}\")\n",
    "\n",
    "for old_name, new_name in files_to_rename.items():\n",
    "    old_path = os.path.join(org_transcripts_folder, old_name)\n",
    "    new_path = os.path.join(org_transcripts_folder, new_name)\n",
    "    os.rename(old_path, new_path)\n",
    "    print(f\"Renamed {old_name} to {new_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper function to remove instances of ```text = \"...item [something]...\"``` and ```text = \"...intervals [something]...\"``` from a single TextGrid file**\n",
    "\n",
    "- To not interfere with praatio library's splitting logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_text_restriction(textgrid_path):\n",
    "    try:\n",
    "        with open(textgrid_path, \"r\", encoding=\"utf-16\") as file:\n",
    "            textgrid = file.read()\n",
    "        encoding = \"utf-16\"\n",
    "    except UnicodeError:\n",
    "        with open(textgrid_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            textgrid = file.read()\n",
    "        encoding = \"utf-8\"\n",
    "\n",
    "    text_restriction_1 = r'text = \"(.*?item \\[.*?\\].*?)\"'\n",
    "    text_restriction_2 = r'text = \"(.*?intervals \\[.*?\\].*?)\"'\n",
    "\n",
    "    def replace_brackets(match):\n",
    "        text_content = match.group(1)\n",
    "        text_content = text_content.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        return f'text = \"{text_content}\"'\n",
    "\n",
    "    # Receives: regex pattern, function to do replacement for matched patterns \n",
    "    # (result of function is used as replacement text), input string where the replacement will occur\n",
    "\n",
    "    # Function receives a match object. It is called for each match found in the input string\n",
    "    # Match object represents a specific occurence of the matched pattern\n",
    "    textgrid_fixed = re.sub(text_restriction_1, replace_brackets, textgrid)\n",
    "    textgrid_fixed_final = re.sub(text_restriction_2, replace_brackets, textgrid_fixed)\n",
    "\n",
    "    with open(textgrid_path, \"w\", encoding=encoding) as file:\n",
    "        file.write(textgrid_fixed_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove text restrictions to let praatio library run properly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_successfully = []\n",
    "cleaned_unsuccessfully = []\n",
    "for filename in os.listdir(org_transcripts_folder):\n",
    "    try:\n",
    "        textgrid_path = os.path.join(org_transcripts_folder, filename)\n",
    "        tg = textgrid.openTextgrid(textgrid_path, False)\n",
    "    except:\n",
    "        remove_text_restriction(textgrid_path)\n",
    "        try:\n",
    "            tg = textgrid.openTextgrid(textgrid_path, False)\n",
    "            cleaned_successfully.append(filename)\n",
    "        except:\n",
    "            cleaned_unsuccessfully.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3018-1.TextGrid',\n",
       " '3025-1.TextGrid',\n",
       " '3030-1.TextGrid',\n",
       " '3045-2.TextGrid',\n",
       " '3048-2.TextGrid',\n",
       " '3055-1.TextGrid',\n",
       " '3061-2.TextGrid',\n",
       " '3069-2.TextGrid',\n",
       " '3083-1.TextGrid',\n",
       " '3093-2.TextGrid',\n",
       " '3095-1.TextGrid',\n",
       " '3122-1.TextGrid',\n",
       " '3127-2.TextGrid',\n",
       " '3136-2.TextGrid',\n",
       " '3137-1.TextGrid',\n",
       " '3141-1.TextGrid',\n",
       " '3141-2.TextGrid',\n",
       " '3169-2.TextGrid',\n",
       " '3174-1.TextGrid',\n",
       " '3178-1.TextGrid',\n",
       " '3178-2.TextGrid',\n",
       " '3202-1.TextGrid',\n",
       " '3214-1.TextGrid',\n",
       " '3232-2.TextGrid',\n",
       " '3244-1.TextGrid',\n",
       " '3244-2.TextGrid',\n",
       " '3250-1.TextGrid',\n",
       " '3263-1.TextGrid']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_unsuccessfully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Code to initialise the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>USER INPUT REQUIRED</u>**\n",
    "\n",
    "- Change Relative Paths and Naming Conventions if you want \n",
    "- Set the segment duration (has to be <= 30s because of Whisper's design) and buffer between each entry (in ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio_path = ['org_wavs']\n",
    "input_textgrid_path = ['org_transcripts']\n",
    "output_train_path = ['dataset', 'train']\n",
    "output_test_path = ['dataset', 'test']\n",
    "output_compressed_path = ['dataset','data']\n",
    "compressed_filename = 'imda_nsc_p3.tar.gz'\n",
    "compressed_train_prompt_filename = 'prompts-train.txt.gz'\n",
    "compressed_test_prompt_filename = 'prompts-test.txt.gz'\n",
    "segment_duration_s = 30\n",
    "buffer_ms = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialise Paths and Create the directories**\n",
    "\n",
    "**<u>USER ACTION REQUIRED</u>**\n",
    "\n",
    "- Specify the input drive path\n",
    "- Create the ```org_wavs```, ```invalid_waves``` folders in the input drive\n",
    "- Add in the ```.wav``` from IMDA NSC to ```org_wavs``` in the input drive\n",
    "- Move the following files from ```org_wavs``` to ```invalid_wavs```: \n",
    "    - 3035-2.wav: Instantaneous timing and transcription don't match\n",
    "    - 3075-2.wav: Instantaneous timing and transcription don't match\n",
    "    - 3143-2.wav: Overlap in transcription timing\n",
    "    - 3201-1.wav: Instantaneous timing and transcription don't match\n",
    "    - 3250-2.wav: Overlap in transcription timing\n",
    "- Copy ```clean_textgrid/org_transcripts``` as ```org_transcripts``` to the input drive\n",
    "\n",
    "Can replace point 1,3 with code: add in to ```create_dir```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_drive_path = 'D:\\\\' # os.getcwd()\n",
    "output_drive_path = os.getcwd()\n",
    "input_wav_folder = os.path.join(input_drive_path, *input_audio_path)\n",
    "input_textgrid_folder = os.path.join(input_drive_path, *input_textgrid_path)\n",
    "output_train_folder_waves = os.path.join(output_drive_path, *output_train_path, 'waves')\n",
    "output_train_folder_transcripts = os.path.join(output_drive_path, *output_train_path, 'transcripts')\n",
    "output_test_folder_waves  = os.path.join(output_drive_path, *output_test_path, 'waves')\n",
    "output_test_folder_transcripts = os.path.join(output_drive_path, *output_test_path, 'transcripts')\n",
    "output_textgrids_folder = os.path.join(output_drive_path, *output_train_path, 'textgrids')\n",
    "output_compressed_folder = os.path.join(output_drive_path, *output_compressed_path)\n",
    "output_compressed_file = os.path.join(output_compressed_folder, compressed_filename)\n",
    "output_compressed_train_prompt_file = os.path.join(output_compressed_folder, compressed_train_prompt_filename)\n",
    "output_compressed_test_prompt_file = os.path.join(output_compressed_folder, compressed_test_prompt_filename)\n",
    "\n",
    "create_dir = [output_train_folder_waves, output_train_folder_transcripts,\n",
    "              output_test_folder_waves, output_test_folder_transcripts, output_textgrids_folder, output_compressed_folder]\n",
    "\n",
    "# create input wav and textgrid folder\n",
    "#create_dir = [input_wav_folder, input_textgrid_folder, output_train_folder_waves, output_train_folder_transcripts,\n",
    "              #output_test_folder_waves, output_test_folder_transcripts, output_textgrids_folder, output_compressed_folder]\n",
    "\n",
    "for dir in create_dir:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Code to process and segment the original ```.wav``` and ```.TextGrid``` files into output files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper function to clean the transcription**\n",
    "\n",
    "1. Lower-case the text\n",
    "\n",
    "2. Remove and replace annotations\n",
    "\n",
    "- Paralinguistic Phenomena: Remove '(ppb)', '(ppc)', '(ppl)', '(ppo)'\n",
    "- Acronyms: Remove '_'\n",
    "- Multi-word nouns: Replace '-' with ' '\n",
    "- Discourse particles: Remove '[' and ']'\n",
    "- Fillers: Remove '(' and ')'\n",
    "- Interjections: Remove '!'\n",
    "- Other languages: Remove '#'\n",
    "- Unclear words: Remove ```'<unk>'```\n",
    "- Incomplete words: Remove '~'\n",
    "- Short pauses: Remove ```'<s>'```\n",
    "- Invalid: Remove ```'<z>'```\n",
    "- Long-running non-english utterances: Remove ```'<nen>'```\n",
    "- Fillers: Remove ```'<fil/>'```\n",
    "- Speaker Noise: Remove ```'<spk/>'```\n",
    "- Unknown: Remove '**'\n",
    "- Non-primary speaker sound: Remove ```'<non/>'```\n",
    "- End of sentence: Remove ```'<s/>'```\n",
    "- Comma: Remove ```'<c/>'```\n",
    "- Remove all instances of ```<whatever is inside>```\n",
    "\n",
    "3. Remove extra spaces created by ```<s>``` and stuff\n",
    "\n",
    "Refer to the Transcription Guidelines by IMDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcription(transcript):\n",
    "    transcript = transcript.strip()\n",
    "    transcript = transcript.lower()\n",
    "    remove = [r'\\(ppb\\)|\\(ppc\\)|\\(ppl\\)|\\(ppo\\)', r'_', r'\\[|\\]', r'\\(|\\)', r'!', \n",
    "            r'#', r'<unk>', r'~', r'<s>', r'<z>', r'<nen>', r'<fil/>', r'<spk/>',\n",
    "            r'\\*', r'<non/>', r'<s/>', r'<c/>', r'<[^>]+>'] \n",
    "    replace = ['-']\n",
    "    for e in remove:\n",
    "        transcript = re.sub(e, '', transcript)\n",
    "    for e in replace:\n",
    "        transcript = re.sub(e, ' ', transcript)\n",
    "    transcript = re.sub(r'\\s+', ' ', transcript).strip()\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main function**\n",
    "\n",
    "- Matches a single ```.wav``` file to its respective ```.TextGrid``` file\n",
    "\n",
    "- Break the ```.wav``` file and ```.TextGrid``` files into segments such that each segment only contains a transcription that is <= 30s long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_transcript(audio_filename, input_audio_path, input_textgrid_path, output_dir_wav, output_dir_transcript, segment_duration_s, buffer):\n",
    "    # Initialise the wav and TextGrid paths of the current file\n",
    "    audio_path = os.path.join(input_audio_path, f'{audio_filename}.wav')\n",
    "    textgrid_path = os.path.join(input_textgrid_path, f'{audio_filename}.TextGrid')\n",
    "\n",
    "    audio = AudioSegment.from_wav(audio_path)\n",
    "    tg = textgrid.openTextgrid(textgrid_path, False) \n",
    "\n",
    "    # Specify the current segment index\n",
    "    segment_index = 1\n",
    "\n",
    "    # Initialise the current segment duration\n",
    "    curr_segment_duration = 0\n",
    "    # Initialise a list to hold the transcriptions for the current segment\n",
    "    curr_transcriptions = []\n",
    "    # Initialise a list to hold the audios for the current segment\n",
    "    curr_wavs = []\n",
    "    # Get the buffer in seconds -> To separate potentially unrelated speech\n",
    "    buffer_s = buffer/1000 \n",
    "    # Initialise audio buffer\n",
    "    buffer_audio = AudioSegment.silent(duration=buffer)\n",
    "\n",
    "    for tier_name in tg.tierNames: \n",
    "        tier = tg.getTier(tier_name) \n",
    "        for start,end,label in tier.entries:  \n",
    "            # Get the duration of this new entry\n",
    "            entry_duration = end-start\n",
    "\n",
    "            # if entry_duration <= segment_duration_s -> don't need to consider and\n",
    "\n",
    "            # If the new entry does not exceed our sepcified duration of each segment and\n",
    "            # adding a buffer and new entry to the current segment does not exceed our specified duration of each segment\n",
    "            # we can try accumulating the current segment\n",
    "            if entry_duration < segment_duration_s and curr_segment_duration + buffer_s + entry_duration <= segment_duration_s:\n",
    "                # Clean the transcription/label of this entry\n",
    "                curr_transcription_clean = clean_transcription(label)\n",
    "                # If this entry has text after cleaning i.e. contains proper ground truth transcription,\n",
    "                # it is a valid sample\n",
    "                if len(curr_transcription_clean) > 0:\n",
    "                    # Update the current_segment_duration\n",
    "                    curr_segment_duration = curr_segment_duration + buffer_s + entry_duration\n",
    "                    # Add the current cleaned transcription of this entry\n",
    "                    curr_transcriptions.append(curr_transcription_clean)\n",
    "                    # Add the audio of this entry: Segment the audio using the start and end time from the current TextGrid entry\n",
    "                    curr_wavs.append(audio[start*1000:(end*1000)+1]) # Add 1 ms s.t the end timing is inclusive\n",
    "\n",
    "            # If adding a buffer and new entry exceeds our specified duration of each segment,\n",
    "            # that means the current segment is completed and\n",
    "            # we save the current transcription and the segmented audio as well as perform resetting\n",
    "            elif curr_segment_duration > 0:\n",
    "                    # Join the current transcription for the segment\n",
    "                    transcript_segment = ' '.join(curr_transcriptions)\n",
    "\n",
    "                    # Initialise the transcription segment path\n",
    "                    transcript_segment_path = os.path.join(output_dir_transcript, f'{audio_filename}_{segment_index}.txt')\n",
    "                    # Write the transcription to the transcription segment file\n",
    "                    with open(transcript_segment_path, 'w') as f:\n",
    "                        f.write(f'{audio_filename}_{segment_index} {transcript_segment}')\n",
    "\n",
    "                    # Join the audio segments together with an audio buffer between them\n",
    "                    audio_segment = curr_wavs[0]\n",
    "                    for wav in curr_wavs[1:]:\n",
    "                        audio_segment = audio_segment + buffer_audio + wav\n",
    "\n",
    "                    # Initialise the audio segment path\n",
    "                    audio_segment_path = os.path.join(output_dir_wav, f'{audio_filename}_{segment_index}.wav')\n",
    "                    # Save the audio segment\n",
    "                    audio_segment.export(audio_segment_path, format=\"wav\")\n",
    "\n",
    "                    # Increment the segment index\n",
    "                    segment_index+=1\n",
    "\n",
    "                    # Resetting\n",
    "                    curr_transcription_clean = clean_transcription(label)\n",
    "                    # If the entry in the current iteration is <= than our specified duration of each segment and has text after cleaning i.e. contains proper ground truth transcription\n",
    "                    if entry_duration <= segment_duration_s and len(curr_transcription_clean) > 0:\n",
    "                        # Reset the current segment duration\n",
    "                        curr_segment_duration = entry_duration\n",
    "                        # Reset the list to hold the transcriptions for the new segment\n",
    "                        curr_transcriptions = [curr_transcription_clean]\n",
    "                        # Reset the list to hold the audios for the new segment\n",
    "                        curr_wavs = [audio[start*1000:(end*1000)+1]] # Add 1 ms s.t the end timing is inclusive\n",
    "                    # Skip the entry as a sample if it is > than our specified duration of each segment\n",
    "                    else:\n",
    "                        # Reset the new segment duration\n",
    "                        curr_segment_duration = 0\n",
    "                        # Reset the list to hold the transcriptions for the new segment\n",
    "                        curr_transcriptions = []\n",
    "                        # Reset the list to hold the audios for the new segment\n",
    "                        curr_wavs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the main function to create segments for each ```.wav``` and ```.TextGrid``` file**\n",
    "\n",
    "Output is the segmented ```.wav``` audio files and corresponding ```.txt``` transcription files that is stored in ```train/waves``` and ```train/transcripts``` respectively\n",
    "\n",
    "Note: We first put the files into the train folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_wav_folder):\n",
    "    try:\n",
    "        filename = filename.split('.')[0]\n",
    "        process_audio_transcript(filename, input_wav_folder, input_textgrid_folder, output_train_folder_waves, output_train_folder_transcripts, segment_duration_s, buffer_ms)\n",
    "    except Exception as e:\n",
    "        print(f\"Filename {filename}\")\n",
    "        print(f\"Exception {e}\")\n",
    "        # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Move a split of the ```.wav``` files and ```.txt``` file to test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of samples is 100345\n",
      "The total number of training samples will be 80276\n",
      "The total number of test samples will be 20069\n"
     ]
    }
   ],
   "source": [
    "test_split = 0.2\n",
    "\n",
    "sample_filenames = []\n",
    "for filename in os.listdir(output_train_folder_waves):\n",
    "    sample_filenames.append(filename.split('.')[0])\n",
    "\n",
    "samples = len(sample_filenames)\n",
    "\n",
    "num_train_samples = math.floor((1-test_split)*samples)\n",
    "num_test_samples = samples-num_train_samples\n",
    "\n",
    "print(f\"The total number of samples is {samples}\")\n",
    "print(f\"The total number of training samples will be {num_train_samples}\")\n",
    "print(f\"The total number of test samples will be {num_test_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(sample_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_test_samples):\n",
    "    filename = sample_filenames[i]\n",
    "\n",
    "    source_wav = os.path.join(output_train_folder_waves, filename + '.wav')\n",
    "    destination_wav = os.path.join(output_test_folder_waves)\n",
    "    shutil.move(source_wav, destination_wav)\n",
    "\n",
    "    source_transcript = os.path.join(output_train_folder_transcripts, filename + '.txt')\n",
    "    destination_transcript = os.path.join(output_test_folder_transcripts)\n",
    "    shutil.move(source_transcript, destination_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write the ```/train/prompts.txt``` and ```/test/prompts.txt``` files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_path = os.path.join(output_drive_path, *output_train_path, 'prompts.txt')\n",
    "with open(train_prompts_path, 'a') as outfile:\n",
    "    for filename in os.listdir(output_train_folder_transcripts):\n",
    "        file_path = os.path.join(output_train_folder_transcripts, filename)\n",
    "        with open(file_path, \"r\") as infile:\n",
    "            outfile.write(infile.read() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_path = os.path.join(output_drive_path, *output_test_path, 'prompts.txt')\n",
    "with open(test_prompts_path, 'a') as outfile:\n",
    "    for filename in os.listdir(output_test_folder_transcripts):\n",
    "        file_path = os.path.join(output_test_folder_transcripts, filename)\n",
    "        with open(file_path, \"r\") as infile:\n",
    "            outfile.write(infile.read() + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Compress the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compress the folders into ```.tar.gzip```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_compress = [train_prompts_path, output_train_folder_waves, test_prompts_path, output_test_folder_waves]\n",
    "\n",
    "with tarfile.open(output_compressed_file, \"w:gz\") as tar_gz:\n",
    "    for path in paths_to_compress:\n",
    "        rel_path = os.path.relpath(path, os.path.join(os.getcwd(), *output_compressed_path))\n",
    "        tar_gz.add(path, arcname=rel_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_prompts_path, 'rb') as f_in, gzip.open(output_compressed_train_prompt_file, 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_prompts_path, 'rb') as f_in, gzip.open(output_compressed_test_prompt_file, 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_prompts_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    train_prompts_filenames = sorted([l.split(' ')[0] for l in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3000-1_11',\n",
       " '3000-1_12',\n",
       " '3000-1_13',\n",
       " '3000-1_16',\n",
       " '3000-1_17',\n",
       " '3000-1_19',\n",
       " '3000-1_2',\n",
       " '3000-1_20',\n",
       " '3000-1_21',\n",
       " '3000-1_22']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prompts_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wavs_filenames = []\n",
    "for filename in os.listdir(output_train_folder_waves):\n",
    "    filename = filename.split('.')[0]\n",
    "    train_wavs_filenames.append(filename)\n",
    "train_waves_filename = sorted(train_wavs_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3000-1_11',\n",
       " '3000-1_12',\n",
       " '3000-1_13',\n",
       " '3000-1_16',\n",
       " '3000-1_17',\n",
       " '3000-1_19',\n",
       " '3000-1_2',\n",
       " '3000-1_20',\n",
       " '3000-1_21',\n",
       " '3000-1_22']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_waves_filename[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prompts_filenames==train_waves_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_prompts_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    test_prompts_filenames = sorted([l.split(' ')[0] for l in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3000-1_1',\n",
       " '3000-1_10',\n",
       " '3000-1_14',\n",
       " '3000-1_15',\n",
       " '3000-1_18',\n",
       " '3000-1_29',\n",
       " '3000-1_44',\n",
       " '3000-1_45',\n",
       " '3000-1_49',\n",
       " '3000-1_50']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompts_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wavs_filenames = []\n",
    "for filename in os.listdir(output_test_folder_waves):\n",
    "    filename = filename.split('.')[0]\n",
    "    test_wavs_filenames.append(filename)\n",
    "test_waves_filename = sorted(test_wavs_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3000-1_1',\n",
       " '3000-1_10',\n",
       " '3000-1_14',\n",
       " '3000-1_15',\n",
       " '3000-1_18',\n",
       " '3000-1_29',\n",
       " '3000-1_44',\n",
       " '3000-1_45',\n",
       " '3000-1_49',\n",
       " '3000-1_50']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_wavs_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompts_filenames==test_wavs_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80276"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_prompts_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20069"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_prompts_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
