{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Get Data \n",
    "\n",
    "National Speech Corpus\n",
    "- Part 3: 1000 hours of conversational speech data (Used by Home team)\n",
    "- Part 2: 1000 hours of prompted recordings of random sentences containing local words and entities (Used by some developer)\n",
    "- Part 4: Conversational code-switched data (from Singaporean English to various native languages)\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "- https://medium.com/htx-dsai/finetuning-whisper-for-the-singaporean-home-team-context-a3ae1a6ae809\n",
    "- https://www.jensenlwt.com/blog/singlish-whisper-finetuning-asr-for-singapore-unique-english\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Prepare Data\n",
    "\n",
    "- Match each transcript sentence to its corresponding audio file\n",
    "- Check on the environment where the audio is recorded (decide the environment)\n",
    "    - Hometeam\n",
    "        - The NSC Part 3 recordings are split into two environments, each with two different microphones used for recording. In the first environment, where speakers were in the same room, we selected the recordings using the close-talk mic as this isolated the main speakerâ€™s voice (without picking up background noise or the secondary speaker). For the second environment with speakers in different rooms, we chose to use the standing microphone recordings, as opposed to recordings via telephone.\n",
    "    - Same room environment: Close-talk mic that isolates main speaker's voice \n",
    "    - Different room environment: Standing microphone as opposed to telephone\n",
    "- Clean the transcripts by removing annotations\n",
    "- Normalise the transcript text\n",
    "    - Remove punctuations\n",
    "    - Lowercase text\n",
    "- Create 30s audio segments with corresponding transcripts\n",
    "    - Using time segments from ```TextGrid files```, splice out corresponding segments from WAV files\n",
    "    - Combine shorter consecutive segments (?)\n",
    "    - 30s: Whisper's feature extractor ensures all audio is 30s (intrinsic design)\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "- https://medium.com/htx-dsai/finetuning-whisper-for-the-singaporean-home-team-context-a3ae1a6ae809\n",
    "- https://www.jensenlwt.com/blog/singlish-whisper-finetuning-asr-for-singapore-unique-english\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "More on dataset part 3 (see ```ABOUT.txt```):\n",
    "\n",
    "Part 3 consists of about 1000 hours of conversational data recorded from about 1000 local English speakers, split into pairs. The data includes conversations covering daily life and of speakers playing games provided. \n",
    "\n",
    "Part 3's recordings were split into 2 environments. In the Same Room environment where speakers were in same room, the recordings were done using 2 microphones: a close-talk mic and a boundary mic. In the Separate Room environment, speakers were separated into individual rooms. The recordings were done using 2 microphones in each room: a standing mic and a telephone. \n",
    "\n",
    "Part 3 is further organised into a six subdirectories, 3 for each recording environment (Same Room or Separate Room). Among each group of 3 subdirectories, 1 contains transcriptions, while the remaining 2 contain audio data from each of the two microphones used for the environment. There is also a manifest document at the root of the Part 3 folder that lists the files released.\n",
    "\n",
    "\n",
    "Summary of Part 3 data organization:\n",
    "- Same Room environment, files organized by speaker number:\n",
    "    - /Scripts Same: Orthographic transcripts saved in TextGrid format\n",
    "    - /Audio Same BoundaryMic: Audio files in WAV format recorded using the boundary mic, sampled at 16kHz\n",
    "    - /Audio Same CloseMic: Audio files in WAV format recorded using the close-talk mic, sampled at 16kHz\n",
    "\n",
    "\n",
    "- Separate Room environment, files organized by speaker number and session number:\n",
    "    - /Scripts Separate: Orthographic transcripts saved in TextGrid format \n",
    "    - /Audio Separate IVR: Audio files in WAV format recorded using the telephone, sampled at 16kHz\n",
    "    - /Audio Separate StandingMic: Audio files in WAV format recorded using the standing mic, sampled at 16kHz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Iteration 1: Simple Example/Debugging**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Match 3000-1.wav and 3000-1.TEXTGRID**\n",
    "\n",
    "- Use Dataset Part 3 (used by Home Team)\n",
    "- Specific datasets (used by Home Team)\n",
    "    - Audio Same CloseMic\n",
    "    - Audio Separate StandingMic \n",
    "- In this simple example, first settle the Audio Same CloseMic dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Create 30s segments from 3000-1.wav and 3000-1.TEXTGRID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jiaaro/pydub#installation\n",
    "# https://github.com/timmahrt/praatIO/tree/main\n",
    "\n",
    "import os\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Initialise input and output paths\n",
    "audio_path = os.path.join(os.getcwd(), 'dataset', 'part3', 'simple_example', '3000-1.wav')\n",
    "textgrid_path = os.path.join(os.getcwd(), 'dataset', 'part3', 'simple_example', '3000-1.TextGrid')\n",
    "output_dir = os.path.join(os.getcwd(), 'dataset', 'part3', 'simple_example', '3000-1-splits')\n",
    "\n",
    "# https://github.com/jiaaro/pydub\n",
    "# https://github.com/timmahrt/praatIO\n",
    "# https://timmahrt.github.io/praatIO/praatio.html\n",
    "audio = AudioSegment.from_wav(audio_path)\n",
    "tg = textgrid.openTextgrid(textgrid_path, False) # do not include intervals and points with empty labels\n",
    "\n",
    "# pydub does things in milliseconds\n",
    "segment_duration_ms = 30 * 1000  \n",
    "\n",
    "# Get total duration of the audio in milliseconds\n",
    "audio_duration = len(audio)\n",
    "\n",
    "# Initialize start time and segment index\n",
    "start_time = 0\n",
    "segment_index = 1\n",
    "\n",
    "#while start_time < audio_duration:\n",
    "    # Initialise end time of the segment\n",
    "end_time = min(start_time + segment_duration_ms, audio_duration)\n",
    "\n",
    "# Extract audio segment given the current start and end timing\n",
    "audio_segment = audio[start_time:end_time]\n",
    "\n",
    "# Save the audio segment\n",
    "audio_segment_path = os.path.join(output_dir, f'segment_{segment_index}.wav')\n",
    "audio_segment.export(audio_segment_path, format=\"wav\")\n",
    "\n",
    "# Extract the corresponding TextGrid segment\n",
    "# https://timmahrt.github.io/praatIO/praatio/data_classes/textgrid.html\n",
    "tg_segment = tg.crop(start_time / 1000, end_time / 1000, mode=\"truncated\", rebaseToZero=False)\n",
    "\n",
    "# Check tg_segment \n",
    "# https://timmahrt.github.io/praatIO/praatio/data_classes/textgrid.html\n",
    "tg_segment_path = os.path.join(output_dir, 'tg_segment.TextGrid')\n",
    "tg_segment.save(tg_segment_path, \"long_textgrid\", True)\n",
    "\n",
    "# Collect transcriptions from the TextGrid segment\n",
    "transcriptions = []\n",
    "for tier_name in tg_segment.tierNames: # For each tier (in order) in the TextGrid segment\n",
    "    tier = tg_segment.getTier(tier_name) # Get the tier\n",
    "    for entry in tier.entries: # For each of its entries, extract the labels \n",
    "        if entry.label.strip():  # Only include non-empty transcriptions -> but should be handled above already\n",
    "            transcriptions.append(entry.label)\n",
    "\n",
    "# Save the transcriptions to a text file\n",
    "transcription_path = os.path.join(output_dir, f'segment_{segment_index}_transcription.txt')\n",
    "with open(transcription_path, 'w') as f:\n",
    "    f.write(\"\\n\".join(transcriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_audio = os.path.join(output_dir, 'segment_1.wav')\n",
    "\n",
    "from IPython.display import Audio\n",
    "display(Audio(output_dir_audio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transcription**\n",
    "```\n",
    "<S>\n",
    "(um) you can go first\n",
    "<S>\n",
    "you guys are going to stand here [ah]\n",
    "<S>\n",
    "they are like !wow! this is a weird topic (um)\n",
    "<S>\n",
    "Singapore and Malaysia are like\n",
    "<S>\n",
    "you know brothers but not really brothers brothers on a on a tricky relationship\n",
    "<S>\n",
    "you know what let's skip this topic\n",
    "<S>\n",
    "next do I go do I go next\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TextGrid**\n",
    "```\n",
    "File type = \"ooTextFile\"\n",
    "Object class = \"TextGrid\"\n",
    "\n",
    "xmin = 0 \n",
    "xmax = 30 \n",
    "tiers? <exists> \n",
    "size = 1 \n",
    "item []: \n",
    "    item [1]:\n",
    "        class = \"IntervalTier\" \n",
    "        name = \"3000-1\" \n",
    "        xmin = 0 \n",
    "        xmax = 30 \n",
    "        intervals: size = 14 \n",
    "        intervals [1]:\n",
    "            xmin = 0 \n",
    "            xmax = 1.556 \n",
    "            text = \"<S>\" \n",
    "        intervals [2]:\n",
    "            xmin = 1.556 \n",
    "            xmax = 2.661 \n",
    "            text = \"(um) you can go first\" \n",
    "        intervals [3]:\n",
    "            xmin = 2.661 \n",
    "            xmax = 3.848 \n",
    "            text = \"<S>\" \n",
    "        intervals [4]:\n",
    "            xmin = 3.848 \n",
    "            xmax = 4.998 \n",
    "            text = \"you guys are going to stand here [ah]\" \n",
    "        intervals [5]:\n",
    "            xmin = 4.998 \n",
    "            xmax = 10.473 \n",
    "            text = \"<S>\" \n",
    "        intervals [6]:\n",
    "            xmin = 10.473 \n",
    "            xmax = 13.531 \n",
    "            text = \"they are like !wow! this is a weird topic (um)\" \n",
    "        intervals [7]:\n",
    "            xmin = 13.531 \n",
    "            xmax = 16.156 \n",
    "            text = \"<S>\" \n",
    "        intervals [8]:\n",
    "            xmin = 16.156 \n",
    "            xmax = 17.868 \n",
    "            text = \"Singapore and Malaysia are like\" \n",
    "        intervals [9]:\n",
    "            xmin = 17.868 \n",
    "            xmax = 19.781 \n",
    "            text = \"<S>\" \n",
    "        intervals [10]:\n",
    "            xmin = 19.781 \n",
    "            xmax = 24.718 \n",
    "            text = \"you know brothers but not really brothers brothers on a on a tricky relationship\" \n",
    "        intervals [11]:\n",
    "            xmin = 24.718 \n",
    "            xmax = 26.281 \n",
    "            text = \"<S>\" \n",
    "        intervals [12]:\n",
    "            xmin = 26.281 \n",
    "            xmax = 27.318 \n",
    "            text = \"you know what let's skip this topic\" \n",
    "        intervals [13]:\n",
    "            xmin = 27.318 \n",
    "            xmax = 28.156 \n",
    "            text = \"<S>\" \n",
    "        intervals [14]:\n",
    "            xmin = 28.156 \n",
    "            xmax = 30 \n",
    "            text = \"next do I go do I go next\" \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Clean and format the transcripts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_transcript = os.path.join(output_dir, 'segment_1_transcription.txt')\n",
    "\n",
    "with open(output_dir_transcript, 'r') as f:\n",
    "    transcript = ' '.join(line.strip() for line in f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Cleaning</u>\n",
    "\n",
    "1. Lower-case the text\n",
    "\n",
    "2. Remove and replace annotations\n",
    "\n",
    "- Acronyms: Remove '_'\n",
    "- Multi-word nouns: Replace '-' with ' '\n",
    "- Discourse particles: Remove '[' and ']'\n",
    "- Fillers: Remove '(' and ')'\n",
    "- Interjections: Remove '!'\n",
    "- Paralinguistic Phenomena: Remove '(ppb)', '(ppc)', '(ppl)', '(ppo)'\n",
    "- Other languages: Remove '#'\n",
    "- Unclear words: Remove ```'<unk>'```\n",
    "- Incomplete words: Remove '~'\n",
    "- Short pauses: Remove ```'<s>'```\n",
    "- Invalid: Remove ```'<z>'```\n",
    "- Long-running non-english utterances: Remove ```'<nen>'```\n",
    "- Fillers: Remove ```'<fil/>'```\n",
    "- Speaker Noise: Remove ```'<spk/>'```\n",
    "- Unknown: Remove '**'\n",
    "- Non-primary speaker sound: Remove ```'<non/>'```\n",
    "- End of sentence: Remove ```'<s/>'```\n",
    "- Comma: Remove ```'<c/>'```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "transcript = transcript.lower()\n",
    "\n",
    "remove = [r'_', r'\\[|\\]', r'\\(|\\)', r'!', r'\\(ppb\\)|\\(ppc\\)|\\(ppl\\)|\\(ppo\\)', \n",
    "          r'#', r'<unk>', r'~', r'<s>', r'<z>', r'<nen>', r'<fil/>', r'<spk/>',\n",
    "          r'\\*', r'<non/>', r'<s/>', r'<c/>']\n",
    "\n",
    "replace = ['-']\n",
    "\n",
    "\n",
    "for e in remove:\n",
    "    transcript = re.sub(e, '', transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in replace:\n",
    "    transcript = re.sub(e, ' ', transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra spaces created by <s> and stuff\n",
    "transcript = re.sub(r'\\s+', ' ', transcript).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need to change the order** \n",
    "\n",
    "(ppl) (ppb) etc. should be put infront because if the parantheses are removed, they won't be matched later\n",
    "\n",
    "Also need to remove all ```<example_word>```, example: ```<malay>malay word</malay>```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = ['(ppl)','(test)','sfs','(rdg)', 'tg_s']\n",
    "testing_2 = ' '.join(test.strip() for test in testing)\n",
    "remove = [r'\\(ppb\\)|\\(ppc\\)|\\(ppl\\)|\\(ppo\\)', r'_', r'\\[|\\]', r'\\(|\\)', r'!', \n",
    "            r'#', r'<unk>', r'~', r'<s>', r'<z>', r'<nen>', r'<fil/>', r'<spk/>',\n",
    "            r'\\*', r'<non/>', r'<s/>', r'<c/>']\n",
    "for e in remove:\n",
    "    testing_2 = re.sub(e, '', testing_2)\n",
    "testing_2 = re.sub(r'\\s+', ' ', testing_2).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jiaaro/pydub#installation\n",
    "# https://github.com/timmahrt/praatIO/tree/main\n",
    "\n",
    "import os\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Initialise input and output paths\n",
    "audio_path = os.path.join(os.getcwd(), 'dataset', 'part3', 'simple_example', '3000-1.wav')\n",
    "textgrid_path = os.path.join(os.getcwd(), 'dataset', 'part3', 'simple_example', '3000-1.TextGrid')\n",
    "output_dir = os.path.join(os.getcwd(), 'dataset', 'part3', 'simple_example', '3000-1-splits')\n",
    "\n",
    "# https://github.com/jiaaro/pydub\n",
    "# https://github.com/timmahrt/praatIO\n",
    "# https://timmahrt.github.io/praatIO/praatio.html\n",
    "audio = AudioSegment.from_wav(audio_path)\n",
    "tg = textgrid.openTextgrid(textgrid_path, False) # do not include intervals and points with empty labels\n",
    "\n",
    "# pydub does things in milliseconds\n",
    "segment_duration_ms = 30 * 1000  \n",
    "\n",
    "# Get total duration of the audio in milliseconds\n",
    "audio_duration = len(audio)\n",
    "\n",
    "# Initialize start time and segment index\n",
    "start_time = 0\n",
    "segment_index = 1\n",
    "\n",
    "#while start_time < audio_duration:\n",
    "    # Initialise end time of the segment\n",
    "end_time = min(start_time + segment_duration_ms, audio_duration)\n",
    "\n",
    "# Extract audio segment given the current start and end timing\n",
    "audio_segment = audio[start_time:end_time]\n",
    "\n",
    "# Save the audio segment\n",
    "audio_segment_path = os.path.join(output_dir, f'segment_{segment_index}.wav')\n",
    "audio_segment.export(audio_segment_path, format=\"wav\")\n",
    "\n",
    "# Extract the corresponding TextGrid segment\n",
    "# https://timmahrt.github.io/praatIO/praatio/data_classes/textgrid.html\n",
    "tg_segment = tg.crop(start_time / 1000, end_time / 1000, mode=\"truncated\", rebaseToZero=False)\n",
    "\n",
    "# Check tg_segment \n",
    "# https://timmahrt.github.io/praatIO/praatio/data_classes/textgrid.html\n",
    "tg_segment_path = os.path.join(output_dir, 'tg_segment.TextGrid')\n",
    "tg_segment.save(tg_segment_path, \"long_textgrid\", True)\n",
    "\n",
    "# Collect transcriptions from the TextGrid segment\n",
    "transcriptions = []\n",
    "for tier_name in tg_segment.tierNames: # For each tier (in order) in the TextGrid segment\n",
    "    tier = tg_segment.getTier(tier_name) # Get the tier\n",
    "    for entry in tier.entries: # For each of its entries, extract the labels \n",
    "        if entry.label.strip():  # Only include non-empty transcriptions -> but should be handled above already\n",
    "            transcriptions.append(entry.label)\n",
    "\n",
    "print(transcriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(line.strip() for line in transcriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcription(transcript):\n",
    "    transcript = ' '.join(line.strip() for line in transcript)\n",
    "\n",
    "    transcript = transcript.lower()\n",
    "\n",
    "    remove = [r'_', r'\\[|\\]', r'\\(|\\)', r'!', r'\\(ppb\\)|\\(ppc\\)|\\(ppl\\)|\\(ppo\\)', \n",
    "            r'#', r'<unk>', r'~', r'<s>', r'<z>', r'<nen>', r'<fil/>', r'<spk/>',\n",
    "            r'\\*', r'<non/>', r'<s/>', r'<c/>']\n",
    "\n",
    "    replace = ['-']\n",
    "\n",
    "\n",
    "    for e in remove:\n",
    "        transcript = re.sub(e, '', transcript)\n",
    "\n",
    "    for e in replace:\n",
    "        transcript = re.sub(e, ' ', transcript)\n",
    "\n",
    "    transcript = re.sub(r'\\s+', ' ', transcript).strip()\n",
    "\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_transcription(transcriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Things to check**\n",
    "- check out 3000-1_33: <malay>malay word</malay>\n",
    "- check out 3000-1_36: no transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Iteration 2: Check if the transcriptions are still ok**\n",
    "\n",
    "```\n",
    "- imda_nsc_p3.tar.gz\n",
    "    - imda_nsc_p3.tar\n",
    "        - train\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files\n",
    "            - waves\n",
    "                - 3000-1_1.wav\n",
    "                - 3000-1_2.wav\n",
    "                - 3000-1_3.wav\n",
    "- prompts-train.txt.gz\n",
    "    - prompts-train.txt: Contains transcriptions for all the train .wav files\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import os\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcription(transcript):\n",
    "    transcript = ' '.join(line.strip() for line in transcript)\n",
    "    transcript = transcript.lower()\n",
    "    remove = [r'\\(ppb\\)|\\(ppc\\)|\\(ppl\\)|\\(ppo\\)', r'_', r'\\[|\\]', r'\\(|\\)', r'!', \n",
    "            r'#', r'<unk>', r'~', r'<s>', r'<z>', r'<nen>', r'<fil/>', r'<spk/>',\n",
    "            r'\\*', r'<non/>', r'<s/>', r'<c/>', r'<[^>]+>'] # Addition: remove all instances of <whatever's inside>\n",
    "    replace = ['-']\n",
    "    for e in remove:\n",
    "        transcript = re.sub(e, '', transcript)\n",
    "    for e in replace:\n",
    "        transcript = re.sub(e, ' ', transcript)\n",
    "    transcript = re.sub(r'\\s+', ' ', transcript).strip()\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input paths\n",
    "audio_filename = '3000-2'\n",
    "\n",
    "audio_path = os.path.join(os.getcwd(), 'dataset', 'dev', 'org_wavs', f'{audio_filename}.wav')\n",
    "textgrid_path = os.path.join(os.getcwd(), 'dataset', 'dev', 'org_transcripts', f'{audio_filename}.TextGrid')\n",
    "\n",
    "# Output paths\n",
    "# output_dir_train_wav = os.path.join(os.getcwd(), 'dataset', 'imda_nsc_prototype', 'train', 'waves', f'{audio_filename}')\n",
    "output_dir_train_wav = os.path.join(os.getcwd(), 'dataset', 'dev', 'train', 'waves')\n",
    "os.makedirs(output_dir_train_wav, exist_ok=True)\n",
    "output_dir_train_text = os.path.join(os.getcwd(), 'dataset', 'dev', 'train', 'prompts.txt')\n",
    "output_dir_train_tg = os.path.join(os.getcwd(), 'dataset', 'dev', 'train', 'textgrids')\n",
    "\n",
    "# https://github.com/jiaaro/pydub\n",
    "# https://github.com/timmahrt/praatIO\n",
    "# https://timmahrt.github.io/praatIO/praatio.html\n",
    "# Extract the audio and text grid\n",
    "audio = AudioSegment.from_wav(audio_path)\n",
    "tg = textgrid.openTextgrid(textgrid_path, False) # do not include intervals and points with empty labels\n",
    "\n",
    "# pydub does things in milliseconds\n",
    "segment_duration_ms = 30 * 1000  \n",
    "\n",
    "# Get total duration of the audio in milliseconds\n",
    "audio_duration = len(audio)\n",
    "\n",
    "# Initialize start time and segment index\n",
    "start_time = 0\n",
    "segment_index = 1\n",
    "\n",
    "while start_time < audio_duration:\n",
    "    # Initialise end time of the segment\n",
    "    end_time = min(start_time + segment_duration_ms, audio_duration)\n",
    "\n",
    "    # Extract audio segment given the current start and end timing\n",
    "    audio_segment = audio[start_time:end_time]\n",
    "\n",
    "    # Extract the corresponding TextGrid segment\n",
    "    # https://timmahrt.github.io/praatIO/praatio/data_classes/textgrid.html\n",
    "    tg_segment = tg.crop(start_time / 1000, end_time / 1000, mode=\"truncated\", rebaseToZero=False)\n",
    "\n",
    "    tg_segment_path = os.path.join(output_dir_train_tg, f'{audio_filename}_{segment_index}.TextGrid')\n",
    "    tg_segment.save(tg_segment_path, \"long_textgrid\", True)\n",
    "\n",
    "    # Collect transcriptions from the TextGrid segment\n",
    "    transcriptions = []\n",
    "    for tier_name in tg_segment.tierNames: # For each tier (in order) in the TextGrid segment\n",
    "        tier = tg_segment.getTier(tier_name) # Get the tier\n",
    "        for entry in tier.entries: # For each of its entries, extract the labels \n",
    "            if entry.label.strip():  # Only include non-empty transcriptions -> but should be handled above already\n",
    "                transcriptions.append(entry.label)\n",
    "\n",
    "    print(f\"Dirty transcription: {transcriptions}\")\n",
    "    # Clean the transcriptions\n",
    "    transcriptions_clean = clean_transcription(transcriptions)\n",
    "    print(f\"Clean transcription: {transcriptions_clean}\")\n",
    "    #print(\"\")\n",
    "\n",
    "    if len(transcriptions_clean) > 0:\n",
    "        # Save the transcriptions to a text file, append mode\n",
    "        with open(output_dir_train_text, 'a') as f:\n",
    "            f.write(f'{audio_filename}_{segment_index} {transcriptions_clean}\\n')\n",
    "\n",
    "        # Save the audio segment\n",
    "        audio_segment_path = os.path.join(output_dir_train_wav, f'{audio_filename}_{segment_index}.wav')\n",
    "        audio_segment.export(audio_segment_path, format=\"wav\")\n",
    "\n",
    "        start_time+=segment_duration_ms\n",
    "        segment_index+=1\n",
    "    else:\n",
    "        start_time+=segment_duration_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**```tar.gz``` file resources**\n",
    "\n",
    "- https://stackoverflow.com/questions/2032403/how-to-create-full-compressed-tar-file-using-python\n",
    "- https://www.tutorialspoint.com/how-to-create-a-tar-file-using-python\n",
    "- https://www.geeksforgeeks.org/python-os-path-relpath-method/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**```txt.gz file resources```**\n",
    "- https://stackoverflow.com/questions/8156707/gzip-a-file-in-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**```folder structure resources```**\n",
    "- https://huggingface.co/docs/datasets/en/audio_dataset#loading-script\n",
    "- https://huggingface.co/datasets/AILAB-VNUHCM/vivos/tree/main/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Iteration 3: Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Before running processing code</u>\n",
    "```\n",
    "dataset\n",
    "- testing\n",
    "    - data: Empty\n",
    "    - org_waves: Manually add in .wav files\n",
    "        - 3000-1.wav\n",
    "        - 3000-2.wav\n",
    "        - ...\n",
    "    - org_transcripts: Manually add in .TextGrid files\n",
    "        - 3000-1.TextGrid\n",
    "        - 3000-2.TextGrid\n",
    "        - ...\n",
    "    - train\n",
    "        - waves: Empty\n",
    "        - transcripts: Empty\n",
    "    - test\n",
    "        - waves: Empty\n",
    "        - transcripts: Empty\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "<u>After running processing code</u>\n",
    "```\n",
    "dataset\n",
    "- testing\n",
    "    - data: Empty\n",
    "    - org_waves: Manually add in .wav files\n",
    "        - 3000-1.wav\n",
    "        - 3000-2.wav\n",
    "        - ...\n",
    "    - org_transcripts: Manually add in .TextGrid files\n",
    "        - 3000-1.TextGrid\n",
    "        - 3000-2.TextGrid\n",
    "        - ...\n",
    "    - train\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in train\n",
    "        - waves\n",
    "            - 3000-1_1.wav\n",
    "            - 3000-1_2.wav\n",
    "            - 3000-1_3.wav\n",
    "            - ...\n",
    "            - 3000-2_1.wav\n",
    "            - 3000-2_2.wav\n",
    "            - 3000-2_3.wav\n",
    "        - transcripts\n",
    "            - 3000-1_1.txt\n",
    "            - 3000-1_2.txt\n",
    "            - 3000-1_3.txt\n",
    "            - ...\n",
    "            - 3000-2_1.txt\n",
    "            - 3000-2_2.txt\n",
    "            - 3000-2_3.txt\n",
    "    - test\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in test\n",
    "        - waves\n",
    "            - 3000-3_1.wav\n",
    "            - 3000-3_2.wav\n",
    "            - 3000-3_3.wav\n",
    "            - ...\n",
    "            - 3000-4_1.wav\n",
    "            - 3000-4_2.wav\n",
    "            - 3000-4_3.wav\n",
    "        - transcripts\n",
    "            - 3000-3_1.txt\n",
    "            - 3000-3_2.txt\n",
    "            - 3000-3_3.txt\n",
    "            - ...\n",
    "            - 3000-4_1.txt\n",
    "            - 3000-4_2.txt\n",
    "            - 3000-4_3.txt\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "<u>After running compression code</u>\n",
    "\n",
    "```\n",
    "data\n",
    "    - input_name.tar.gz\n",
    "        - train\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files\n",
    "            - waves\n",
    "                - 3000-1_1.wav\n",
    "                - 3000-1_2.wav\n",
    "                - 3000-1_3.wav\n",
    "                - ...\n",
    "                - 3000-2_1.wav\n",
    "                - 3000-2_2.wav\n",
    "                - 3000-2_3.wav\n",
    "        - test\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files\n",
    "            - waves\n",
    "                - 3000-3_1.wav\n",
    "                - 3000-3_2.wav\n",
    "                - 3000-3_3.wav\n",
    "                - ...\n",
    "                - 3000-4_1.wav\n",
    "                - 3000-4_2.wav\n",
    "                - 3000-4_3.wav\n",
    "    - prompts-train.txt.gz\n",
    "        - prompts-train.txt: Contains transcriptions for all the train .wav files -> take this from train/prompts.txt\n",
    "    - prompts-test.txt.gz\n",
    "        - prompts-test.txt: Contains transcriptions for all the test .wav files -> take this from test/prompts.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import gzip\n",
    "import math\n",
    "import random\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Relative Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio_path = ['dataset', 'testing', 'org_wavs']\n",
    "input_textgrid_path = ['dataset', 'testing', 'org_transcripts']\n",
    "output_train_path = ['dataset', 'testing', 'train']\n",
    "output_test_path = ['dataset', 'testing', 'test']\n",
    "output_compressed_path = ['dataset', 'testing']\n",
    "compressed_filename = 'imda_nsc_p3_testing.tar.gz'\n",
    "compressed_train_prompt_filename = 'prompts-train.txt.gz'\n",
    "compressed_test_prompt_filename = 'prompts-test.txt.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialise Paths and Create the directories**\n",
    "\n",
    "**IMPT**: Remember to add in the ```.wav``` and ```.TextGrid``` files to org_waves and org_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wav_folder = os.path.join(os.getcwd(), *input_audio_path)\n",
    "input_textgrid_folder = os.path.join(os.getcwd(), *input_textgrid_path)\n",
    "output_train_folder_waves = os.path.join(os.getcwd(), *output_train_path, 'waves')\n",
    "output_train_folder_transcripts = os.path.join(os.getcwd(), *output_train_path, 'transcripts')\n",
    "output_test_folder_waves  = os.path.join(os.getcwd(), *output_test_path, 'waves')\n",
    "output_test_folder_transcripts = os.path.join(os.getcwd(), *output_test_path, 'transcripts')\n",
    "output_textgrids_folder = os.path.join(os.getcwd(), *output_train_path, 'textgrids')\n",
    "output_compressed_folder = os.path.join(os.getcwd(), *output_compressed_path, 'data')\n",
    "output_compressed_file = os.path.join(output_compressed_folder, compressed_filename)\n",
    "output_compressed_train_prompt_file = os.path.join(output_compressed_folder, compressed_train_prompt_filename)\n",
    "output_compressed_test_prompt_file = os.path.join(output_compressed_folder, compressed_test_prompt_filename)\n",
    "\n",
    "create_dir = [input_wav_folder, input_textgrid_folder, output_train_folder_waves, output_train_folder_transcripts,\n",
    "              output_test_folder_waves, output_test_folder_transcripts, output_textgrids_folder, output_compressed_folder]\n",
    "\n",
    "for dir in create_dir:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper function to clean the transcription**\n",
    "\n",
    "1. Lower-case the text\n",
    "\n",
    "2. Remove and replace annotations\n",
    "\n",
    "- Paralinguistic Phenomena: Remove '(ppb)', '(ppc)', '(ppl)', '(ppo)'\n",
    "- Acronyms: Remove '_'\n",
    "- Multi-word nouns: Replace '-' with ' '\n",
    "- Discourse particles: Remove '[' and ']'\n",
    "- Fillers: Remove '(' and ')'\n",
    "- Interjections: Remove '!'\n",
    "- Other languages: Remove '#'\n",
    "- Unclear words: Remove ```'<unk>'```\n",
    "- Incomplete words: Remove '~'\n",
    "- Short pauses: Remove ```'<s>'```\n",
    "- Invalid: Remove ```'<z>'```\n",
    "- Long-running non-english utterances: Remove ```'<nen>'```\n",
    "- Fillers: Remove ```'<fil/>'```\n",
    "- Speaker Noise: Remove ```'<spk/>'```\n",
    "- Unknown: Remove '**'\n",
    "- Non-primary speaker sound: Remove ```'<non/>'```\n",
    "- End of sentence: Remove ```'<s/>'```\n",
    "- Comma: Remove ```'<c/>'```\n",
    "- Remove all instances of ```<whatever is inside>```\n",
    "\n",
    "3. Remove extra spaces created by ```<s>``` and stuff\n",
    "\n",
    "Refer to the Transcription Guidelines by IMDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcription(transcript):\n",
    "    transcript = ' '.join(line.strip() for line in transcript)\n",
    "    transcript = transcript.lower()\n",
    "    remove = [r'\\(ppb\\)|\\(ppc\\)|\\(ppl\\)|\\(ppo\\)', r'_', r'\\[|\\]', r'\\(|\\)', r'!', \n",
    "            r'#', r'<unk>', r'~', r'<s>', r'<z>', r'<nen>', r'<fil/>', r'<spk/>',\n",
    "            r'\\*', r'<non/>', r'<s/>', r'<c/>', r'<[^>]+>'] \n",
    "    replace = ['-']\n",
    "    for e in remove:\n",
    "        transcript = re.sub(e, '', transcript)\n",
    "    for e in replace:\n",
    "        transcript = re.sub(e, ' ', transcript)\n",
    "    transcript = re.sub(r'\\s+', ' ', transcript).strip()\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main function**\n",
    "\n",
    "Matches a single ```.wav``` file to its respective ```.TextGrid``` file\n",
    "\n",
    "- Break the ```.wav``` file and ```.TextGrid``` file into 30s segments\n",
    "- Clean the ```.TextGrid``` file\n",
    "- Only keep segments that have audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_transcript(audio_filename, input_audio_path, input_textgrid_path, output_path, sanity_check=False):\n",
    "    audio_path = os.path.join(os.getcwd(), *input_audio_path, f'{audio_filename}.wav')\n",
    "    textgrid_path = os.path.join(os.getcwd(), *input_textgrid_path, f'{audio_filename}.TextGrid')\n",
    "\n",
    "    output_dir_wav = os.path.join(os.getcwd(), *output_path, 'waves')\n",
    "    output_dir_transcript = os.path.join(os.getcwd(), *output_path, 'transcripts')\n",
    "\n",
    "    output_dir_textgrid = os.path.join(os.getcwd(), *output_path, 'textgrids')\n",
    "\n",
    "    audio = AudioSegment.from_wav(audio_path)\n",
    "    tg = textgrid.openTextgrid(textgrid_path, False) \n",
    "\n",
    "    segment_duration_ms = 30 * 1000  \n",
    "\n",
    "    audio_duration = len(audio)\n",
    "\n",
    "    start_time = 0\n",
    "    segment_index = 1\n",
    "\n",
    "    while start_time < audio_duration:\n",
    "        end_time = min(start_time + segment_duration_ms, audio_duration)\n",
    "\n",
    "        audio_segment = audio[start_time:end_time]\n",
    "        tg_segment = tg.crop(start_time / 1000, end_time / 1000, mode=\"truncated\", rebaseToZero=False)\n",
    "\n",
    "        transcriptions = []\n",
    "        for tier_name in tg_segment.tierNames: \n",
    "            tier = tg_segment.getTier(tier_name) \n",
    "            for entry in tier.entries:  \n",
    "                if entry.label.strip():  \n",
    "                    transcriptions.append(entry.label)\n",
    "\n",
    "        transcriptions_clean = clean_transcription(transcriptions)\n",
    "\n",
    "        if len(transcriptions_clean) > 0:\n",
    "            transcript_segment_path = os.path.join(output_dir_transcript, f'{audio_filename}_{segment_index}.txt')\n",
    "            with open(transcript_segment_path, 'w') as f:\n",
    "                f.write(f'{audio_filename}_{segment_index} {transcriptions_clean}')\n",
    "\n",
    "            if sanity_check:\n",
    "                tg_segment_path = os.path.join(output_dir_textgrid, f'{audio_filename}_{segment_index}.TextGrid')\n",
    "                tg_segment.save(tg_segment_path, \"long_textgrid\", True)\n",
    "            \n",
    "            audio_segment_path = os.path.join(output_dir_wav, f'{audio_filename}_{segment_index}.wav')\n",
    "            audio_segment.export(audio_segment_path, format=\"wav\")\n",
    "\n",
    "            start_time+=segment_duration_ms\n",
    "            segment_index+=1\n",
    "        else:\n",
    "            start_time+=segment_duration_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the main function to segment 30s chunks for each ```.wav``` and ```.TextGrid``` file**\n",
    "\n",
    "Output is the segmented ```.wav``` files and transcriptions for each ```.wav``` file stored in ```train/waves``` and ```train/transcripts``` respectively\n",
    "\n",
    "Note: We first put the files into the train folder\n",
    "\n",
    "A sanity check can be set to True to view the segmented ```.TextGrid``` files in ```./train/textgrids/```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = os.path.join(os.getcwd(), *input_audio_path)\n",
    "for filename in os.listdir(audio_path):\n",
    "    filename = filename.split('.')[0]\n",
    "    process_audio_transcript(filename, input_audio_path, input_textgrid_path, output_train_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Move a split of the ```.wav``` files and ```.txt``` file to test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.2\n",
    "\n",
    "sample_filenames = []\n",
    "for filename in os.listdir(output_train_folder_waves):\n",
    "    sample_filenames.append(filename.split('.')[0])\n",
    "\n",
    "samples = len(sample_filenames)\n",
    "\n",
    "num_train_samples = math.floor((1-test_split)*samples)\n",
    "num_test_samples = samples-num_train_samples\n",
    "\n",
    "print(f\"The total number of samples is {samples}\")\n",
    "print(f\"The total number of training samples will be {num_train_samples}\")\n",
    "print(f\"The total number of test samples will be {num_test_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(sample_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_test_samples):\n",
    "    filename = sample_filenames[i]\n",
    "\n",
    "    source_wav = os.path.join(output_train_folder_waves, filename + '.wav')\n",
    "    destination_wav = os.path.join(output_test_folder_waves)\n",
    "    shutil.move(source_wav, destination_wav)\n",
    "\n",
    "    source_transcript = os.path.join(output_train_folder_transcripts, filename + '.txt')\n",
    "    destination_transcript = os.path.join(output_test_folder_transcripts)\n",
    "    shutil.move(source_transcript, destination_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write the ```/train/prompts.txt``` and ```/test/prompts.txt``` files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_path = os.path.join(os.getcwd(), *output_train_path, 'prompts.txt')\n",
    "with open(train_prompts_path, 'a') as outfile:\n",
    "    for filename in os.listdir(output_train_folder_transcripts):\n",
    "        file_path = os.path.join(output_train_folder_transcripts, filename)\n",
    "        with open(file_path, \"r\") as infile:\n",
    "            outfile.write(infile.read() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_path = os.path.join(os.getcwd(), *output_test_path, 'prompts.txt')\n",
    "with open(test_prompts_path, 'a') as outfile:\n",
    "    for filename in os.listdir(output_test_folder_transcripts):\n",
    "        file_path = os.path.join(output_test_folder_transcripts, filename)\n",
    "        with open(file_path, \"r\") as infile:\n",
    "            outfile.write(infile.read() + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compress the folders into ```.tar.gzip```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_compress = [train_prompts_path, output_train_folder_waves, test_prompts_path, output_test_folder_waves]\n",
    "\n",
    "with tarfile.open(output_compressed_file, \"w:gz\") as tar_gz:\n",
    "    for path in paths_to_compress:\n",
    "        rel_path = os.path.relpath(path, os.path.join(os.getcwd(), *output_compressed_path))\n",
    "        tar_gz.add(path, arcname=rel_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_prompts_path, 'rb') as f_in, gzip.open(output_compressed_train_prompt_file, 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_prompts_path, 'rb') as f_in, gzip.open(output_compressed_test_prompt_file, 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_prompts_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    train_prompts_filenames = sorted([l.split(' ')[0] for l in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wavs_filenames = []\n",
    "for filename in os.listdir(output_train_folder_waves):\n",
    "    filename = filename.split('.')[0]\n",
    "    train_wavs_filenames.append(filename)\n",
    "train_waves_filename = sorted(train_wavs_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_waves_filename[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_filenames==train_waves_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_prompts_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    test_prompts_filenames = sorted([l.split(' ')[0] for l in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wavs_filenames = []\n",
    "for filename in os.listdir(output_test_folder_waves):\n",
    "    filename = filename.split('.')[0]\n",
    "    test_wavs_filenames.append(filename)\n",
    "test_waves_filename = sorted(test_wavs_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wavs_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_filenames==test_wavs_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Iteration 4: How to fix overlap between some audio files and transcriptions**\n",
    "\n",
    "Example: \n",
    "\n",
    "3000-1_12 and 3000-1_13\n",
    "\n",
    "Audio at the end of 3000-1_12 includes 3/4-ish of text in ```intervals[22]```\n",
    "\n",
    "Audio at the start of 3000-1_13 includes 1/4-ish of text in ```intervals[1]```\n",
    "\n",
    "Solution: Segment based on TextGrid files instead of Audio files?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "<u>Initialising the directory</u>\n",
    "```\n",
    "dataset\n",
    "- testing\n",
    "    - data: Used to store compression files\n",
    "    - org_waves: Manually add in .wav files\n",
    "        - 3000-1.wav\n",
    "        - 3000-2.wav\n",
    "        - ...\n",
    "    - org_transcripts: Manually add in .TextGrid files\n",
    "        - 3000-1.TextGrid\n",
    "        - 3000-2.TextGrid\n",
    "        - ...\n",
    "    - train\n",
    "        - waves: Empty\n",
    "        - transcripts: Empty\n",
    "    - test\n",
    "        - waves: Empty\n",
    "        - transcripts: Empty\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Step 2:\n",
    "<u>After running the processing code</u>\n",
    "```\n",
    "dataset\n",
    "- testing\n",
    "    - data: Used to store compression files\n",
    "    - org_waves: Manually add in .wav files\n",
    "        - 3000-1.wav\n",
    "        - 3000-2.wav\n",
    "        - ...\n",
    "    - org_transcripts: Manually add in .TextGrid files\n",
    "        - 3000-1.TextGrid\n",
    "        - 3000-2.TextGrid\n",
    "        - ...\n",
    "    - train\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in train\n",
    "        - waves\n",
    "            - 3000-1_1.wav\n",
    "            - 3000-1_2.wav\n",
    "            - 3000-1_3.wav\n",
    "            - ...\n",
    "            - 3000-2_1.wav\n",
    "            - 3000-2_2.wav\n",
    "            - 3000-2_3.wav\n",
    "        - transcripts\n",
    "            - 3000-1_1.txt\n",
    "            - 3000-1_2.txt\n",
    "            - 3000-1_3.txt\n",
    "            - ...\n",
    "            - 3000-2_1.txt\n",
    "            - 3000-2_2.txt\n",
    "            - 3000-2_3.txt\n",
    "    - test\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in test\n",
    "        - waves\n",
    "            - 3000-3_1.wav\n",
    "            - 3000-3_2.wav\n",
    "            - 3000-3_3.wav\n",
    "            - ...\n",
    "            - 3000-4_1.wav\n",
    "            - 3000-4_2.wav\n",
    "            - 3000-4_3.wav\n",
    "        - transcripts\n",
    "            - 3000-3_1.txt\n",
    "            - 3000-3_2.txt\n",
    "            - 3000-3_3.txt\n",
    "            - ...\n",
    "            - 3000-4_1.txt\n",
    "            - 3000-4_2.txt\n",
    "            - 3000-4_3.txt\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Step 3:\n",
    "<u>After running the compression code</u>\n",
    "\n",
    "```\n",
    "data\n",
    "    - input_name.tar.gz\n",
    "        - train\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files\n",
    "            - waves\n",
    "                - 3000-1_1.wav\n",
    "                - 3000-1_2.wav\n",
    "                - 3000-1_3.wav\n",
    "                - ...\n",
    "                - 3000-2_1.wav\n",
    "                - 3000-2_2.wav\n",
    "                - 3000-2_3.wav\n",
    "        - test\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files\n",
    "            - waves\n",
    "                - 3000-3_1.wav\n",
    "                - 3000-3_2.wav\n",
    "                - 3000-3_3.wav\n",
    "                - ...\n",
    "                - 3000-4_1.wav\n",
    "                - 3000-4_2.wav\n",
    "                - 3000-4_3.wav\n",
    "    - prompts-train.txt.gz\n",
    "        - prompts-train.txt: Contains transcriptions for all the train .wav files -> take this from train/prompts.txt\n",
    "    - prompts-test.txt.gz\n",
    "        - prompts-test.txt: Contains transcriptions for all the test .wav files -> take this from test/prompts.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import gzip\n",
    "import math\n",
    "import random\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>USER INPUT REQUIRED</u> Input Relative Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio_path = ['dataset', 'testing', 'org_wavs']\n",
    "input_textgrid_path = ['dataset', 'testing', 'org_transcripts']\n",
    "output_train_path = ['dataset', 'testing', 'train']\n",
    "output_test_path = ['dataset', 'testing', 'test']\n",
    "output_compressed_path = ['dataset', 'testing']\n",
    "compressed_filename = 'imda_nsc_p3_testing.tar.gz'\n",
    "compressed_train_prompt_filename = 'prompts-train.txt.gz'\n",
    "compressed_test_prompt_filename = 'prompts-test.txt.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialise Paths and Create the directories**\n",
    "\n",
    "**IMPT <u>USER INPUT REQUIRED</u>**: Remember to add in the ```.wav``` and ```.TextGrid``` files to org_waves and org_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wav_folder = os.path.join(os.getcwd(), *input_audio_path)\n",
    "input_textgrid_folder = os.path.join(os.getcwd(), *input_textgrid_path)\n",
    "output_train_folder_waves = os.path.join(os.getcwd(), *output_train_path, 'waves')\n",
    "output_train_folder_transcripts = os.path.join(os.getcwd(), *output_train_path, 'transcripts')\n",
    "output_test_folder_waves  = os.path.join(os.getcwd(), *output_test_path, 'waves')\n",
    "output_test_folder_transcripts = os.path.join(os.getcwd(), *output_test_path, 'transcripts')\n",
    "output_textgrids_folder = os.path.join(os.getcwd(), *output_train_path, 'textgrids')\n",
    "output_compressed_folder = os.path.join(os.getcwd(), *output_compressed_path, 'data')\n",
    "output_compressed_file = os.path.join(output_compressed_folder, compressed_filename)\n",
    "output_compressed_train_prompt_file = os.path.join(output_compressed_folder, compressed_train_prompt_filename)\n",
    "output_compressed_test_prompt_file = os.path.join(output_compressed_folder, compressed_test_prompt_filename)\n",
    "\n",
    "create_dir = [input_wav_folder, input_textgrid_folder, output_train_folder_waves, output_train_folder_transcripts,\n",
    "              output_test_folder_waves, output_test_folder_transcripts, output_textgrids_folder, output_compressed_folder]\n",
    "\n",
    "for dir in create_dir:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper function to clean the transcription**\n",
    "\n",
    "1. Lower-case the text\n",
    "\n",
    "2. Remove and replace annotations\n",
    "\n",
    "- Paralinguistic Phenomena: Remove '(ppb)', '(ppc)', '(ppl)', '(ppo)'\n",
    "- Acronyms: Remove '_'\n",
    "- Multi-word nouns: Replace '-' with ' '\n",
    "- Discourse particles: Remove '[' and ']'\n",
    "- Fillers: Remove '(' and ')'\n",
    "- Interjections: Remove '!'\n",
    "- Other languages: Remove '#'\n",
    "- Unclear words: Remove ```'<unk>'```\n",
    "- Incomplete words: Remove '~'\n",
    "- Short pauses: Remove ```'<s>'```\n",
    "- Invalid: Remove ```'<z>'```\n",
    "- Long-running non-english utterances: Remove ```'<nen>'```\n",
    "- Fillers: Remove ```'<fil/>'```\n",
    "- Speaker Noise: Remove ```'<spk/>'```\n",
    "- Unknown: Remove '**'\n",
    "- Non-primary speaker sound: Remove ```'<non/>'```\n",
    "- End of sentence: Remove ```'<s/>'```\n",
    "- Comma: Remove ```'<c/>'```\n",
    "- Remove all instances of ```<whatever is inside>```\n",
    "\n",
    "3. Remove extra spaces created by ```<s>``` and stuff\n",
    "\n",
    "Refer to the Transcription Guidelines by IMDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcription(transcript):\n",
    "    transcript = ' '.join(line.strip() for line in transcript)\n",
    "    transcript = transcript.lower()\n",
    "    remove = [r'\\(ppb\\)|\\(ppc\\)|\\(ppl\\)|\\(ppo\\)', r'_', r'\\[|\\]', r'\\(|\\)', r'!', \n",
    "            r'#', r'<unk>', r'~', r'<s>', r'<z>', r'<nen>', r'<fil/>', r'<spk/>',\n",
    "            r'\\*', r'<non/>', r'<s/>', r'<c/>', r'<[^>]+>'] \n",
    "    replace = ['-']\n",
    "    for e in remove:\n",
    "        transcript = re.sub(e, '', transcript)\n",
    "    for e in replace:\n",
    "        transcript = re.sub(e, ' ', transcript)\n",
    "    transcript = re.sub(r'\\s+', ' ', transcript).strip()\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main function**\n",
    "\n",
    "Matches a single ```.wav``` file to its respective ```.TextGrid``` file\n",
    "\n",
    "- Break the ```.wav``` file and ```.TextGrid``` file into 30s segments\n",
    "- Clean the ```.TextGrid``` file\n",
    "- Only keep segments that have audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to fix overlap between some audio files and transcriptions**\n",
    "\n",
    "Example: \n",
    "\n",
    "3000-1_12 and 3000-1_13\n",
    "\n",
    "Audio at the end of 3000-1_12 includes 3/4-ish of text in ```intervals[22]```\n",
    "\n",
    "Audio at the start of 3000-1_13 includes 1/4-ish of text in ```intervals[1]```\n",
    "\n",
    "```\n",
    "input_textgrid_path = ['dataset', 'testing', 'org_transcripts']\n",
    "test_textgrid_path = os.path.join(os.getcwd(), *input_textgrid_path, '3000-1.TextGrid')\n",
    "tg_test = textgrid.openTextgrid(test_textgrid_path, False) \n",
    "\n",
    "for tier_name in tg_test.tierNames: \n",
    "    print(tier_name)\n",
    "\n",
    ">>> 3000-1\n",
    "\n",
    "for tier_name in tg_test.tierNames: \n",
    "    tier = tg_test.getTier(tier_name) \n",
    "    for entry in tier.entries:  \n",
    "        print(entry)\n",
    "\n",
    ">>> Interval(start=0.0, end=1.556, label='<S>')\n",
    ">>> Interval(start=1.556, end=2.661, label='(um) you can go first')\n",
    ">>>...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_transcript(audio_filename, input_audio_path, input_textgrid_path, output_path, sanity_check=False):\n",
    "    audio_path = os.path.join(os.getcwd(), *input_audio_path, f'{audio_filename}.wav')\n",
    "    textgrid_path = os.path.join(os.getcwd(), *input_textgrid_path, f'{audio_filename}.TextGrid')\n",
    "\n",
    "    output_dir_wav = os.path.join(os.getcwd(), *output_path, 'waves')\n",
    "    output_dir_transcript = os.path.join(os.getcwd(), *output_path, 'transcripts')\n",
    "\n",
    "    output_dir_textgrid = os.path.join(os.getcwd(), *output_path, 'textgrids')\n",
    "\n",
    "    audio = AudioSegment.from_wav(audio_path)\n",
    "    tg = textgrid.openTextgrid(textgrid_path, False) \n",
    "\n",
    "    # Specify the duration of each segment\n",
    "    segment_duration_s = 30 \n",
    "    # Specify the current segment duration\n",
    "    curr_segment_duration = 0\n",
    "    # Specify the current segment index\n",
    "    segment_index = 1\n",
    "    # Specify the timestamps traversed for the current segment\n",
    "    curr_timestamps = []\n",
    "    # Specify the transcriptions for the current segment\n",
    "    curr_transcriptions = []\n",
    "\n",
    "    for tier_name in tg.tierNames: \n",
    "        tier = tg.getTier(tier_name) \n",
    "        for start,end,label in tier.entries:  \n",
    "            # Get the duration of this new entry\n",
    "            entry_duration = end-start\n",
    "            # If the addition of this new entry to the current segment duration does not exceed\n",
    "            # our specified duration of each segment, we can accumulate the current segment\n",
    "            if curr_segment_duration + entry_duration <= segment_duration_s:\n",
    "                # Update the current_segment_duration\n",
    "                curr_segment_duration+=entry_duration\n",
    "                # Update the timestamps and transcriptions\n",
    "                curr_timestamps.extend([start,end])\n",
    "                curr_transcriptions.append(label)\n",
    "\n",
    "            # If the addition of a new entry exceeds our specified duration of each segment\n",
    "            # that means the current segment is completed and\n",
    "            # we save the transcription and the segmented audio as well as\n",
    "            # perform resetting\n",
    "            else:\n",
    "                # Clean the transcription\n",
    "                curr_transcriptions_clean = clean_transcription(curr_transcriptions)\n",
    "                # If there are words after cleaning\n",
    "                if len(curr_transcriptions_clean) > 0:\n",
    "                    # Initialise the transcription segment path\n",
    "                    transcript_segment_path = os.path.join(output_dir_transcript, f'{audio_filename}_{segment_index}.txt')\n",
    "                    # Write the transcription to the transcription segment file\n",
    "                    with open(transcript_segment_path, 'w') as f:\n",
    "                        f.write(f'{audio_filename}_{segment_index} {curr_transcriptions_clean}')\n",
    "                    # Calculate the boundaries for the audio segment in ms\n",
    "                    segment_start = min(curr_timestamps)*1000\n",
    "                    segment_end = max(curr_timestamps)*1000\n",
    "\n",
    "                    # Sanity check on TextGrid Segments\n",
    "                    if sanity_check:\n",
    "                        tg_segment = tg.crop(segment_start / 1000, segment_end / 1000, mode=\"strict\", rebaseToZero=False)\n",
    "                        tg_segment_path = os.path.join(output_dir_textgrid, f'{audio_filename}_{segment_index}.TextGrid')\n",
    "                        tg_segment.save(tg_segment_path, \"long_textgrid\", True)\n",
    "\n",
    "                    # Segment the audio using the start and time from the TextGrid\n",
    "                    audio_segment = audio[segment_start:segment_end]\n",
    "\n",
    "                    # Save the audio segment\n",
    "                    audio_segment_path = os.path.join(output_dir_wav, f'{audio_filename}_{segment_index}.wav')\n",
    "                    audio_segment.export(audio_segment_path, format=\"wav\")\n",
    "\n",
    "                # Resetting\n",
    "                # If a single entry is <= than 30s\n",
    "                if entry_duration <= segment_duration_s:\n",
    "                    # Reset the current segment duration\n",
    "                    curr_segment_duration = entry_duration\n",
    "                    # Reset the current timestamps to include the start and end of this iteration\n",
    "                    curr_timestamps = [start,end]\n",
    "                    # Reset the current transcriptions to include the label of this iteration\n",
    "                    curr_transcriptions = [label]\n",
    "                # Skip the entry as a sample if it is > than 30s\n",
    "                else:\n",
    "                    # Reset the current segment duration\n",
    "                    curr_segment_duration = 0\n",
    "                    # Reset the current timestamps from empty\n",
    "                    curr_timestamps = []\n",
    "                    # Reset the current transcriptions from empty\n",
    "                    curr_transcriptions = []\n",
    "\n",
    "                # Increment the segment index only if there was transcriptions (and thus audio) to be saved\n",
    "                if len(curr_transcriptions_clean) > 0:\n",
    "                    # Increment the segment index\n",
    "                    segment_index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the main function to segment 30s chunks for each ```.wav``` and ```.TextGrid``` file**\n",
    "\n",
    "Output is the segmented ```.wav``` files and transcriptions for each ```.wav``` file stored in ```train/waves``` and ```train/transcripts``` respectively\n",
    "\n",
    "Note: We first put the files into the train folder\n",
    "\n",
    "A sanity check can be set to True to view the segmented ```.TextGrid``` files in ```./train/textgrids/```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = os.path.join(os.getcwd(), *input_audio_path)\n",
    "for filename in os.listdir(audio_path):\n",
    "    filename = filename.split('.')[0]\n",
    "    process_audio_transcript(filename, input_audio_path, input_textgrid_path, output_train_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Move a split of the ```.wav``` files and ```.txt``` file to test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.2\n",
    "\n",
    "sample_filenames = []\n",
    "for filename in os.listdir(output_train_folder_waves):\n",
    "    sample_filenames.append(filename.split('.')[0])\n",
    "\n",
    "samples = len(sample_filenames)\n",
    "\n",
    "num_train_samples = math.floor((1-test_split)*samples)\n",
    "num_test_samples = samples-num_train_samples\n",
    "\n",
    "print(f\"The total number of samples is {samples}\")\n",
    "print(f\"The total number of training samples will be {num_train_samples}\")\n",
    "print(f\"The total number of test samples will be {num_test_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(sample_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_test_samples):\n",
    "    filename = sample_filenames[i]\n",
    "\n",
    "    source_wav = os.path.join(output_train_folder_waves, filename + '.wav')\n",
    "    destination_wav = os.path.join(output_test_folder_waves)\n",
    "    shutil.move(source_wav, destination_wav)\n",
    "\n",
    "    source_transcript = os.path.join(output_train_folder_transcripts, filename + '.txt')\n",
    "    destination_transcript = os.path.join(output_test_folder_transcripts)\n",
    "    shutil.move(source_transcript, destination_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write the ```/train/prompts.txt``` and ```/test/prompts.txt``` files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_path = os.path.join(os.getcwd(), *output_train_path, 'prompts.txt')\n",
    "with open(train_prompts_path, 'a') as outfile:\n",
    "    for filename in os.listdir(output_train_folder_transcripts):\n",
    "        file_path = os.path.join(output_train_folder_transcripts, filename)\n",
    "        with open(file_path, \"r\") as infile:\n",
    "            outfile.write(infile.read() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_path = os.path.join(os.getcwd(), *output_test_path, 'prompts.txt')\n",
    "with open(test_prompts_path, 'a') as outfile:\n",
    "    for filename in os.listdir(output_test_folder_transcripts):\n",
    "        file_path = os.path.join(output_test_folder_transcripts, filename)\n",
    "        with open(file_path, \"r\") as infile:\n",
    "            outfile.write(infile.read() + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compress the folders into ```.tar.gzip```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_compress = [train_prompts_path, output_train_folder_waves, test_prompts_path, output_test_folder_waves]\n",
    "\n",
    "with tarfile.open(output_compressed_file, \"w:gz\") as tar_gz:\n",
    "    for path in paths_to_compress:\n",
    "        rel_path = os.path.relpath(path, os.path.join(os.getcwd(), *output_compressed_path))\n",
    "        tar_gz.add(path, arcname=rel_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_prompts_path, 'rb') as f_in, gzip.open(output_compressed_train_prompt_file, 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_prompts_path, 'rb') as f_in, gzip.open(output_compressed_test_prompt_file, 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_prompts_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    train_prompts_filenames = sorted([l.split(' ')[0] for l in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wavs_filenames = []\n",
    "for filename in os.listdir(output_train_folder_waves):\n",
    "    filename = filename.split('.')[0]\n",
    "    train_wavs_filenames.append(filename)\n",
    "train_waves_filename = sorted(train_wavs_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_waves_filename[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_filenames==train_waves_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_prompts_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    test_prompts_filenames = sorted([l.split(' ')[0] for l in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wavs_filenames = []\n",
    "for filename in os.listdir(output_test_folder_waves):\n",
    "    filename = filename.split('.')[0]\n",
    "    test_wavs_filenames.append(filename)\n",
    "test_waves_filename = sorted(test_wavs_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wavs_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_filenames==test_wavs_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Iteration 5: Segment audio to only include main speakers speech**\n",
    "\n",
    "Example: \n",
    "\n",
    "3000-1_27 previously from Iteration 4\n",
    "\n",
    "There was people (the non-main speaker) talking. For training, the ground truth from iteration 4 only includes the main speaker's speech but this is unfair to the ASR because it may transcribe the non-main speaker's speech as well which affects training and evaluation\n",
    "\n",
    "Solution: Segment based on entry and only if the entry has proper ground truth transcriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "<u>Initialising the directory</u>\n",
    "```\n",
    "dataset\n",
    "- testing\n",
    "    - data: Used to store compression files\n",
    "    - org_waves: Manually add in .wav files to be segmented\n",
    "        - 3000-1.wav\n",
    "        - 3000-2.wav\n",
    "        - ...\n",
    "    - org_transcripts: Manually add in .TextGrid files to be segmented\n",
    "        - 3000-1.TextGrid\n",
    "        - 3000-2.TextGrid\n",
    "        - ...\n",
    "    - train\n",
    "        - waves: Empty\n",
    "        - transcripts: Empty\n",
    "    - test\n",
    "        - waves: Empty\n",
    "        - transcripts: Empty\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Step 2:\n",
    "<u>After running the processing code</u>\n",
    "```\n",
    "dataset\n",
    "- testing\n",
    "    - data: Used to store compression files\n",
    "    - org_waves: Manually add in .wav files\n",
    "        - 3000-1.wav\n",
    "        - 3000-2.wav\n",
    "        - ...\n",
    "    - org_transcripts: Manually add in .TextGrid files\n",
    "        - 3000-1.TextGrid\n",
    "        - 3000-2.TextGrid\n",
    "        - ...\n",
    "    - train\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in train\n",
    "        - waves\n",
    "            - 3000-1_1.wav\n",
    "            - 3000-1_2.wav\n",
    "            - 3000-1_3.wav\n",
    "            - ...\n",
    "            - 3000-2_1.wav\n",
    "            - 3000-2_2.wav\n",
    "            - 3000-2_3.wav\n",
    "        - transcripts\n",
    "            - 3000-1_1.txt\n",
    "            - 3000-1_2.txt\n",
    "            - 3000-1_3.txt\n",
    "            - ...\n",
    "            - 3000-2_1.txt\n",
    "            - 3000-2_2.txt\n",
    "            - 3000-2_3.txt\n",
    "    - test\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in test\n",
    "        - waves\n",
    "            - 3000-3_1.wav\n",
    "            - 3000-3_2.wav\n",
    "            - 3000-3_3.wav\n",
    "            - ...\n",
    "            - 3000-4_1.wav\n",
    "            - 3000-4_2.wav\n",
    "            - 3000-4_3.wav\n",
    "        - transcripts\n",
    "            - 3000-3_1.txt\n",
    "            - 3000-3_2.txt\n",
    "            - 3000-3_3.txt\n",
    "            - ...\n",
    "            - 3000-4_1.txt\n",
    "            - 3000-4_2.txt\n",
    "            - 3000-4_3.txt\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Step 3:\n",
    "<u>After running the compression code</u>\n",
    "\n",
    "```\n",
    "data\n",
    "    - input_name.tar.gz\n",
    "        - train\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files in train\n",
    "            - waves\n",
    "                - 3000-1_1.wav\n",
    "                - 3000-1_2.wav\n",
    "                - 3000-1_3.wav\n",
    "                - ...\n",
    "                - 3000-2_1.wav\n",
    "                - 3000-2_2.wav\n",
    "                - 3000-2_3.wav\n",
    "        - test\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files in test\n",
    "            - waves\n",
    "                - 3000-3_1.wav\n",
    "                - 3000-3_2.wav\n",
    "                - 3000-3_3.wav\n",
    "                - ...\n",
    "                - 3000-4_1.wav\n",
    "                - 3000-4_2.wav\n",
    "                - 3000-4_3.wav\n",
    "    - prompts-train.txt.gz\n",
    "        - prompts-train.txt: Contains transcriptions for all the train .wav files -> taken from train/prompts.txt\n",
    "    - prompts-test.txt.gz\n",
    "        - prompts-test.txt: Contains transcriptions for all the test .wav files -> take from test/prompts.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johnl\\miniconda3\\envs\\myenv2\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import gzip\n",
    "import math\n",
    "import random\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>USER INPUT REQUIRED</u> Input Relative Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio_path = ['dataset', 'testing', 'org_wavs']\n",
    "input_textgrid_path = ['dataset', 'testing', 'org_transcripts']\n",
    "output_train_path = ['dataset', 'testing', 'train']\n",
    "output_test_path = ['dataset', 'testing', 'test']\n",
    "output_compressed_path = ['dataset', 'testing']\n",
    "compressed_filename = 'imda_nsc_p3_testing.tar.gz'\n",
    "compressed_train_prompt_filename = 'prompts-train.txt.gz'\n",
    "compressed_test_prompt_filename = 'prompts-test.txt.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialise Paths and Create the directories**\n",
    "\n",
    "**IMPT <u>USER INPUT REQUIRED</u>**: Remember to add in the ```.wav``` and ```.TextGrid``` files to org_waves and org_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wav_folder = os.path.join(os.getcwd(), *input_audio_path)\n",
    "input_textgrid_folder = os.path.join(os.getcwd(), *input_textgrid_path)\n",
    "output_train_folder_waves = os.path.join(os.getcwd(), *output_train_path, 'waves')\n",
    "output_train_folder_transcripts = os.path.join(os.getcwd(), *output_train_path, 'transcripts')\n",
    "output_test_folder_waves  = os.path.join(os.getcwd(), *output_test_path, 'waves')\n",
    "output_test_folder_transcripts = os.path.join(os.getcwd(), *output_test_path, 'transcripts')\n",
    "output_textgrids_folder = os.path.join(os.getcwd(), *output_train_path, 'textgrids')\n",
    "output_compressed_folder = os.path.join(os.getcwd(), *output_compressed_path, 'data')\n",
    "output_compressed_file = os.path.join(output_compressed_folder, compressed_filename)\n",
    "output_compressed_train_prompt_file = os.path.join(output_compressed_folder, compressed_train_prompt_filename)\n",
    "output_compressed_test_prompt_file = os.path.join(output_compressed_folder, compressed_test_prompt_filename)\n",
    "\n",
    "create_dir = [input_wav_folder, input_textgrid_folder, output_train_folder_waves, output_train_folder_transcripts,\n",
    "              output_test_folder_waves, output_test_folder_transcripts, output_textgrids_folder, output_compressed_folder]\n",
    "\n",
    "for dir in create_dir:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper function to clean the transcription**\n",
    "\n",
    "1. Lower-case the text\n",
    "\n",
    "2. Remove and replace annotations\n",
    "\n",
    "- Paralinguistic Phenomena: Remove '(ppb)', '(ppc)', '(ppl)', '(ppo)'\n",
    "- Acronyms: Remove '_'\n",
    "- Multi-word nouns: Replace '-' with ' '\n",
    "- Discourse particles: Remove '[' and ']'\n",
    "- Fillers: Remove '(' and ')'\n",
    "- Interjections: Remove '!'\n",
    "- Other languages: Remove '#'\n",
    "- Unclear words: Remove ```'<unk>'```\n",
    "- Incomplete words: Remove '~'\n",
    "- Short pauses: Remove ```'<s>'```\n",
    "- Invalid: Remove ```'<z>'```\n",
    "- Long-running non-english utterances: Remove ```'<nen>'```\n",
    "- Fillers: Remove ```'<fil/>'```\n",
    "- Speaker Noise: Remove ```'<spk/>'```\n",
    "- Unknown: Remove '**'\n",
    "- Non-primary speaker sound: Remove ```'<non/>'```\n",
    "- End of sentence: Remove ```'<s/>'```\n",
    "- Comma: Remove ```'<c/>'```\n",
    "- Remove all instances of ```<whatever is inside>```\n",
    "\n",
    "3. Remove extra spaces created by ```<s>``` and stuff\n",
    "\n",
    "Refer to the Transcription Guidelines by IMDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcription(transcript):\n",
    "    transcript = transcript.strip()\n",
    "    transcript = transcript.lower()\n",
    "    remove = [r'\\(ppb\\)|\\(ppc\\)|\\(ppl\\)|\\(ppo\\)', r'_', r'\\[|\\]', r'\\(|\\)', r'!', \n",
    "            r'#', r'<unk>', r'~', r'<s>', r'<z>', r'<nen>', r'<fil/>', r'<spk/>',\n",
    "            r'\\*', r'<non/>', r'<s/>', r'<c/>', r'<[^>]+>'] \n",
    "    replace = ['-']\n",
    "    for e in remove:\n",
    "        transcript = re.sub(e, '', transcript)\n",
    "    for e in replace:\n",
    "        transcript = re.sub(e, ' ', transcript)\n",
    "    transcript = re.sub(r'\\s+', ' ', transcript).strip()\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main function**\n",
    "\n",
    "- Matches a single ```.wav``` file to its respective ```.TextGrid``` file\n",
    "\n",
    "- Break the ```.wav``` file and ```.TextGrid``` files into segments such that each segment only contains a transcription that is <= 30s long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_transcript(audio_filename, input_audio_path, input_textgrid_path, output_path, sanity_check=False):\n",
    "    audio_path = os.path.join(os.getcwd(), *input_audio_path, f'{audio_filename}.wav')\n",
    "    textgrid_path = os.path.join(os.getcwd(), *input_textgrid_path, f'{audio_filename}.TextGrid')\n",
    "\n",
    "    output_dir_wav = os.path.join(os.getcwd(), *output_path, 'waves')\n",
    "    output_dir_transcript = os.path.join(os.getcwd(), *output_path, 'transcripts')\n",
    "\n",
    "    output_dir_textgrid = os.path.join(os.getcwd(), *output_path, 'textgrids')\n",
    "\n",
    "    audio = AudioSegment.from_wav(audio_path)\n",
    "    tg = textgrid.openTextgrid(textgrid_path, False) \n",
    "\n",
    "    # Specify the duration of each segment\n",
    "    segment_duration_s = 30 \n",
    "    # Specify the current segment index\n",
    "    segment_index = 1\n",
    "\n",
    "    for tier_name in tg.tierNames: \n",
    "        tier = tg.getTier(tier_name) \n",
    "        for start,end,label in tier.entries:  \n",
    "            # Get the duration of this new entry\n",
    "            entry_duration = end-start\n",
    "            # If the entry's duration is less than our specified duration of each segment\n",
    "            if entry_duration <= segment_duration_s:\n",
    "                # Clean the transcription/label of this entry\n",
    "                curr_transcriptions_clean = clean_transcription(label)\n",
    "                # If this entry has text after cleaning i.e. contains proper ground truth transcription\n",
    "                if len(curr_transcriptions_clean) > 0:\n",
    "                    # Initialise the transcription segment path\n",
    "                    transcript_segment_path = os.path.join(output_dir_transcript, f'{audio_filename}_{segment_index}.txt')\n",
    "                    # Write the transcription to the transcription segment file\n",
    "                    with open(transcript_segment_path, 'w') as f:\n",
    "                        f.write(f'{audio_filename}_{segment_index} {curr_transcriptions_clean}')\n",
    "\n",
    "                    # Calculate the boundaries for the audio segment in ms\n",
    "                    segment_start = start*1000\n",
    "                    segment_end = end*1000\n",
    "\n",
    "                    # Sanity check on TextGrid Segments\n",
    "                    if sanity_check:\n",
    "                        tg_segment = tg.crop(segment_start / 1000, segment_end / 1000, mode=\"strict\", rebaseToZero=False)\n",
    "                        tg_segment_path = os.path.join(output_dir_textgrid, f'{audio_filename}_{segment_index}.TextGrid')\n",
    "                        tg_segment.save(tg_segment_path, \"long_textgrid\", True)\n",
    "\n",
    "                    # Segment the audio using the start and time from the current TextGrid entry\n",
    "                    audio_segment = audio[segment_start:segment_end+1] # Add 1 ms s.t the end timing is inclusive\n",
    "\n",
    "                    # Save the audio segment\n",
    "                    audio_segment_path = os.path.join(output_dir_wav, f'{audio_filename}_{segment_index}.wav')\n",
    "                    audio_segment.export(audio_segment_path, format=\"wav\")\n",
    "\n",
    "                    # Increment the segment index\n",
    "                    segment_index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the main function to create segments for each ```.wav``` and ```.TextGrid``` file**\n",
    "\n",
    "Output is the segmented ```.wav``` audio files and corresponding ```.txt``` transcription files that is stored in ```train/waves``` and ```train/transcripts``` respectively\n",
    "\n",
    "Note: We first put the files into the train folder\n",
    "\n",
    "A sanity check can be set to ```True``` to view the corresponding segmented ```.TextGrid``` files in ```./train/textgrids/```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = os.path.join(os.getcwd(), *input_audio_path)\n",
    "for filename in os.listdir(audio_path):\n",
    "    filename = filename.split('.')[0]\n",
    "    process_audio_transcript(filename, input_audio_path, input_textgrid_path, output_train_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Move a split of the ```.wav``` files and ```.txt``` file to test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of samples is 1463\n",
      "The total number of training samples will be 1170\n",
      "The total number of test samples will be 293\n"
     ]
    }
   ],
   "source": [
    "test_split = 0.2\n",
    "\n",
    "sample_filenames = []\n",
    "for filename in os.listdir(output_train_folder_waves):\n",
    "    sample_filenames.append(filename.split('.')[0])\n",
    "\n",
    "samples = len(sample_filenames)\n",
    "\n",
    "num_train_samples = math.floor((1-test_split)*samples)\n",
    "num_test_samples = samples-num_train_samples\n",
    "\n",
    "print(f\"The total number of samples is {samples}\")\n",
    "print(f\"The total number of training samples will be {num_train_samples}\")\n",
    "print(f\"The total number of test samples will be {num_test_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(sample_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_test_samples):\n",
    "    filename = sample_filenames[i]\n",
    "\n",
    "    source_wav = os.path.join(output_train_folder_waves, filename + '.wav')\n",
    "    destination_wav = os.path.join(output_test_folder_waves)\n",
    "    shutil.move(source_wav, destination_wav)\n",
    "\n",
    "    source_transcript = os.path.join(output_train_folder_transcripts, filename + '.txt')\n",
    "    destination_transcript = os.path.join(output_test_folder_transcripts)\n",
    "    shutil.move(source_transcript, destination_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write the ```/train/prompts.txt``` and ```/test/prompts.txt``` files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_path = os.path.join(os.getcwd(), *output_train_path, 'prompts.txt')\n",
    "with open(train_prompts_path, 'a') as outfile:\n",
    "    for filename in os.listdir(output_train_folder_transcripts):\n",
    "        file_path = os.path.join(output_train_folder_transcripts, filename)\n",
    "        with open(file_path, \"r\") as infile:\n",
    "            outfile.write(infile.read() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_path = os.path.join(os.getcwd(), *output_test_path, 'prompts.txt')\n",
    "with open(test_prompts_path, 'a') as outfile:\n",
    "    for filename in os.listdir(output_test_folder_transcripts):\n",
    "        file_path = os.path.join(output_test_folder_transcripts, filename)\n",
    "        with open(file_path, \"r\") as infile:\n",
    "            outfile.write(infile.read() + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compress the folders into ```.tar.gzip```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_compress = [train_prompts_path, output_train_folder_waves, test_prompts_path, output_test_folder_waves]\n",
    "\n",
    "with tarfile.open(output_compressed_file, \"w:gz\") as tar_gz:\n",
    "    for path in paths_to_compress:\n",
    "        rel_path = os.path.relpath(path, os.path.join(os.getcwd(), *output_compressed_path))\n",
    "        tar_gz.add(path, arcname=rel_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_prompts_path, 'rb') as f_in, gzip.open(output_compressed_train_prompt_file, 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_prompts_path, 'rb') as f_in, gzip.open(output_compressed_test_prompt_file, 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_prompts_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    train_prompts_filenames = sorted([l.split(' ')[0] for l in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3000-1_1',\n",
       " '3000-1_10',\n",
       " '3000-1_100',\n",
       " '3000-1_101',\n",
       " '3000-1_102',\n",
       " '3000-1_103',\n",
       " '3000-1_104',\n",
       " '3000-1_105',\n",
       " '3000-1_106',\n",
       " '3000-1_107']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prompts_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wavs_filenames = []\n",
    "for filename in os.listdir(output_train_folder_waves):\n",
    "    filename = filename.split('.')[0]\n",
    "    train_wavs_filenames.append(filename)\n",
    "train_waves_filename = sorted(train_wavs_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3000-1_1',\n",
       " '3000-1_10',\n",
       " '3000-1_100',\n",
       " '3000-1_101',\n",
       " '3000-1_102',\n",
       " '3000-1_103',\n",
       " '3000-1_104',\n",
       " '3000-1_105',\n",
       " '3000-1_106',\n",
       " '3000-1_107']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_waves_filename[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prompts_filenames==train_waves_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_prompts_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    test_prompts_filenames = sorted([l.split(' ')[0] for l in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3000-1_112',\n",
       " '3000-1_114',\n",
       " '3000-1_115',\n",
       " '3000-1_121',\n",
       " '3000-1_122',\n",
       " '3000-1_123',\n",
       " '3000-1_129',\n",
       " '3000-1_131',\n",
       " '3000-1_14',\n",
       " '3000-1_140']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompts_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wavs_filenames = []\n",
    "for filename in os.listdir(output_test_folder_waves):\n",
    "    filename = filename.split('.')[0]\n",
    "    test_wavs_filenames.append(filename)\n",
    "test_waves_filename = sorted(test_wavs_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3000-1_112',\n",
       " '3000-1_114',\n",
       " '3000-1_115',\n",
       " '3000-1_121',\n",
       " '3000-1_122',\n",
       " '3000-1_123',\n",
       " '3000-1_129',\n",
       " '3000-1_131',\n",
       " '3000-1_14',\n",
       " '3000-1_140']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_wavs_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompts_filenames==test_wavs_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Upload to HF\n",
    "\n",
    "<u>Upload to HuggingFace</u>\n",
    "\n",
    "Prepare our own audio dataset and upload it to HF\n",
    "\n",
    "Stream data during the training process\n",
    "\n",
    "Each file is around 112770 KB which is 0.11 GB\n",
    "\n",
    "Part 3 consists of 1000 hours, which is maybe 110 GB ish\n",
    "\n",
    "But maybe half of it is not the enviornment we want\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "Folder structure\n",
    "\n",
    "Configure your dataset repository with audio files\n",
    "\n",
    "- https://huggingface.co/docs/datasets/audio_dataset#audiofolder\n",
    "- https://huggingface.co/docs/datasets/en/repository_structure#split-pattern-hierarchy\n",
    "- https://huggingface.co/docs/hub/datasets-audio\n",
    "\n",
    "```\n",
    "test_dataset\n",
    "    - metadata.csv: file_name (full relative path to audio file), transcription\n",
    "    - data\n",
    "        - train\n",
    "            - first_train_audio_file.wav\n",
    "            - second_train_audio_file.wav\n",
    "            - ...\n",
    "```\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "### <u>Approach 1</u>\n",
    "\n",
    "**<u>Part 1: Folder-based builders: Build dataset locally</u>**\n",
    "\n",
    "https://huggingface.co/docs/datasets/create_dataset\n",
    "\n",
    "https://huggingface.co/docs/datasets/audio_dataset#audiofolder\n",
    "\n",
    "https://huggingface.co/docs/datasets/en/repository_structure#split-pattern-hierarchy\n",
    "\n",
    "AudioFolder is a dataset builder to load an audio dataset with several thousand audio files. Additional information such as transcription is loaded by AudioFolder if its included in the metadata file\n",
    "\n",
    "AudioFolder creates splits based on split pattern hierarchy \n",
    "\n",
    "```\n",
    "# After structuring the data\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"audiofolder\", data_dir=\"/path/to/data\")\n",
    "```\n",
    "\n",
    "**<u>Part 2: Push local dataset to Hub</u>**\n",
    "\n",
    "https://huggingface.co/docs/datasets/upload_dataset\n",
    "\n",
    "```\n",
    "pip install huggingface_hub\n",
    "\n",
    "huggingface-cli login\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"stevhliu/demo\")\n",
    "\n",
    "dataset.push_to_hub(\"stevhliu/processed_demo\")\n",
    "```\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "### <u>Approach 2</u>\n",
    "\n",
    "https://huggingface.co/docs/datasets/audio_dataset#audiofolder\n",
    "\n",
    "https://huggingface.co/docs/hub/datasets-adding\n",
    "\n",
    "**<u>Part 1: Upload local dataset directory to Hub</u>**\n",
    "\n",
    "**<u>Uploading Datasets in general</u>**\n",
    "\n",
    "https://huggingface.co/docs/hub/datasets-adding\n",
    "\n",
    "- Dataset repos are Git repos, so we can use Git to push data files to the Hub\n",
    "- Starter: https://huggingface.co/docs/hub/repositories-getting-started\n",
    "- Parquet is the recommended format due to its efficient compression etc.\n",
    "    - For more general use cases involving analytics, data filtering or metadata parsing, Parquet is the recommended option for large scale image and audio datasets.\n",
    "- For large scale image and audio datasets streaming, WebDataset should be preferred over raw image and audio files to avoid the overhead of accessing individual files\n",
    "- Hugging Face Hub supports large scale datasets, usually uploaded in Parquet via push_to_hub() or WebDataset format\n",
    "\n",
    "**<u>Creating audio datasets</u>**\n",
    "\n",
    "- https://huggingface.co/docs/hub/datasets-audio\n",
    "- https://huggingface.co/collections/datasets-examples/audio-dataset-66aca0b73e8f69e3d069e607\n",
    "\n",
    "**<u>Uploading large folders</u>**\n",
    "\n",
    "https://huggingface.co/docs/huggingface_hub/guides/upload#upload-a-folder-by-chunks\n",
    "\n",
    "- Upload folder normally: ```upload_folder()```\n",
    "    - Upload a local folder to an existing repo\n",
    "    - Specify the path of the local folder to upload, where you want to upload the folder to in the repository, and the name of the repository you want to add the folder to. Depending on your repository type, you can optionally set the repository type as a dataset, model, or space\n",
    "\n",
    "    ```\n",
    "    from huggingface_hub import HfApi\n",
    "    api = HfApi()\n",
    "\n",
    "    api.upload_folder(\n",
    "        folder_path=\"/path/to/local/space\",\n",
    "        repo_id=\"username/my-cool-space\",\n",
    "        repo_type=\"space\",\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    - By default, the .gitignore file will be taken into account to know which files should be committed or not. By default we check if a .gitignore file is present in a commit, and if not, we check if it exists on the Hub. Please be aware that only a .gitignore file present at the root of the directory with be used. We do not check for .gitignore files in subdirectories.\n",
    "\n",
    "    - Makes a single commit, fails explicitly when something wrong happens\n",
    "\n",
    "- Upload a large folder: ```upload_large_folder()```\n",
    "    - Resumable\n",
    "        - Upload process is split into many small tasks\n",
    "        - Each time a task is completed, result is cached locally in ```./cache/huggingface``` inside the folder you're trying to upload\n",
    "    - Multi-threaded\n",
    "    - Resilient to errors: High-level retry-mechanism\n",
    "        - Downside: If transient errors happen, the process will continue and retry. If permanent errors happen (e.g. permission denied), it will retry indefinitely without solving the root cause.\n",
    "    - Limitations\n",
    "        - ...\n",
    "\n",
    "\n",
    "    ```\n",
    "    api.upload_large_folder(\n",
    "        repo_id=\"HuggingFaceM4/Docmatix\",\n",
    "        repo_type=\"dataset\",\n",
    "        folder_path=\"/path/to/local/docmatix\",\n",
    "    )\n",
    "    ```\n",
    "\n",
    "- Recommendations\n",
    "    - Start small\n",
    "\n",
    "- Upload a folder by chunks: ```upload_folder()```\n",
    "    - Upload a folder in serveral commits so we don't have to resume the process from the beginning: Pass ```multi_commits=True``` as a argument\n",
    "    - Recommended to pass ```multi_commits_verbose=True```\n",
    "    - Upload will resume from where it stopped\n",
    "        - If the process is interrupted before completing, you can rerun your script to resume the upload. The created PR will be automatically detected and the upload will resume from where it stopped\n",
    "    - ```multi_commits``` is still an experimental feature\n",
    "\n",
    "**<u>Repo Limits and recommendations</u>**\n",
    "\n",
    "https://huggingface.co/docs/hub/repositories-recommendations\n",
    "\n",
    "- Repo size: Generally support repos up to 300GB\n",
    "- Number of files: Keep total number of files under 100k\n",
    "    - Large datasets can be exported as Parque files or in WebDataset format\n",
    "    - Cannot exceed 10k files per folder. Solution is to create a repo structure that uses subdirectories \n",
    "\n",
    "\n",
    "**<u>Part 2: Load dataset from the hub using audiofolder</u>**\n",
    "\n",
    "```\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"audiofolder\", data_dir=\"/path/to/data\") # There's a streaming option: https://huggingface.co/docs/datasets/en/stream\n",
    "```\n",
    "\n",
    "### <u>Approach 3</u>\n",
    "\n",
    "https://huggingface.co/docs/hub/repositories-getting-started\n",
    "\n",
    "https://huggingface.co/docs/datasets/en/audio_dataset#loading-script ((Legacy) Loading script)\n",
    "\n",
    "https://huggingface.co/docs/hub/datasets-audio\n",
    "\n",
    "https://huggingface.co/collections/datasets-examples/audio-dataset-66aca0b73e8f69e3d069e607\n",
    "\n",
    "https://medium.com/htx-dsai/finetuning-whisper-for-the-singaporean-home-team-context-a3ae1a6ae809\n",
    "\n",
    "https://huggingface.co/docs/hub/datasets-webdataset\n",
    "\n",
    "Custom loading script\n",
    "\n",
    "Reasons\n",
    "- For large scale image and audio datasets streaming, WebDataset should be preferred over raw image and audio files to avoid the overhead of accessing individual files. \n",
    "- Audio datasets are commonly stored in tar.gz archives which requires a particular approach to support streaming mode. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dataset loading script for audio datasets\n",
    "\n",
    "Audio datasets are commonly stored in tar.gz archives which requires a particular approach to support streaming mode\n",
    "\n",
    "see ```new_dataset_script tutorial.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Put the dataset into WebDataset format\n",
    "\n",
    "vivos format:\n",
    "\n",
    "```\n",
    "- vivos.tar.gz\n",
    "    - vivos.tar\n",
    "        - train\n",
    "            - genders.txt: Contains the gender type for each waves folder\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files\n",
    "            - waves\n",
    "                - VIVOSSPK01 -> Speaker ID\n",
    "                    - VIVOSSPK01_R001.wav\n",
    "                    - VIVOSSPK01_R002.wav\n",
    "                    - VIVOSSPK01_R003.wav\n",
    "\n",
    "            - test\n",
    "    - prompts-train.txt.gz\n",
    "        - prompts-train.txt: Contains transcriptions for all the .wav files\n",
    "    - prompts-test.txt.gz\n",
    "```\n",
    "\n",
    "Usual size per archive is generally around 1GB?\n",
    "\n",
    "```\n",
    "- imda_nsc_p3.tar.gz\n",
    "    - imda_nsc_p3.tar\n",
    "        - train\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files\n",
    "            - waves\n",
    "                - 3000-1.tar\n",
    "                    - 3000-1_1.wav\n",
    "                    - 3000-1_2.wav\n",
    "                    - 3000-1_3.wav\n",
    "- prompts-train.txt.gz\n",
    "    - prompts-train.txt: Contains transcriptions for all the train .wav files\n",
    "```\n",
    "\n",
    "try this first\n",
    "\n",
    "```\n",
    "- imda_nsc_p3.tar.gz\n",
    "    - imda_nsc_p3.tar\n",
    "        - train\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files\n",
    "            - waves\n",
    "                - 3000-1_1.wav\n",
    "                - 3000-1_2.wav\n",
    "                - 3000-1_3.wav\n",
    "- prompts-train.txt.gz\n",
    "    - prompts-train.txt: Contains transcriptions for all the train .wav files\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
