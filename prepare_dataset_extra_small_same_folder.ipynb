{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset 3: Decrease the size of the train dataset from 530 hours to 10 hours\n",
    "\n",
    "- https://www.jensenlwt.com/blog/singlish-whisper-finetuning-asr-for-singapore-unique-english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Folder Structure\n",
    "\n",
    "```\n",
    "output drive\n",
    "- dataset_3\n",
    "    - data: Used to store compression files\n",
    "    - train\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in train\n",
    "        - waves\n",
    "        - transcripts\n",
    "    - test\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in test\n",
    "        - waves\n",
    "        - transcripts\n",
    "...\n",
    "\n",
    "data\n",
    "- imda_nsc_p3_extra_small.tar.gz\n",
    "    - train\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in train\n",
    "        - waves\n",
    "            - 3000-1_1.wav\n",
    "            - 3000-1_2.wav\n",
    "            - 3000-1_3.wav\n",
    "            - ...\n",
    "            - 3000-2_1.wav\n",
    "            - 3000-2_2.wav\n",
    "            - 3000-2_3.wav\n",
    "    - test\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in test\n",
    "        - waves\n",
    "            - 3000-3_1.wav\n",
    "            - 3000-3_2.wav\n",
    "            - 3000-3_3.wav\n",
    "            - ...\n",
    "            - 3000-4_1.wav\n",
    "            - 3000-4_2.wav\n",
    "            - 3000-4_3.wav\n",
    "- prompts-train-extra-small.txt.gz\n",
    "    - prompts-train.txt: Contains transcriptions for all the train .wav files -> taken from train/prompts.txt\n",
    "- prompts-test-extra-small.txt.gz\n",
    "    - prompts-test.txt: Contains transcriptions for all the test .wav files -> take from test/prompts.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johnl\\miniconda3\\envs\\myenv2\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import gzip\n",
    "import math\n",
    "import random\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialise Paths and Create the directories**\n",
    "\n",
    "**<u>USER ACTION REQUIRED</u>**\n",
    "\n",
    "- Change Relative Paths and Naming Conventions if you want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_train_path = ['dataset', 'train']\n",
    "org_test_path = ['dataset', 'test']\n",
    "small_train_path = ['dataset_3', 'train']\n",
    "small_test_path = ['dataset_3', 'test']\n",
    "small_compressed_path = ['dataset_3','data']\n",
    "small_compressed_filename = 'imda_nsc_p3_extra_small.tar.gz'\n",
    "small_compressed_train_prompt_filename = 'prompts-train-extra-small.txt.gz'\n",
    "small_compressed_test_prompt_filename = 'prompts-test-extra-small.txt.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>USER ACTION REQUIRED</u>**\n",
    "\n",
    "- Specify the output drive path\n",
    "- Change Relative Paths and Naming Conventions if you want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_drive_path = os.getcwd()\n",
    "small_train_folder_waves = os.path.join(output_drive_path, *small_train_path, 'waves')\n",
    "small_train_folder_transcripts = os.path.join(output_drive_path, *small_train_path, 'transcripts')\n",
    "small_test_folder_waves = os.path.join(output_drive_path, *small_test_path, 'waves')\n",
    "small_test_folder_transcripts = os.path.join(output_drive_path, *small_test_path, 'transcripts')\n",
    "small_compressed_folder = os.path.join(output_drive_path, *small_compressed_path)\n",
    "small_compressed_file = os.path.join(small_compressed_folder, small_compressed_filename)\n",
    "small_compressed_train_prompt_file = os.path.join(small_compressed_folder, small_compressed_train_prompt_filename)\n",
    "small_compressed_test_prompt_file = os.path.join(small_compressed_folder, small_compressed_test_prompt_filename)\n",
    "\n",
    "org_train_folder_waves = os.path.join(output_drive_path, *org_train_path, 'waves')\n",
    "org_train_folder_transcripts = os.path.join(output_drive_path, *org_train_path, 'transcripts')\n",
    "org_test_folder_waves = os.path.join(output_drive_path, *org_test_path, 'waves')\n",
    "org_test_folder_transcripts = os.path.join(output_drive_path, *org_test_path, 'transcripts')\n",
    "\n",
    "create_dir = [small_train_folder_waves, small_train_folder_transcripts, small_test_folder_waves, small_test_folder_transcripts, \n",
    "              small_compressed_folder]\n",
    "\n",
    "for dir in create_dir:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>USER ACTION REQUIRED</u>**\n",
    "\n",
    "- Decide the total dataset hours that will be uploaded to HuggingFace\n",
    "- Change Relative Paths and Naming Conventions if you want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data hours will be 10\n",
      "Test data hours will be 2\n"
     ]
    }
   ],
   "source": [
    "total_dataset_hours = 12\n",
    "train_split = 0.9\n",
    "train_data_hours = math.floor(0.9*total_dataset_hours)\n",
    "test_data_hours = total_dataset_hours - train_data_hours\n",
    "print(f'Train data hours will be {train_data_hours}')\n",
    "print(f'Test data hours will be {test_data_hours}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a function to copy files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyfiles_wav(src_dir,dest_dir,filenames):\n",
    "    for filename in filenames:\n",
    "        src_fp = os.path.join(src_dir,filename + '.wav')\n",
    "        shutil.copy2(src_fp, dest_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyfiles_txt(src_dir,dest_dir,filenames):\n",
    "    for filename in filenames:\n",
    "        src_fp = os.path.join(src_dir,filename + '.txt')\n",
    "        shutil.copy2(src_fp, dest_dir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accumulate the required hours of training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulated 10.001350555555547 hours of training data\n"
     ]
    }
   ],
   "source": [
    "total_duration = 0 \n",
    "train_filenames = []\n",
    "for filename in os.listdir(org_train_folder_waves):\n",
    "    fp = os.path.join(org_train_folder_waves, filename)\n",
    "    audio = AudioSegment.from_file(fp)\n",
    "    total_duration += len(audio)/1000 # Add the length of audio segments in seconds\n",
    "    train_filenames.append(filename.split('.')[0])\n",
    "    if total_duration/3600 >= train_data_hours: # Check if the total duration has exceeded our requirements in hours\n",
    "        print(f'Accumulated {total_duration/3600} hours of training data')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3000-1_11',\n",
       " '3000-1_12',\n",
       " '3000-1_13',\n",
       " '3000-1_16',\n",
       " '3000-1_17',\n",
       " '3000-1_19',\n",
       " '3000-1_2',\n",
       " '3000-1_20',\n",
       " '3000-1_21',\n",
       " '3000-1_22']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filenames[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy training wav files from ```data/train/waves``` to ```data_3/train/waves```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "copyfiles_wav(org_train_folder_waves,small_train_folder_waves,train_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy training transcript files from ```data/train/transcripts``` to ```data_3/train/transcripts```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "copyfiles_txt(org_train_folder_transcripts,small_train_folder_transcripts,train_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accumulate the required hours of test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulated 2.001969722222222 hours of test data\n"
     ]
    }
   ],
   "source": [
    "total_duration = 0 \n",
    "test_filenames = []\n",
    "for filename in os.listdir(org_test_folder_waves):\n",
    "    fp = os.path.join(org_test_folder_waves, filename)\n",
    "    audio = AudioSegment.from_file(fp)\n",
    "    total_duration += len(audio)/1000 # Add the length of audio segments in seconds\n",
    "    test_filenames.append(filename.split('.')[0])\n",
    "    if total_duration/3600 >= test_data_hours: # Check if the total duration has exceeded our requirements in hours\n",
    "        print(f'Accumulated {total_duration/3600} hours of test data')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3000-1_1',\n",
       " '3000-1_10',\n",
       " '3000-1_14',\n",
       " '3000-1_15',\n",
       " '3000-1_18',\n",
       " '3000-1_29',\n",
       " '3000-1_44',\n",
       " '3000-1_45',\n",
       " '3000-1_49',\n",
       " '3000-1_50']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_filenames[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy training wav files from ```data/test/waves``` to ```data_3/test/waves```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "copyfiles_wav(org_test_folder_waves,small_test_folder_waves,test_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy training transcript files from ```data/test/transcripts``` to ```data_3/test/transcripts```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "copyfiles_txt(org_test_folder_transcripts,small_test_folder_transcripts,test_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write the ```/train/prompts.txt``` and ```/test/prompts.txt``` files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_path = os.path.join(output_drive_path, *small_train_path, 'prompts.txt')\n",
    "with open(train_prompts_path, 'a') as outfile:\n",
    "    for filename in os.listdir(small_train_folder_transcripts):\n",
    "        file_path = os.path.join(small_train_folder_transcripts, filename)\n",
    "        with open(file_path, \"r\") as infile:\n",
    "            outfile.write(infile.read() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_path = os.path.join(output_drive_path, *small_test_path, 'prompts.txt')\n",
    "with open(test_prompts_path, 'a') as outfile:\n",
    "    for filename in os.listdir(small_test_folder_transcripts):\n",
    "        file_path = os.path.join(small_test_folder_transcripts, filename)\n",
    "        with open(file_path, \"r\") as infile:\n",
    "            outfile.write(infile.read() + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compress the folders into ```.tar.gzip```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_compress = [train_prompts_path, small_train_folder_waves, test_prompts_path, small_test_folder_waves]\n",
    "\n",
    "with tarfile.open(small_compressed_file, \"w:gz\") as tar_gz:\n",
    "    for path in paths_to_compress:\n",
    "        rel_path = os.path.relpath(path, os.path.join(os.getcwd(), *small_compressed_path))\n",
    "        tar_gz.add(path, arcname=rel_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_prompts_path, 'rb') as f_in, gzip.open(small_compressed_train_prompt_file, 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_prompts_path, 'rb') as f_in, gzip.open(small_compressed_test_prompt_file, 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
