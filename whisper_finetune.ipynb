{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper Finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Get Data \n",
    "\n",
    "National Speech Corpus\n",
    "- Part 3: 1000 hours of conversational speech data (Used by Home team)\n",
    "- Part 2: 1000 hours of prompted recordings of random sentences containing local words and entities (Used by some developer)\n",
    "- Part 4: Conversational code-switched data (from Singaporean English to various native languages)\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "- https://medium.com/htx-dsai/finetuning-whisper-for-the-singaporean-home-team-context-a3ae1a6ae809\n",
    "- https://www.jensenlwt.com/blog/singlish-whisper-finetuning-asr-for-singapore-unique-english\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Prepare Data\n",
    "\n",
    "- Match each transcript sentence to its corresponding audio file\n",
    "- Check on the environment where the audio is recorded (decide the environment)\n",
    "    - Close-talk mic that isolates main speaker's voice \n",
    "    - Standing microphone \n",
    "- Clean the transcripts by removing annotations\n",
    "- Normalise the transcript text\n",
    "    - Remove punctuations\n",
    "    - Lowercase text\n",
    "- Create 30s audio segments with corresponding transcripts\n",
    "    - Using time segments from ```TextGrid files```, splice out corresponding segments from WAV files\n",
    "    - Combine shorter consecutive segments (?)\n",
    "    - 30s: Whisper's feature extractor ensures all audio is 30s (intrinsic design)\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "- https://medium.com/htx-dsai/finetuning-whisper-for-the-singaporean-home-team-context-a3ae1a6ae809\n",
    "- https://www.jensenlwt.com/blog/singlish-whisper-finetuning-asr-for-singapore-unique-english\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Match 3000-1.wav and 3000-1.TEXTGRID**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Clean transcripts by removing annotations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jiaaro/pydub#installation\n",
    "# https://github.com/timmahrt/praatIO/tree/main\n",
    "\n",
    "import os\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment\n",
    "\n",
    "audio_path = os.path.join(os.getcwd(), 'dataset', 'part3', 'simple_example', '3000-1.wav')\n",
    "textgrid_path = os.path.join(os.getcwd(), 'dataset', 'part3', 'simple_example', '3000-1.TextGrid')\n",
    "output_dir = os.path.join(os.getcwd(), 'dataset', 'part3', 'simple_example', '3000-1-splits')\n",
    "\n",
    "audio = AudioSegment.from_wav(audio_path)\n",
    "tg = textgrid.openTextgrid(textgrid_path, False)\n",
    "\n",
    "# pydub does things in milliseconds\n",
    "segment_duration_ms = 30 * 1000  \n",
    "\n",
    "# Get total duration of the audio in milliseconds\n",
    "audio_duration = len(audio)\n",
    "\n",
    "# Initialize start time and segment index\n",
    "start_time = 0\n",
    "segment_index = 1\n",
    "\n",
    "#while start_time < audio_duration:\n",
    "    # Initialise end time of the segment\n",
    "end_time = min(start_time + segment_duration_ms, audio_duration)\n",
    "\n",
    "# Extract audio segment given the current start and end timing\n",
    "audio_segment = audio[start_time:end_time]\n",
    "\n",
    "# Save the audio segment\n",
    "audio_segment_path = os.path.join(output_dir, f'segment_{segment_index}.wav')\n",
    "audio_segment.export(audio_segment_path, format=\"wav\")\n",
    "\n",
    "# Extract the corresponding TextGrid segment\n",
    "tg_segment = tg.crop(start_time / 1000, end_time / 1000, mode=\"truncated\", rebaseToZero=True)\n",
    "\n",
    "# Check tg_segment\n",
    "tg_segment_path = os.path.join(output_dir, 'tg_segment.TextGrid')\n",
    "tg_segment.save(tg_segment_path, \"long_textgrid\", True)\n",
    "\n",
    "# Collect transcriptions from the TextGrid segment\n",
    "transcriptions = []\n",
    "for tier_name in tg_segment.tierNames:\n",
    "    tier = tg_segment.getTier(tier_name)\n",
    "    for entry in tier.entries:\n",
    "        if entry.label.strip():  # Only include non-empty transcriptions\n",
    "            transcriptions.append(entry.label)\n",
    "\n",
    "# Save the transcriptions to a text file\n",
    "transcription_path = os.path.join(output_dir, f'segment_{segment_index}_transcription.txt')\n",
    "with open(transcription_path, 'w') as f:\n",
    "    f.write(\"\\n\".join(transcriptions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Load Data\n",
    "\n",
    "<u>Upload to HuggingFace</u>\n",
    "\n",
    "Prepare our own audio dataset and upload it to HF\n",
    "\n",
    "Stream data during the training process\n",
    "\n",
    "- https://medium.com/htx-dsai/finetuning-whisper-for-the-singaporean-home-team-context-a3ae1a6ae809\n",
    "- https://twodatadetectives.medium.com/push-your-custom-dataset-to-huggingface-two-ways-47482e8a0f34\n",
    "- https://huggingface.co/docs/datasets/en/create_dataset\n",
    "- https://huggingface.co/docs/datasets/en/audio_dataset#loading-script\n",
    "- https://github.com/huggingface/datasets/blob/main/templates/new_dataset_script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
