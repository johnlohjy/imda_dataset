{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "<u>Initialising the directory</u>\n",
    "```\n",
    "dataset\n",
    "- testing\n",
    "    - data: Used to store compression files\n",
    "    - org_waves: Manually add in .wav files\n",
    "        - 3000-1.wav\n",
    "        - 3000-2.wav\n",
    "        - ...\n",
    "    - org_transcripts: Manually add in .TextGrid files\n",
    "        - 3000-1.TextGrid\n",
    "        - 3000-2.TextGrid\n",
    "        - ...\n",
    "    - train\n",
    "        - waves: Empty\n",
    "        - transcripts: Empty\n",
    "    - test\n",
    "        - waves: Empty\n",
    "        - transcripts: Empty\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Step 2:\n",
    "<u>After running the processing code</u>\n",
    "```\n",
    "dataset\n",
    "- testing\n",
    "    - data: Used to store compression files\n",
    "    - org_waves: Manually add in .wav files\n",
    "        - 3000-1.wav\n",
    "        - 3000-2.wav\n",
    "        - ...\n",
    "    - org_transcripts: Manually add in .TextGrid files\n",
    "        - 3000-1.TextGrid\n",
    "        - 3000-2.TextGrid\n",
    "        - ...\n",
    "    - train\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in train\n",
    "        - waves\n",
    "            - 3000-1_1.wav\n",
    "            - 3000-1_2.wav\n",
    "            - 3000-1_3.wav\n",
    "            - ...\n",
    "            - 3000-2_1.wav\n",
    "            - 3000-2_2.wav\n",
    "            - 3000-2_3.wav\n",
    "        - transcripts\n",
    "            - 3000-1_1.txt\n",
    "            - 3000-1_2.txt\n",
    "            - 3000-1_3.txt\n",
    "            - ...\n",
    "            - 3000-2_1.txt\n",
    "            - 3000-2_2.txt\n",
    "            - 3000-2_3.txt\n",
    "    - test\n",
    "        - prompts.txt: Contains transcriptions for all the .wav files in test\n",
    "        - waves\n",
    "            - 3000-3_1.wav\n",
    "            - 3000-3_2.wav\n",
    "            - 3000-3_3.wav\n",
    "            - ...\n",
    "            - 3000-4_1.wav\n",
    "            - 3000-4_2.wav\n",
    "            - 3000-4_3.wav\n",
    "        - transcripts\n",
    "            - 3000-3_1.txt\n",
    "            - 3000-3_2.txt\n",
    "            - 3000-3_3.txt\n",
    "            - ...\n",
    "            - 3000-4_1.txt\n",
    "            - 3000-4_2.txt\n",
    "            - 3000-4_3.txt\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Step 3:\n",
    "<u>After running the compression code</u>\n",
    "\n",
    "```\n",
    "data\n",
    "    - input_name.tar.gz\n",
    "        - train\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files\n",
    "            - waves\n",
    "                - 3000-1_1.wav\n",
    "                - 3000-1_2.wav\n",
    "                - 3000-1_3.wav\n",
    "                - ...\n",
    "                - 3000-2_1.wav\n",
    "                - 3000-2_2.wav\n",
    "                - 3000-2_3.wav\n",
    "        - test\n",
    "            - prompts.txt: Contains transcriptions for all the .wav files\n",
    "            - waves\n",
    "                - 3000-3_1.wav\n",
    "                - 3000-3_2.wav\n",
    "                - 3000-3_3.wav\n",
    "                - ...\n",
    "                - 3000-4_1.wav\n",
    "                - 3000-4_2.wav\n",
    "                - 3000-4_3.wav\n",
    "    - prompts-train.txt.gz\n",
    "        - prompts-train.txt: Contains transcriptions for all the train .wav files -> take this from train/prompts.txt\n",
    "    - prompts-test.txt.gz\n",
    "        - prompts-test.txt: Contains transcriptions for all the test .wav files -> take this from test/prompts.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johnl\\miniconda3\\envs\\myenv2\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import gzip\n",
    "import math\n",
    "import random\n",
    "from praatio import textgrid \n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>USER INPUT REQUIRED</u> Input Relative Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio_path = ['dataset', 'testing', 'org_wavs']\n",
    "input_textgrid_path = ['dataset', 'testing', 'org_transcripts']\n",
    "output_train_path = ['dataset', 'testing', 'train']\n",
    "output_test_path = ['dataset', 'testing', 'test']\n",
    "output_compressed_path = ['dataset', 'testing']\n",
    "compressed_filename = 'imda_nsc_p3_testing.tar.gz'\n",
    "compressed_train_prompt_filename = 'prompts-train.txt.gz'\n",
    "compressed_test_prompt_filename = 'prompts-test.txt.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialise Paths and Create the directories**\n",
    "\n",
    "**IMPT <u>USER INPUT REQUIRED</u>**: Remember to add in the ```.wav``` and ```.TextGrid``` files to org_waves and org_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wav_folder = os.path.join(os.getcwd(), *input_audio_path)\n",
    "input_textgrid_folder = os.path.join(os.getcwd(), *input_textgrid_path)\n",
    "output_train_folder_waves = os.path.join(os.getcwd(), *output_train_path, 'waves')\n",
    "output_train_folder_transcripts = os.path.join(os.getcwd(), *output_train_path, 'transcripts')\n",
    "output_test_folder_waves  = os.path.join(os.getcwd(), *output_test_path, 'waves')\n",
    "output_test_folder_transcripts = os.path.join(os.getcwd(), *output_test_path, 'transcripts')\n",
    "output_textgrids_folder = os.path.join(os.getcwd(), *output_train_path, 'textgrids')\n",
    "output_compressed_folder = os.path.join(os.getcwd(), *output_compressed_path, 'data')\n",
    "output_compressed_file = os.path.join(output_compressed_folder, compressed_filename)\n",
    "output_compressed_train_prompt_file = os.path.join(output_compressed_folder, compressed_train_prompt_filename)\n",
    "output_compressed_test_prompt_file = os.path.join(output_compressed_folder, compressed_test_prompt_filename)\n",
    "\n",
    "create_dir = [input_wav_folder, input_textgrid_folder, output_train_folder_waves, output_train_folder_transcripts,\n",
    "              output_test_folder_waves, output_test_folder_transcripts, output_textgrids_folder, output_compressed_folder]\n",
    "\n",
    "for dir in create_dir:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper function to clean the transcription**\n",
    "\n",
    "1. Lower-case the text\n",
    "\n",
    "2. Remove and replace annotations\n",
    "\n",
    "- Paralinguistic Phenomena: Remove '(ppb)', '(ppc)', '(ppl)', '(ppo)'\n",
    "- Acronyms: Remove '_'\n",
    "- Multi-word nouns: Replace '-' with ' '\n",
    "- Discourse particles: Remove '[' and ']'\n",
    "- Fillers: Remove '(' and ')'\n",
    "- Interjections: Remove '!'\n",
    "- Other languages: Remove '#'\n",
    "- Unclear words: Remove ```'<unk>'```\n",
    "- Incomplete words: Remove '~'\n",
    "- Short pauses: Remove ```'<s>'```\n",
    "- Invalid: Remove ```'<z>'```\n",
    "- Long-running non-english utterances: Remove ```'<nen>'```\n",
    "- Fillers: Remove ```'<fil/>'```\n",
    "- Speaker Noise: Remove ```'<spk/>'```\n",
    "- Unknown: Remove '**'\n",
    "- Non-primary speaker sound: Remove ```'<non/>'```\n",
    "- End of sentence: Remove ```'<s/>'```\n",
    "- Comma: Remove ```'<c/>'```\n",
    "- Remove all instances of ```<whatever is inside>```\n",
    "\n",
    "3. Remove extra spaces created by ```<s>``` and stuff\n",
    "\n",
    "Refer to the Transcription Guidelines by IMDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcription(transcript):\n",
    "    transcript = ' '.join(line.strip() for line in transcript)\n",
    "    transcript = transcript.lower()\n",
    "    remove = [r'\\(ppb\\)|\\(ppc\\)|\\(ppl\\)|\\(ppo\\)', r'_', r'\\[|\\]', r'\\(|\\)', r'!', \n",
    "            r'#', r'<unk>', r'~', r'<s>', r'<z>', r'<nen>', r'<fil/>', r'<spk/>',\n",
    "            r'\\*', r'<non/>', r'<s/>', r'<c/>', r'<[^>]+>'] \n",
    "    replace = ['-']\n",
    "    for e in remove:\n",
    "        transcript = re.sub(e, '', transcript)\n",
    "    for e in replace:\n",
    "        transcript = re.sub(e, ' ', transcript)\n",
    "    transcript = re.sub(r'\\s+', ' ', transcript).strip()\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main function**\n",
    "\n",
    "Matches a single ```.wav``` file to its respective ```.TextGrid``` file\n",
    "\n",
    "- Break the ```.wav``` file and ```.TextGrid``` file into 30s segments\n",
    "- Clean the ```.TextGrid``` file\n",
    "- Only keep segments that have audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_transcript(audio_filename, input_audio_path, input_textgrid_path, output_path, sanity_check=False):\n",
    "    audio_path = os.path.join(os.getcwd(), *input_audio_path, f'{audio_filename}.wav')\n",
    "    textgrid_path = os.path.join(os.getcwd(), *input_textgrid_path, f'{audio_filename}.TextGrid')\n",
    "\n",
    "    output_dir_wav = os.path.join(os.getcwd(), *output_path, 'waves')\n",
    "    output_dir_transcript = os.path.join(os.getcwd(), *output_path, 'transcripts')\n",
    "\n",
    "    output_dir_textgrid = os.path.join(os.getcwd(), *output_path, 'textgrids')\n",
    "\n",
    "    audio = AudioSegment.from_wav(audio_path)\n",
    "    tg = textgrid.openTextgrid(textgrid_path, False) \n",
    "\n",
    "    segment_duration_ms = 30 * 1000  \n",
    "\n",
    "    audio_duration = len(audio)\n",
    "\n",
    "    start_time = 0\n",
    "    segment_index = 1\n",
    "\n",
    "    while start_time < audio_duration:\n",
    "        end_time = min(start_time + segment_duration_ms, audio_duration)\n",
    "\n",
    "        audio_segment = audio[start_time:end_time]\n",
    "        tg_segment = tg.crop(start_time / 1000, end_time / 1000, mode=\"truncated\", rebaseToZero=False)\n",
    "\n",
    "        transcriptions = []\n",
    "        for tier_name in tg_segment.tierNames: \n",
    "            tier = tg_segment.getTier(tier_name) \n",
    "            for entry in tier.entries:  \n",
    "                if entry.label.strip():  \n",
    "                    transcriptions.append(entry.label)\n",
    "\n",
    "        transcriptions_clean = clean_transcription(transcriptions)\n",
    "\n",
    "        if len(transcriptions_clean) > 0:\n",
    "            transcript_segment_path = os.path.join(output_dir_transcript, f'{audio_filename}_{segment_index}.txt')\n",
    "            with open(transcript_segment_path, 'w') as f:\n",
    "                f.write(f'{audio_filename}_{segment_index} {transcriptions_clean}')\n",
    "\n",
    "            if sanity_check:\n",
    "                tg_segment_path = os.path.join(output_dir_textgrid, f'{audio_filename}_{segment_index}.TextGrid')\n",
    "                tg_segment.save(tg_segment_path, \"long_textgrid\", True)\n",
    "            \n",
    "            audio_segment_path = os.path.join(output_dir_wav, f'{audio_filename}_{segment_index}.wav')\n",
    "            audio_segment.export(audio_segment_path, format=\"wav\")\n",
    "\n",
    "            start_time+=segment_duration_ms\n",
    "            segment_index+=1\n",
    "        else:\n",
    "            start_time+=segment_duration_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the main function to segment 30s chunks for each ```.wav``` and ```.TextGrid``` file**\n",
    "\n",
    "Output is the segmented ```.wav``` files and transcriptions for each ```.wav``` file stored in ```train/waves``` and ```train/transcripts``` respectively\n",
    "\n",
    "Note: We first put the files into the train folder\n",
    "\n",
    "A sanity check can be set to True to view the segmented ```.TextGrid``` files in ```./train/textgrids/```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = os.path.join(os.getcwd(), *input_audio_path)\n",
    "for filename in os.listdir(audio_path):\n",
    "    filename = filename.split('.')[0]\n",
    "    process_audio_transcript(filename, input_audio_path, input_textgrid_path, output_train_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Move a split of the ```.wav``` files and ```.txt``` file to test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of samples is 238\n",
      "The total number of training samples will be 190\n",
      "The total number of test samples will be 48\n"
     ]
    }
   ],
   "source": [
    "test_split = 0.2\n",
    "\n",
    "sample_filenames = []\n",
    "for filename in os.listdir(output_train_folder_waves):\n",
    "    sample_filenames.append(filename.split('.')[0])\n",
    "\n",
    "samples = len(sample_filenames)\n",
    "\n",
    "num_train_samples = math.floor((1-test_split)*samples)\n",
    "num_test_samples = samples-num_train_samples\n",
    "\n",
    "print(f\"The total number of samples is {samples}\")\n",
    "print(f\"The total number of training samples will be {num_train_samples}\")\n",
    "print(f\"The total number of test samples will be {num_test_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(sample_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_test_samples):\n",
    "    filename = sample_filenames[i]\n",
    "\n",
    "    source_wav = os.path.join(output_train_folder_waves, filename + '.wav')\n",
    "    destination_wav = os.path.join(output_test_folder_waves)\n",
    "    shutil.move(source_wav, destination_wav)\n",
    "\n",
    "    source_transcript = os.path.join(output_train_folder_transcripts, filename + '.txt')\n",
    "    destination_transcript = os.path.join(output_test_folder_transcripts)\n",
    "    shutil.move(source_transcript, destination_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write the ```/train/prompts.txt``` and ```/test/prompts.txt``` files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_path = os.path.join(os.getcwd(), *output_train_path, 'prompts.txt')\n",
    "with open(train_prompts_path, 'a') as outfile:\n",
    "    for filename in os.listdir(output_train_folder_transcripts):\n",
    "        file_path = os.path.join(output_train_folder_transcripts, filename)\n",
    "        with open(file_path, \"r\") as infile:\n",
    "            outfile.write(infile.read() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts_path = os.path.join(os.getcwd(), *output_test_path, 'prompts.txt')\n",
    "with open(test_prompts_path, 'a') as outfile:\n",
    "    for filename in os.listdir(output_test_folder_transcripts):\n",
    "        file_path = os.path.join(output_test_folder_transcripts, filename)\n",
    "        with open(file_path, \"r\") as infile:\n",
    "            outfile.write(infile.read() + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compress the folders into ```.tar.gzip```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_compress = [train_prompts_path, output_train_folder_waves, test_prompts_path, output_test_folder_waves]\n",
    "\n",
    "with tarfile.open(output_compressed_file, \"w:gz\") as tar_gz:\n",
    "    for path in paths_to_compress:\n",
    "        rel_path = os.path.relpath(path, os.path.join(os.getcwd(), *output_compressed_path))\n",
    "        tar_gz.add(path, arcname=rel_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_prompts_path, 'rb') as f_in, gzip.open(output_compressed_train_prompt_file, 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_prompts_path, 'rb') as f_in, gzip.open(output_compressed_test_prompt_file, 'wb') as f_out:\n",
    "    f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_prompts_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    train_prompts_filenames = sorted([l.split(' ')[0] for l in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3000-1_1',\n",
       " '3000-1_100',\n",
       " '3000-1_101',\n",
       " '3000-1_102',\n",
       " '3000-1_103',\n",
       " '3000-1_104',\n",
       " '3000-1_105',\n",
       " '3000-1_106',\n",
       " '3000-1_107',\n",
       " '3000-1_108']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prompts_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wavs_filenames = []\n",
    "for filename in os.listdir(output_train_folder_waves):\n",
    "    filename = filename.split('.')[0]\n",
    "    train_wavs_filenames.append(filename)\n",
    "train_waves_filename = sorted(train_wavs_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3000-1_1',\n",
       " '3000-1_100',\n",
       " '3000-1_101',\n",
       " '3000-1_102',\n",
       " '3000-1_103',\n",
       " '3000-1_104',\n",
       " '3000-1_105',\n",
       " '3000-1_106',\n",
       " '3000-1_107',\n",
       " '3000-1_108']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_waves_filename[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prompts_filenames==train_waves_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_prompts_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    test_prompts_filenames = sorted([l.split(' ')[0] for l in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3000-1_10',\n",
       " '3000-1_118',\n",
       " '3000-1_119',\n",
       " '3000-1_13',\n",
       " '3000-1_15',\n",
       " '3000-1_27',\n",
       " '3000-1_28',\n",
       " '3000-1_32',\n",
       " '3000-1_33',\n",
       " '3000-1_34']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompts_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wavs_filenames = []\n",
    "for filename in os.listdir(output_test_folder_waves):\n",
    "    filename = filename.split('.')[0]\n",
    "    test_wavs_filenames.append(filename)\n",
    "test_waves_filename = sorted(test_wavs_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3000-1_10',\n",
       " '3000-1_118',\n",
       " '3000-1_119',\n",
       " '3000-1_13',\n",
       " '3000-1_15',\n",
       " '3000-1_27',\n",
       " '3000-1_28',\n",
       " '3000-1_32',\n",
       " '3000-1_33',\n",
       " '3000-1_34']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_wavs_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompts_filenames==test_wavs_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
